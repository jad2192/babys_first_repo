{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5105)\n",
      "/home/james/anaconda3/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import log, exp, zeros, dot, array\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import timeit\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(x):\n",
    "    \n",
    "    m = x.max()\n",
    "    x_s = x - m\n",
    "    return m + log((exp(x_s)).sum())\n",
    "\n",
    "\n",
    "def label_seq(l,j):\n",
    "    '''Creates a list of all posible length l sequences taking values in\n",
    "       {0,1,...,j-1}. Out put list is of length j^l'''\n",
    "    \n",
    "    \n",
    "    return list(product(list(range(j)), repeat=l))\n",
    "\n",
    "def find_legit_vals(k,l,n):\n",
    "    '''Finds the only possible label pairs (i,j) with f_k(i,j,x,t) != 0.\n",
    "       Will be used to speed up gradient computation.\n",
    "       l: Number of labels\n",
    "       n: Size of a nodes feature vector'''\n",
    "    \n",
    "    res = []\n",
    "    k_s = k - n*l\n",
    "    \n",
    "    if k_s < 0:  #Means k is in the Unary features\n",
    "        \n",
    "        i = k // n\n",
    "        \n",
    "        for j in range(l):\n",
    "            \n",
    "            res.append((i,j))\n",
    "            \n",
    "    else:  #Means k is a Binary feature\n",
    "        \n",
    "        f = (k_s // n)\n",
    "        j = f % l\n",
    "        i = f // l\n",
    "        res.append((i,j))  \n",
    "    \n",
    "    return res\n",
    "\n",
    "C_init = np.array([1,1,0])\n",
    "\n",
    "class CRF(object):\n",
    "    \n",
    "    def __init__(self, feature_function, K, L, lamb=1, W = 'none'):\n",
    "        ''' If our labels belong to space L and our observations belonging to X amd\n",
    "            then length of our chain is T (call {0,1, ... , T-1} = T') then \n",
    "            feature_functions is a vector valued function, f: L^2 x X x T' --> R^K\n",
    "            i.e. f(i,j,x,t) is a K-d real valued vector and has component functions of the form\n",
    "            f_k(i,j,x,t) to be specified, think of (i,j) = (y_t, y_t-1). It will have an optional\n",
    "            keyword argument 'project' which defaults to -1, if a positive integer k,\n",
    "            it will project onto the k-th component.\n",
    "            \n",
    "            K: # of Features\n",
    "            \n",
    "            L: Number of labels. Will assume labels have been encoded as integers in {0,...,L-1} \n",
    "            \n",
    "            lamb: L2 regularization constant'''\n",
    "        \n",
    "        self.K = K\n",
    "        self.L = L\n",
    "        self.Lambda = lamb\n",
    "        self.f_x = feature_function\n",
    "        \n",
    "        if type(W) == str:\n",
    "            if W == 'none':\n",
    "                self.W = 0.2 * np.random.randn(K)\n",
    "                \n",
    "            if W == 'U':\n",
    "                self.W = np.zeros(K)\n",
    "                self.W[0] = 1\n",
    "            if W == 'B':\n",
    "                self.W = np.ones(K)\n",
    "                self.W[1:] = np.random.randn(K-1)\n",
    "        else:\n",
    "            self.W = W\n",
    "            \n",
    "      \n",
    "        \n",
    "    def  log_forward(self, x):\n",
    "        '''This computes the log(alphas) as in the forward-backward algorithm in order to\n",
    "           be used for inference tasks later on.\n",
    "           x is an observation.'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]\n",
    "        alphas = zeros((T, self.L))\n",
    "        \n",
    "        # Initialization\n",
    "        \n",
    "        for l in range(self.L):\n",
    "            \n",
    "            alphas[0,l] = dot(self.W, f(l,0,x,0))\n",
    "            \n",
    "        # Recursion\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                psi = array([dot(self.W, f(l,i,x,t)) for i in range(self.L)])\n",
    "                \n",
    "                alphas[t,l] = log_sum_exp(psi + alphas[t-1])\n",
    "            \n",
    "        return alphas\n",
    "    \n",
    "        \n",
    "    def log_backward(self, x):\n",
    "        '''This computes the log(betas) as in the forward-backward algorithm in order to\n",
    "           be used for inference tasks later on.\n",
    "           x is an observation.'''\n",
    "        \n",
    "        # Initialization\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]\n",
    "        betas = np.ones((T, self.L))\n",
    "      \n",
    "        # Recursion\n",
    "        \n",
    "        for t in range(T-2,-1,-1):\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                psi = array([dot(self.W, f(i,l,x,t+1)) for i in range(self.L)])\n",
    "                \n",
    "                betas[t][l] = log_sum_exp(psi + betas[t+1])\n",
    "                \n",
    "        return betas\n",
    "    \n",
    "    \n",
    "    def log_partition(self, x):\n",
    "        '''Efficient computation of the log of the partition function Z(x) appearing in CRF model.\n",
    "           Input an observation and inital label (for forward algorithm) and output is log(Z(x))'''\n",
    "        \n",
    "        alphas = self.log_forward(x)\n",
    "        \n",
    "        return log_sum_exp(alphas[-1])\n",
    "    \n",
    "    \n",
    "    def MAP(self, x):\n",
    "        '''Viterbi algortithm for computing the most likely label of a sequence with\n",
    "           given observation vector x using maximum a posteriori estimation. Using log\n",
    "           sum version for numeric stability'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]   \n",
    "        # Initialization\n",
    "        \n",
    "        deltas = np.zeros((T, self.L))\n",
    "        delt_arg = np.zeros((T, self.L))\n",
    "        \n",
    "        for l in range(self.L):\n",
    "            \n",
    "            deltas[0][l] = dot(self.W, f(l,0,x,0))  # Not sure about this.\n",
    "            \n",
    "        # Recursion\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                psi = array([dot(self.W, f(l,i,x,t)) for i in range(self.L)])\n",
    "                \n",
    "                deltas[t][l] = (psi + deltas[t-1]).max()\n",
    "                delt_arg[t][l] = (psi + deltas[t-1]).argmax()\n",
    "            \n",
    "        map_lab = np.zeros(T, dtype='i4')\n",
    "        map_lab[-1] = deltas[-1].argmax()\n",
    "        \n",
    "        for t in range(T-2,-1,-1):\n",
    "            \n",
    "            map_lab[t] = delt_arg[t+1][map_lab[t+1]]\n",
    "            \n",
    "                \n",
    "        return tuple(map_lab)\n",
    "        \n",
    "        \n",
    "    def marginal(self,i,j,x,t):\n",
    "        '''Using the forward backward algorithm to compute the marginal p(y_t-1=i,y_t=j|x)'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        alphas = self.log_forward(x)\n",
    "        betas = self.log_backward(x)\n",
    "        psi = dot(self.W,f(j,i,x,t))\n",
    "        psi_b = np.array([dot(self.W,f(k,0,x,0)) for k in range(self.L)])\n",
    "        log_joint = alphas[t-1][i] + psi + betas[t][j] - log_sum_exp(psi_b + betas[0])\n",
    "        \n",
    "        return exp(log_joint)\n",
    "                       \n",
    "    def naive_comp(self, x, out='Z'):\n",
    "        '''Brute force computation of log(Z(x)) or MAP (if out = 'MAP')'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]\n",
    "        \n",
    "        # Get List of all possible label sequences\n",
    "        \n",
    "        lab_seq = label_seq(T, self.L)\n",
    "        \n",
    "        psi = np.zeros(len(lab_seq))\n",
    "        \n",
    "        for k in range(len(lab_seq)):\n",
    "            \n",
    "            lab = lab_seq[k]\n",
    "            temp = np.zeros(T)\n",
    "            temp[0] = dot(self.W, f(lab[0], 0, x, 0))\n",
    "            \n",
    "            for t in range(1,T):\n",
    "                \n",
    "                temp[t] = dot(self.W, f(lab[t], lab[t-1], x, t))\n",
    "            \n",
    "            psi[k] = temp.sum()\n",
    "        \n",
    "        arg_m_i = psi.argmax()\n",
    "        \n",
    "        return log_sum_exp(psi) if out == 'Z' else lab_seq[arg_m_i]\n",
    "        \n",
    "    \n",
    "    def log_pseudo_marg(self, i, j, k, x, t):\n",
    "        '''Computes the log probability for pseudolikelihood training.\n",
    "            i = y_t\n",
    "            j = y_t-1\n",
    "            k = y_t+1'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        Z_c = np.zeros(self.L)\n",
    "        unary_l = [f(l,0,x,t)[0] for l in range(self.L)]\n",
    "        W = self.W[1:]\n",
    "        if t == 0:\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                Z_c[l] = unary_l[l] + W[26*k + l]\n",
    "            \n",
    "            return unary_l[i] + W[26*k + i] - log_sum_exp(Z_c)\n",
    "        \n",
    "        elif 0 < t and t < x.shape[0]-1:\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                Z_c[l] = unary_l[l] + W[26*l + j] + W[26*k + l]\n",
    "            \n",
    "            return unary_l[i] + W[26*k + i] + W[26*i + j] - log_sum_exp(Z_c)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                Z_c[l] =  Z_c[l] = unary_l[l] + W[26*l + j]\n",
    "            \n",
    "            return unary_l[i] + W[26*i + j] - log_sum_exp(Z_c)\n",
    "            \n",
    "    def grad_pll(self, X, Y):\n",
    "        \n",
    "        f = self.f_x\n",
    "        lb = self.Lambda\n",
    "        grad = np.zeros(self.K-1)\n",
    "        \n",
    "        for n in range(X.shape[0]):\n",
    "            \n",
    "            T_n = X[n].shape[0]\n",
    "            \n",
    "            for t in range(T_n):\n",
    "                \n",
    "                E = np.zeros(self.K-1)\n",
    "                \n",
    "                for l in range(self.L):\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        \n",
    "                        E += np.exp(self.log_pseudo_marg(l,0,Y[n][t+1],X[n],0)) * f(Y[n][t+1],l,X[n],0)[1:]\n",
    "                        \n",
    "                    elif 0 < t and t < T_n - 1:\n",
    "                        \n",
    "                        E += np.exp(self.log_pseudo_marg(l,Y[n][t-1],Y[n][t+1],X[n],t))*(f(Y[n][t+1],l,X[n],t)[1:] +\n",
    "                                                  f(l,Y[n][t-1],X[n],t)[1:])\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        E += np.exp(self.log_pseudo_marg(l,Y[n][t-1],0,X[n],t)) * f(l,Y[n][t-1],X[n],t)[1:]\n",
    "                        \n",
    "                if t == 0:\n",
    "                    \n",
    "                    grad += f(Y[n][t+1], Y[n][t],X[n],t)[1:]-E\n",
    "                    \n",
    "                elif 0 < t and t < T_n-1:\n",
    "                    \n",
    "                    grad += f(Y[n][t+1], Y[n][t],X[n],t)[1:]+f(Y[n][t], Y[n][t-1],X[n],t)[1:]-E\n",
    "                    \n",
    "                else: \n",
    "                    \n",
    "                    grad += f(Y[n][t], Y[n][t-1],X[n],t)[1:]-E\n",
    "                    \n",
    "        return lb * self.W[1:] - grad\n",
    "        \n",
    "    \n",
    "    \n",
    "    def gradient(self, X, Y):\n",
    "        ''' Creates the gradient vector of the log-likelihood. \n",
    "            X, Y: Are arrays containing training examples.'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        lamb = self.Lambda\n",
    "        grad = np.zeros(self.K)\n",
    "        \n",
    "        for k in range(self.K):\n",
    "            \n",
    "            val_pair = find_legit_vals(k, self.L, X.shape[-1])\n",
    "            first_term = np.zeros((X.shape[0],T))\n",
    "            \n",
    "            for n in range(X.shape[0]):\n",
    "                \n",
    "                T = X[n].shape[0]\n",
    "                for t in range(T):\n",
    "                    \n",
    "                    first_term[n][t] = f(Y[n][t], Y[n][t-1], X[n], t, project=k)\n",
    "            \n",
    "            sec_term = np.zeros((X.shape[0],self.T))\n",
    "            \n",
    "            for n in range(X.shape[0]):\n",
    "                \n",
    "                for t in range(T):\n",
    "                    \n",
    "                    marginals = np.zeros(len(val_pair))\n",
    "                        \n",
    "                    for j in range(len(val_pair)):\n",
    "                        \n",
    "                        y, y_p = val_pair[j]\n",
    "                        marginals[j] = (f(y, y_p, X[n], t, project=k) * \n",
    "                                        self.marginal(y, y_p, X[n], t))\n",
    "                    \n",
    "                    sec_term[n][t] = marginals.sum()\n",
    "                    \n",
    "            grad[k] = (first_term + sec_term).sum() - self.W[k] * lamb\n",
    "            print(k)\n",
    "        return grad\n",
    "    \n",
    "    \n",
    "    def gradient_f(self, X, Y):\n",
    "        \n",
    "        f = self.f_x\n",
    "        lamb = self.Lambda\n",
    "        grad_f = np.zeros(self.K)\n",
    "        lab_pairs = label_seq(2,self.L)\n",
    "        \n",
    "        for n in range(X.shape[0]):\n",
    "            \n",
    "            T = X[n].shape[0]\n",
    "            grad = np.zeros(self.K)\n",
    "            x, y = X[n], Y[n]\n",
    "            \n",
    "            for t in range(T):\n",
    "            \n",
    "                grad = grad + f(y[t],y[t-1],x,t)\n",
    "        \n",
    "            for pair in lab_pairs:\n",
    "                print(pair)\n",
    "                y, y_p = pair[0], pair[1]\n",
    "                grad_temp = np.zeros(self.K)\n",
    "            \n",
    "                for t in range(T):\n",
    "                \n",
    "                    marg = self.marginal(y,y_p,x,t)\n",
    "                    grad_temp = grad_temp + (marg*f(y,y_p,x,t))\n",
    "        \n",
    "                grad = grad - grad_temp\n",
    "            \n",
    "            grad_f = grad_f + grad\n",
    "    \n",
    "        return lamb * self.W  - grad_f\n",
    "    \n",
    "    def reg_neg_ll(self, X, Y):\n",
    "        \n",
    "        f = self.f_x\n",
    "        res = 0\n",
    "        for n in range(X.shape[0]):\n",
    "            \n",
    "            T = X[n].shape[0]\n",
    "            s = 0\n",
    "            \n",
    "            for t in range(T):\n",
    "            \n",
    "                s += np.dot(self.W,f(Y[n][t],Y[n][t-1],X[n],t))\n",
    "            \n",
    "            res += self.log_partition(X[n]) - s\n",
    "         \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/james/anaconda3/data/HW/OCR/letter/data.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>n</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>i</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>n</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>g</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>o</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>m</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>m</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>a</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>n</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>d</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2    3    4    5    6    7    8    9   ...   125  126  127  128  \\\n",
       "0     1   o    2    1    1    0    0    0    0    0 ...     0    0    0    0   \n",
       "1     2   m    3    1    2    0    0    0    0    0 ...     0    0    0    0   \n",
       "2     3   m    4    1    3    0    0    0    0    0 ...     0    0    0    0   \n",
       "3     4   a    5    1    4    0    0    0    0    0 ...     0    0    0    0   \n",
       "4     5   n    6    1    5    0    0    0    0    0 ...     0    0    0    0   \n",
       "5     6   d    7    1    6    0    0    0    0    0 ...     1    0    0    0   \n",
       "6     7   i    8    1    7    0    0    0    0    0 ...     0    0    0    1   \n",
       "7     8   n    9    1    8    0    0    0    0    0 ...     0    0    0    0   \n",
       "8     9   g   -1    1    9    0    0    1    1    1 ...     0    0    0    0   \n",
       "9    10   o   11    2    1    7    0    0    0    0 ...     0    0    0    0   \n",
       "10   11   m   12    2    2    7    0    0    0    0 ...     0    0    0    0   \n",
       "11   12   m   13    2    3    7    0    0    0    0 ...     0    0    0    0   \n",
       "12   13   a   14    2    4    7    0    0    0    0 ...     0    0    0    0   \n",
       "13   14   n   15    2    5    7    0    0    0    0 ...     0    0    0    0   \n",
       "14   15   d   16    2    6    7    0    0    0    0 ...     1    0    0    0   \n",
       "\n",
       "    129  130  131  132  133  134  \n",
       "0     0    0    0    0    0  NaN  \n",
       "1     0    0    0    0    0  NaN  \n",
       "2     0    0    0    0    0  NaN  \n",
       "3     0    0    0    0    0  NaN  \n",
       "4     0    0    0    0    0  NaN  \n",
       "5     0    0    0    0    0  NaN  \n",
       "6     0    0    0    0    0  NaN  \n",
       "7     0    0    0    0    0  NaN  \n",
       "8     0    0    1    0    0  NaN  \n",
       "9     0    0    0    0    0  NaN  \n",
       "10    0    0    0    0    0  NaN  \n",
       "11    0    0    0    0    0  NaN  \n",
       "12    0    0    0    0    0  NaN  \n",
       "13    0    0    0    0    0  NaN  \n",
       "14    0    0    0    0    0  NaN  \n",
       "\n",
       "[15 rows x 135 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = data.ix[11004].as_matrix()[6:-1]\n",
    "data_m = data.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = np.asarray(im.reshape((16,8)),dtype='i4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f68dc0b6d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAD8CAYAAACchf2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhUVCCouEFBYJKSwSUlgkpLD4LwQLR1CqZHqJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68dc82d630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.int32(X_tr[-2][0].reshape((16,8))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_data = []\n",
    "label_data = []\n",
    "\n",
    "start = 0\n",
    "\n",
    "for k in range(1,52152):\n",
    "    \n",
    "    if data_m[k,4] < data_m[k-1,4]:\n",
    "        \n",
    "        word_data.append(data_m[start:k,6:-1])\n",
    "        label_data.append(data_m[start:k,1])\n",
    "        start = k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_n, y_n = np.zeros((52152,128)), np.zeros((52152,26), dtype='int32')\n",
    "\n",
    "for k in range(52152):\n",
    "    X_n[k] = data_m[k,6:-1]\n",
    "    y_n[k,ord(str(data_m[k,1]))-97] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6876,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_d = np.array(word_data)\n",
    "wd_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vl = wd_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vl = []\n",
    "\n",
    "for k in label_data:\n",
    "    \n",
    "    y_vl.append(encode(k))\n",
    "\n",
    "y_vl = np.array(y_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  2, 14, 13, 18,  4, 16, 20,  4, 13, 19,  8,  0, 11], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vl[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', 'c', 'o', 'n', 's', 'e', 'q', 'u', 'e', 'n', 't', 'i', 'a', 'l'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_n[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(a):\n",
    "    res = np.zeros(len(a), dtype='i4')\n",
    "    for k in range(len(a)):\n",
    "        res[k] = ord(a[k]) - 97\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func(i,j,x,t):\n",
    "    \n",
    "    N = 128                     # Twice the length of data vector\n",
    "    L = 26                         # number of labels\n",
    "    T = 14                          # length of sequence\n",
    "    \n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    unary_chi = unary_model1.predict(x[t].reshape((1,128)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = np.arange(6876)\n",
    "np.random.shuffle(dims)\n",
    "\n",
    "X_tr, y_tr = X_vl[dims[:-676]], y_vl[dims[:-676]]\n",
    "X_ts, y_ts = X_vl[dims[-676:]], y_vl[dims[-676:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6200,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(feat_func, 26**2+1,26,lamb=3, W='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.358306067904895"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.log_pseudo_marg(1,1,1,X_tr[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.0170433 ,  13.98363357,  15.98735387,  15.6663122 ,\n",
       "         7.11589492,  11.20540012,  14.20762575,   6.45963354,\n",
       "        17.46031956,   6.73833861,  12.29407045,  18.03951835,\n",
       "        15.00426585,  23.58519753,   2.89297034,  14.3285808 ,\n",
       "         3.21000409,  19.3483152 ,  18.82247743,  20.01563854,\n",
       "        13.19381771,  14.16106772,  10.86086251,   8.66131703,\n",
       "        15.41231757,   6.16130034,  13.55061437,   6.04598046,\n",
       "        -0.92999654,  -1.13987186,  16.59907135,  -9.09000072,\n",
       "        -9.96000036,  -4.64978003,  12.15773358])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#g = crf.grad_pll(X_tr[:16],y_tr[:16])\n",
    "\n",
    "g[:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score:  95.2857142857 %.\n",
      "Compared to Unary Only:  89.4004329004 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 5 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 10 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 15 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 20 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 25 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 30 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 35 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 40 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 45 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 50 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 55 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 60 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 65 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 70 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 75 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 80 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 85 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 90 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  1 / 95 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  2 / 96 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  2 / 101 . Current Average Test Hamming Accuracy:  95.2857142857 %.\n",
      "Epoch/Iteration:  2 / 106 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 111 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 116 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 121 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 126 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 131 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 136 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 141 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 146 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 151 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 156 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n",
      "Epoch/Iteration:  2 / 161 . Current Average Test Hamming Accuracy:  94.9153439153 %.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-2ab08ff6fac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_pll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mB1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mB2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-c7ac599764e3>\u001b[0m in \u001b[0;36mgrad_pll\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                         \u001b[0mE\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_pseudo_marg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mT_n\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-c7ac599764e3>\u001b[0m in \u001b[0;36mlog_pseudo_marg\u001b[0;34m(self, i, j, k, x, t)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mZ_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0munary_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-c7ac599764e3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mZ_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0munary_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-f07abfe9cb47>\u001b[0m in \u001b[0;36mfeat_func\u001b[0;34m(i, j, x, t)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbinary_chi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0munary_chi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munary_model1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1197\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "\n",
    "from scipy.spatial.distance import hamming \n",
    "\n",
    "crf = CRF(feat_func,26**2+1,26, 1e-12, W=best_W)\n",
    "crf_u = CRF(feat_func,26**2+1,26, 1, W='U')\n",
    "alpha = 0.01\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf.K-1), np.zeros(crf.K-1)\n",
    "#best_W = np.zeros(crf.K)\n",
    "#best_acc = 0\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "epoch = 1\n",
    "\n",
    "acc_t1, acc_tu = np.zeros(30), np.zeros(30)\n",
    "\n",
    "for n in range(30):\n",
    "    acc_t1[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "    acc_tu[n] = 1 - hamming(crf_u.MAP(X_ts[n]), y_ts[n])\n",
    "    \n",
    "print('Initial accuracy score: ',100* acc_t1.mean(), '%.')\n",
    "print('Compared to Unary Only: ', 100* acc_tu.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr[min_batch[k:k+batch_size]],y_tr[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf.W[1:] = crf.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 5 == 0:\n",
    "            \n",
    "            acc_test = np.zeros(30)\n",
    "            \n",
    "            for n in range(30):\n",
    "                acc_test[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc <= acc_test.mean():\n",
    "                best_acc = acc_test.mean()\n",
    "                best_W = crf.W\n",
    "        \n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc_f, acc_fu = np.zeros(X_ts.shape[0]), np.zeros(X_ts.shape[0])\n",
    "\n",
    "for n in range(X_ts.shape[0]):\n",
    "    acc_f[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "    acc_fu[n] = 1 - hamming(crf_u.MAP(X_ts[n]), y_ts[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96121693121693119"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbb95ea3d68>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAABiCAYAAAA4COSFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb95efc080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(3,3,1)\n",
    "ax1.imshow(np.int32(X_tr[-2][0].reshape((16,8))))\n",
    "ax2 = fig.add_subplot(3,3,2)\n",
    "ax2.imshow(np.int32(X_tr[-2][1].reshape((16,8))))\n",
    "ax3 = fig.add_subplot(3,3,3)\n",
    "ax3.imshow(np.int32(X_tr[-2][2].reshape((16,8))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uzz\n"
     ]
    }
   ],
   "source": [
    "print(''.join([chr(let + 97) for let in crf.MAP(X_tr[-2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uzz\n"
     ]
    }
   ],
   "source": [
    "print(''.join([chr(let + 97) for let in y_tr[-2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test Hamming accuracy with only trained unary features:  94.7852332852 %.\n",
      "[1.04812081, 0.83590713, 0.36205899]\n",
      "-0.396999118882\n",
      "[ 1.04191886  0.84210908  0.35585704]\n",
      "Iteration:  0 . Current Average Test Hamming Accuracy:  94.7852332852 %.\n",
      "-0.0766653254679\n",
      "[ 1.04320261  0.84339283  0.35457329]\n",
      "0.0958462803525\n",
      "[ 1.04153159  0.84506385  0.35290227]\n",
      "0.0728119366489\n",
      "[ 1.04022552  0.84636992  0.3515962 ]\n",
      "-0.241988192441\n",
      "[ 1.03578855  0.84193295  0.34715923]\n",
      "0.323152990521\n",
      "[ 1.02975689  0.84796462  0.34112756]\n",
      "0.252519455048\n",
      "[ 1.03454127  0.85274901  0.33634318]\n",
      "-0.217801923849\n",
      "[ 1.03872141  0.85692914  0.33216304]\n",
      "-0.0754120718506\n",
      "[ 1.03725762  0.85546536  0.33069926]\n",
      "-0.0951065165789\n",
      "[ 1.03912232  0.85733006  0.32883456]\n",
      "0.105234027837\n",
      "[ 1.03704034  0.85524808  0.32675258]\n",
      "Iteration:  10 . Current Average Test Hamming Accuracy:  94.309042809 %.\n",
      "-0.0862478016505\n",
      "[ 1.03876073  0.85696847  0.32503219]\n",
      "0.152279466811\n",
      "[ 1.04182109  0.85390811  0.32197183]\n",
      "-0.0888929890331\n",
      "[ 1.04361993  0.85210927  0.32017299]\n",
      "-0.185126392072\n",
      "[ 1.03984976  0.8483391   0.31640282]\n",
      "0.0731076414194\n",
      "[ 1.04134747  0.84983681  0.31490511]\n",
      "0.235898838786\n",
      "[ 1.03648795  0.84497729  0.31004558]\n",
      "0.00208427959979\n",
      "[ 1.0365311   0.84502045  0.31000242]\n",
      "-0.151497544867\n",
      "[ 1.03968349  0.84817283  0.30685004]\n",
      "0.07019231102\n",
      "[ 1.04115078  0.84964012  0.30538275]\n",
      "-0.176787815485\n",
      "[ 1.03743916  0.8459285   0.30167113]\n",
      "Iteration:  20 . Current Average Test Hamming Accuracy:  94.309042809 %.\n",
      "-0.102474633583\n",
      "[ 1.03527887  0.84376822  0.29951085]\n",
      "-0.261836899115\n",
      "[ 1.02973747  0.83822681  0.29396944]\n",
      "0.0127715893389\n",
      "[ 1.02946617  0.83795551  0.29424073]\n",
      "0.102463040836\n",
      "[ 1.02728191  0.84013976  0.29205648]\n",
      "-0.0869723352736\n",
      "[ 1.02542161  0.84200006  0.29019618]\n",
      "0.102070112998\n",
      "[ 1.02323133  0.83980978  0.28800589]\n",
      "0.107734408234\n",
      "[ 1.02555031  0.84212876  0.28568691]\n",
      "-0.122152712064\n",
      "[ 1.02818744  0.83949163  0.28304978]\n",
      "0.0753001069578\n",
      "[ 1.02655718  0.84112189  0.28141952]\n",
      "-0.163274585059\n",
      "[ 1.03010176  0.83757731  0.27787495]\n",
      "Iteration:  30 . Current Average Test Hamming Accuracy:  94.309042809 %.\n",
      "0.240873507968\n",
      "[ 1.03534468  0.83233439  0.27263202]\n",
      "-0.110459363657\n",
      "[ 1.03775506  0.83474476  0.27022164]\n",
      "-0.137216014488\n",
      "[ 1.04075659  0.83174323  0.26722011]\n",
      "-0.145567694647\n",
      "[ 1.03756489  0.82855153  0.26402842]\n",
      "0.116185256275\n",
      "[ 1.04011813  0.83110476  0.26147518]\n",
      "-0.17200543655\n",
      "[ 1.04390632  0.83489295  0.25768699]\n",
      "0.048736454512\n",
      "[ 1.04498194  0.83596858  0.25661136]\n",
      "-0.112682814967\n",
      "[ 1.04747397  0.83347655  0.25411934]\n",
      "0.154232219745\n",
      "[ 1.05089163  0.83689422  0.25070168]\n",
      "0.246815602555\n",
      "[ 1.04541191  0.83141449  0.24522195]\n",
      "Iteration:  40 . Current Average Test Hamming Accuracy:  94.1661856662 %.\n",
      "-0.119582965336\n",
      "[ 1.04807178  0.82875462  0.24256208]\n",
      "0.0731370565409\n",
      "[ 1.04644207  0.83038433  0.24093237]\n",
      "-0.128684546866\n",
      "[ 1.04931455  0.82751185  0.23805989]\n",
      "0.1681946407\n",
      "[ 1.05307534  0.82375106  0.2342991 ]\n",
      "-0.0971238391829\n",
      "[ 1.05525058  0.82157583  0.23212386]\n",
      "-0.056052426417\n",
      "[ 1.05650796  0.82031844  0.23086648]\n",
      "-0.115453406029\n",
      "[ 1.05391405  0.81772453  0.22827257]\n",
      "-0.086021616317\n",
      "[ 1.05584963  0.81966011  0.22633699]\n",
      "0.063990981327\n",
      "[ 1.05440765  0.81821813  0.22489502]\n",
      "0.0874640186556\n",
      "[ 1.05638139  0.82019187  0.22292128]\n",
      "Iteration:  50 . Current Average Test Hamming Accuracy:  94.1661856662 %.\n",
      "-0.155054658758\n",
      "[ 1.05287752  0.82369574  0.21941741]\n",
      "-0.0440116101224\n",
      "[ 1.05387342  0.82469164  0.21842151]\n",
      "-0.0369835128105\n",
      "[ 1.0547114   0.82552961  0.21758353]\n",
      "0.0482161654605\n",
      "[ 1.05361751  0.8266235   0.21648965]\n",
      "0.137394836676\n",
      "[ 1.05049653  0.82350251  0.21336867]\n",
      "0.0946900019061\n",
      "[ 1.05265008  0.82134896  0.21121512]\n",
      "0.0300272346465\n",
      "[ 1.0533338   0.82203269  0.21053139]\n",
      "0.143723985259\n",
      "[ 1.05005739  0.81875628  0.20725499]\n",
      "-0.15332357393\n",
      "[ 1.05355659  0.82225548  0.20375579]\n",
      "-0.138397247019\n",
      "[ 1.05671861  0.8254175   0.20059377]\n",
      "Iteration:  60 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "0.0415367659316\n",
      "[ 1.05766864  0.82636753  0.19964374]\n",
      "-0.118283016263\n",
      "[ 1.06037685  0.82365932  0.19693553]\n",
      "-0.0738319679806\n",
      "[ 1.05868466  0.82535151  0.19524333]\n",
      "-0.0671937214818\n",
      "[ 1.05714307  0.82380992  0.19370174]\n",
      "-0.0671910494183\n",
      "[ 1.05560004  0.82226689  0.19215871]\n",
      "-0.19326728559\n",
      "[ 1.06004263  0.81782429  0.18771611]\n",
      "0.0414669385944\n",
      "[ 1.06099672  0.81687021  0.18676203]\n",
      "0.0543001861877\n",
      "[ 1.06224721  0.8181207   0.18551154]\n",
      "0.0463253728065\n",
      "[ 1.06117942  0.81705291  0.18444375]\n",
      "-0.175208564838\n",
      "[ 1.06522145  0.82109494  0.18040173]\n",
      "Iteration:  70 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "0.117137948234\n",
      "[ 1.0625168   0.81839029  0.17769708]\n",
      "0.0655203317824\n",
      "[ 1.06403088  0.81990438  0.17618299]\n",
      "0.0207349038465\n",
      "[ 1.06451043  0.81942483  0.17570345]\n",
      "-0.140875326427\n",
      "[ 1.06777111  0.81616415  0.17244277]\n",
      "-0.161156564388\n",
      "[ 1.07150412  0.81243114  0.16870976]\n",
      "-0.0710879887046\n",
      "[ 1.07315205  0.81078321  0.16706183]\n",
      "-0.0782272092013\n",
      "[ 1.07133727  0.81259799  0.16524705]\n",
      "0.0638373520281\n",
      "[ 1.0728193   0.81111596  0.16376503]\n",
      "0.0362297206486\n",
      "[ 1.0719776   0.81027426  0.16292333]\n",
      "-0.0580234934383\n",
      "[ 1.07332656  0.81162322  0.16157437]\n",
      "Iteration:  80 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "-0.0754921385046\n",
      "[ 1.07157028  0.80986695  0.1598181 ]\n",
      "-0.0681396988965\n",
      "[ 1.07315657  0.81145323  0.15823182]\n",
      "-0.0499189630684\n",
      "[ 1.0719937   0.8126161   0.15706895]\n",
      "-0.0457106797824\n",
      "[ 1.07092818  0.81368161  0.15600343]\n",
      "0.0570914653339\n",
      "[ 1.06959655  0.81501325  0.15467179]\n",
      "-0.0593547120152\n",
      "[ 1.07098182  0.81639853  0.15328652]\n",
      "-0.0763085044997\n",
      "[ 1.07276385  0.81818056  0.15150449]\n",
      "-0.114867778136\n",
      "[ 1.07007977  0.81549648  0.1488204 ]\n",
      "-0.0838822836675\n",
      "[ 1.06811859  0.81745766  0.14685922]\n",
      "0.0134825555959\n",
      "[ 1.06780319  0.81777306  0.14717462]\n",
      "Iteration:  90 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "0.0855903423301\n",
      "[ 1.06980654  0.81576971  0.14517127]\n",
      "0.0582550013237\n",
      "[ 1.06844227  0.81713398  0.143807  ]\n",
      "0.124447159209\n",
      "[ 1.0655263   0.82004994  0.14089104]\n",
      "-0.00260921020117\n",
      "[ 1.06546513  0.81998878  0.1409522 ]\n",
      "-0.0240427432631\n",
      "[ 1.06602906  0.82055271  0.14038827]\n",
      "0.0555526594925\n",
      "[ 1.06733272  0.81924905  0.13908461]\n",
      "-0.0657368223458\n",
      "[ 1.06578932  0.82079245  0.13754121]\n",
      "-0.02431889635\n",
      "[ 1.06521807  0.82022121  0.13811245]\n",
      "-0.00509917020099\n",
      "[ 1.06533791  0.82034104  0.13799262]\n",
      "-0.0297556474036\n",
      "[ 1.06603751  0.81964144  0.13729302]\n",
      "Iteration:  100 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "-0.104074574279\n",
      "[ 1.06358946  0.82208949  0.13484497]\n",
      "-0.0479624796385\n",
      "[ 1.06471813  0.82096082  0.1337163 ]\n",
      "0.0667433218121\n",
      "[ 1.06628944  0.81938951  0.13214499]\n",
      "-0.0977359140075\n",
      "[ 1.06398752  0.81708759  0.12984307]\n",
      "-0.0859536996284\n",
      "[ 1.06196226  0.81506234  0.13186833]\n",
      "-0.0140417952837\n",
      "[ 1.06163127  0.81473135  0.13219932]\n",
      "-0.0173483539415\n",
      "[ 1.06122218  0.81514044  0.13179022]\n",
      "0.0932742593675\n",
      "[ 1.06342254  0.8173408   0.12958987]\n",
      "0.0504129737176\n",
      "[ 1.06223284  0.8185305   0.12840016]\n",
      "0.0689745734998\n",
      "[ 1.06386118  0.81690215  0.12677182]\n",
      "Iteration:  110 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "0.0506321543872\n",
      "[ 1.06266543  0.81809791  0.12557606]\n",
      "0.0841147524644\n",
      "[ 1.06465263  0.8161107   0.12358886]\n",
      "-0.0875218449432\n",
      "[ 1.06258421  0.81404228  0.12565728]\n",
      "0.0161004780139\n",
      "[ 1.06296485  0.81366165  0.12527664]\n",
      "-0.00541704428622\n",
      "[ 1.06309296  0.81353354  0.12514853]\n",
      "0.0642884407926\n",
      "[ 1.06461383  0.81201267  0.12362766]\n",
      "0.126305042672\n",
      "[ 1.06162487  0.80902372  0.12063871]\n",
      "0.156609302509\n",
      "[ 1.06533213  0.80531647  0.11693146]\n",
      "-0.180871499558\n",
      "[ 1.06104922  0.80103356  0.11264856]\n",
      "0.0783715463542\n",
      "[ 1.06290556  0.8028899   0.11079222]\n",
      "Iteration:  120 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "-0.0147384555268\n",
      "[ 1.06255636  0.8032391   0.11044302]\n",
      "0.00122243366036\n",
      "[ 1.06252739  0.80321013  0.11047199]\n",
      "0.0480150112772\n",
      "[ 1.06366567  0.80207185  0.1093337 ]\n",
      "-0.119986317785\n",
      "[ 1.06651096  0.79922656  0.10648842]\n",
      "0.0453414588001\n",
      "[ 1.06543547  0.79815107  0.10756391]\n",
      "-0.0418749273299\n",
      "[ 1.06444194  0.79715754  0.10657038]\n",
      "0.0349443394494\n",
      "[ 1.06361263  0.79632824  0.10574107]\n",
      "0.0177619571051\n",
      "[ 1.063191    0.79674987  0.10616271]\n",
      "-0.0792212335714\n",
      "[ 1.06507203  0.79486884  0.10428168]\n",
      "-0.0742030484341\n",
      "[ 1.06330972  0.79663115  0.10251937]\n",
      "Iteration:  130 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0400960868254\n",
      "[ 1.06235722  0.79567865  0.10347187]\n",
      "0.0391653406969\n",
      "[ 1.06142662  0.79660925  0.10254126]\n",
      "-0.114720505079\n",
      "[ 1.05870014  0.79933573  0.09981479]\n",
      "0.0685425024742\n",
      "[ 1.0603295   0.79770637  0.09818543]\n",
      "0.0921683007566\n",
      "[ 1.06252095  0.79551492  0.09599398]\n",
      "0.0425435434281\n",
      "[ 1.0615092   0.79450317  0.09498223]\n",
      "0.146645606456\n",
      "[ 1.05802101  0.79101499  0.09149405]\n",
      "0.0330932889335\n",
      "[ 1.05880834  0.79022765  0.09228138]\n",
      "-0.0202910447633\n",
      "[ 1.05929119  0.78974481  0.09276422]\n",
      "0.0217363176851\n",
      "[ 1.05980852  0.78922748  0.09224689]\n",
      "Iteration:  140 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "0.0722051742382\n",
      "[ 1.05808969  0.79094631  0.09052805]\n",
      "0.105066828591\n",
      "[ 1.05558813  0.78844475  0.08802649]\n",
      "0.219964046057\n",
      "[ 1.05035003  0.78320665  0.08278839]\n",
      "-0.137101977793\n",
      "[ 1.05361546  0.77994122  0.07952296]\n",
      "-0.01991724347\n",
      "[ 1.053141    0.77946676  0.0790485 ]\n",
      "0.0691352310055\n",
      "[ 1.05149382  0.77781958  0.07740132]\n",
      "0.00242940873426\n",
      "[ 1.05143593  0.77776169  0.07745921]\n",
      "0.0173896482613\n",
      "[ 1.05185038  0.77734724  0.07787366]\n",
      "0.0214067041909\n",
      "[ 1.05134011  0.77683697  0.07838392]\n",
      "0.0470189199517\n",
      "[ 1.05246105  0.77571604  0.07726298]\n",
      "Iteration:  150 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "0.0146613850345\n",
      "[ 1.05281063  0.77606562  0.0769134 ]\n",
      "-0.0165614164655\n",
      "[ 1.05241569  0.77567068  0.07730834]\n",
      "0.0338960697417\n",
      "[ 1.05322412  0.77486225  0.07649991]\n",
      "-0.0017171447214\n",
      "[ 1.05326508  0.77490321  0.07654087]\n",
      "0.00437830718579\n",
      "[ 1.05336953  0.77479876  0.07643642]\n",
      "-0.0230609649022\n",
      "[ 1.05281931  0.77534898  0.07698664]\n",
      "0.0641990197608\n",
      "[ 1.05128738  0.77381704  0.07545471]\n",
      "0.0786441412033\n",
      "[ 1.05316422  0.77569389  0.07357786]\n",
      "-0.00199641871529\n",
      "[ 1.05321188  0.77574154  0.07362551]\n",
      "-0.00219440618525\n",
      "[ 1.05326426  0.77568916  0.07367789]\n",
      "Iteration:  160 . Current Average Test Hamming Accuracy:  93.6106301106 %.\n",
      "0.0172097085692\n",
      "[ 1.05285341  0.77610001  0.07326704]\n",
      "-0.0988957944378\n",
      "[ 1.05049223  0.77846119  0.07090586]\n",
      "0.0992585710125\n",
      "[ 1.05286231  0.78083128  0.06853578]\n",
      "-0.018587845469\n",
      "[ 1.05241843  0.78038739  0.0680919 ]\n",
      "0.0563852868152\n",
      "[ 1.05376504  0.77904078  0.06674528]\n",
      "-0.0560237602529\n",
      "[ 1.05510315  0.77770267  0.06540717]\n",
      "0.00662344567559\n",
      "[ 1.05526136  0.77786088  0.06524896]\n",
      "0.0868039349377\n",
      "[ 1.05733499  0.77578725  0.06317533]\n",
      "0.0492875610835\n",
      "[ 1.0585125   0.77460974  0.06199782]\n",
      "0.109896698713\n",
      "[ 1.0558868   0.77198404  0.05937211]\n",
      "Iteration:  170 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0966423922846\n",
      "[ 1.0535776   0.76967484  0.05706291]\n",
      "-0.122047944681\n",
      "[ 1.05066114  0.77259129  0.05414646]\n",
      "0.0198514679099\n",
      "[ 1.05018674  0.77211689  0.05462086]\n",
      "0.0419270732688\n",
      "[ 1.04918471  0.77311892  0.05562288]\n",
      "0.0869071777237\n",
      "[ 1.04710756  0.77104177  0.05354574]\n",
      "0.0135670275765\n",
      "[ 1.04678328  0.77136605  0.05322146]\n",
      "0.0217895384159\n",
      "[ 1.04730413  0.7708452   0.05270061]\n",
      "-0.00926473492996\n",
      "[ 1.04708266  0.77106668  0.05292208]\n",
      "0.0321687792357\n",
      "[ 1.04785169  0.77029764  0.05369111]\n",
      "0.0106445627404\n",
      "[ 1.04759721  0.77055213  0.05394559]\n",
      "Iteration:  180 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.0222842056529\n",
      "[ 1.04706442  0.77001935  0.05341281]\n",
      "-0.0109201722629\n",
      "[ 1.04680333  0.77028044  0.05367391]\n",
      "-0.00377283688863\n",
      "[ 1.04689354  0.77037065  0.0535837 ]\n",
      "-0.0471376680505\n",
      "[ 1.04576641  0.77149778  0.05471083]\n",
      "0.0114218635475\n",
      "[ 1.04603953  0.77122466  0.05443771]\n",
      "-0.0823804516206\n",
      "[ 1.04406956  0.77319464  0.05640768]\n",
      "-0.0357161650547\n",
      "[ 1.04492367  0.77234052  0.05555357]\n",
      "-0.0106059554455\n",
      "[ 1.04517731  0.77259416  0.05529993]\n",
      "0.0373292818935\n",
      "[ 1.04607005  0.7734869   0.05619267]\n",
      "0.00186755035622\n",
      "[ 1.04611471  0.77344223  0.05623733]\n",
      "Iteration:  190 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0414291918203\n",
      "[ 1.04512387  0.7724514   0.05722817]\n",
      "-0.0490194108399\n",
      "[ 1.04395149  0.77127901  0.05605578]\n",
      "-0.0331269401684\n",
      "[ 1.04315918  0.7704867   0.05684809]\n",
      "0.0848204717894\n",
      "[ 1.04518785  0.77251538  0.05481941]\n",
      "-0.0198979380267\n",
      "[ 1.04471194  0.77299129  0.0543435 ]\n",
      "-0.0647332781441\n",
      "[ 1.04316366  0.77453957  0.05279522]\n",
      "0.000375210407356\n",
      "[ 1.04315468  0.77454855  0.05280419]\n",
      "0.00989662579696\n",
      "[ 1.04291797  0.77431184  0.0530409 ]\n",
      "-0.0689505016887\n",
      "[ 1.04456717  0.77266264  0.0546901 ]\n",
      "0.0882042257466\n",
      "[ 1.04245744  0.77055291  0.05679983]\n",
      "-0.024070113662\n",
      "[ 1.04188171  0.76997719  0.0562241 ]\n",
      "Iteration:  200 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0515227741912\n",
      "[ 1.04064935  0.76874483  0.05499174]\n",
      "-0.0227333994338\n",
      "[ 1.04119311  0.76820108  0.05553549]\n",
      "0.04114935627\n",
      "[ 1.04020887  0.76918531  0.05455126]\n",
      "-0.117891899086\n",
      "[ 1.03738908  0.7720051   0.05173147]\n",
      "-0.113472697438\n",
      "[ 1.03467501  0.76929103  0.05444554]\n",
      "-0.0508096831397\n",
      "[ 1.03345975  0.76807576  0.0556608 ]\n",
      "-0.0383020847875\n",
      "[ 1.03254365  0.76715967  0.0547447 ]\n",
      "-0.0786224227371\n",
      "[ 1.03442409  0.76904011  0.05286426]\n",
      "-0.0757237821641\n",
      "[ 1.032613    0.76722902  0.05105317]\n",
      "-0.0607384027797\n",
      "[ 1.03406566  0.76577636  0.04960051]\n",
      "Iteration:  210 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0315999556848\n",
      "[ 1.03330991  0.76502062  0.05035626]\n",
      "0.0684967383655\n",
      "[ 1.03494805  0.76338247  0.04871812]\n",
      "0.0993820546305\n",
      "[ 1.03257132  0.76100574  0.04634139]\n",
      "0.0305674149196\n",
      "[ 1.03330233  0.76173674  0.04561038]\n",
      "0.0601299653243\n",
      "[ 1.03474027  0.7602988   0.04417244]\n",
      "-0.0248807041778\n",
      "[ 1.03414529  0.76089378  0.04476742]\n",
      "0.0733106865775\n",
      "[ 1.03239225  0.76264682  0.04301438]\n",
      "-0.0174492290239\n",
      "[ 1.03197501  0.76222958  0.04343162]\n",
      "0.0356675295434\n",
      "[ 1.03282785  0.76137674  0.04257878]\n",
      "0.0262340137143\n",
      "[ 1.0322006   0.76200399  0.04195152]\n",
      "Iteration:  220 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.019444865165\n",
      "[ 1.03173568  0.76246891  0.04148661]\n",
      "0.0674011075423\n",
      "[ 1.03012424  0.76085746  0.03987517]\n",
      "0.0153551038502\n",
      "[ 1.03049134  0.76049036  0.04024227]\n",
      "0.0220072237764\n",
      "[ 1.03101745  0.75996425  0.04076838]\n",
      "-0.033359202441\n",
      "[ 1.03021999  0.75916679  0.04156584]\n",
      "-0.0427971935653\n",
      "[ 1.02919696  0.75814376  0.04258887]\n",
      "-0.0518486919754\n",
      "[ 1.0304363   0.75690441  0.04134953]\n",
      "-0.0593507740175\n",
      "[ 1.0290177   0.75832301  0.03993093]\n",
      "0.123109806384\n",
      "[ 1.02607529  0.7553806   0.04287335]\n",
      "0.083968324226\n",
      "[ 1.02406848  0.7573874   0.04086654]\n",
      "Iteration:  230 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.0509993447027\n",
      "[ 1.02284969  0.7586062   0.04208534]\n",
      "0.105787863924\n",
      "[ 1.02032167  0.75607818  0.03955733]\n",
      "0.0313518474973\n",
      "[ 1.02107085  0.75532901  0.03880815]\n",
      "-0.0919549314228\n",
      "[ 1.01887365  0.75752621  0.03661096]\n",
      "0.18204328758\n",
      "[ 1.0145241   0.75317667  0.0409605 ]\n",
      "-0.00247746535655\n",
      "[ 1.0145833   0.75323586  0.04090131]\n",
      "-0.0209653370202\n",
      "[ 1.01508416  0.75373672  0.04140217]\n",
      "-0.0327758070958\n",
      "[ 1.01586712  0.75451968  0.04061921]\n",
      "-0.0127153061521\n",
      "[ 1.01617085  0.75482342  0.04031548]\n",
      "0.00469972805899\n",
      "[ 1.0160586   0.75471116  0.04020322]\n",
      "Iteration:  240 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0815858835394\n",
      "[ 1.01411001  0.75276258  0.0421518 ]\n",
      "-0.0412312899891\n",
      "[ 1.01312532  0.75177788  0.04116711]\n",
      "0.11837097088\n",
      "[ 1.01029855  0.74895112  0.03834034]\n",
      "0.0861283756387\n",
      "[ 1.00824191  0.74689447  0.0362837 ]\n",
      "-0.136698503951\n",
      "[ 1.00497793  0.7436305   0.03301972]\n",
      "0.000139880528536\n",
      "[ 1.00498127  0.74362716  0.03301638]\n",
      "0.00298129190509\n",
      "[ 1.0049101   0.74355598  0.03294521]\n",
      "-0.00784413057795\n",
      "[ 1.00509735  0.74336873  0.03275796]\n",
      "-0.0161828000784\n",
      "[ 1.00471107  0.74375501  0.03314424]\n",
      "-4.01489319302e-06\n",
      "[ 1.00471117  0.74375511  0.03314434]\n",
      "Iteration:  250 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.144029683177\n",
      "[ 1.00127372  0.74031766  0.02970689]\n",
      "-0.0467440367768\n",
      "[ 1.00238924  0.74143318  0.02859138]\n",
      "-0.0164587323591\n",
      "[ 1.00199649  0.74104043  0.02819863]\n",
      "-0.0411434608857\n",
      "[ 1.00297819  0.74005874  0.02721694]\n",
      "0.0173802355552\n",
      "[ 1.00339285  0.73964407  0.0276316 ]\n",
      "0.0334058409685\n",
      "[ 1.00259591  0.74044101  0.02842854]\n",
      "0.0696199207675\n",
      "[ 1.00425664  0.73878028  0.02676781]\n",
      "0.0410722680773\n",
      "[ 1.00523631  0.73780062  0.02578815]\n",
      "0.0573934295301\n",
      "[ 1.00386747  0.73643178  0.02715698]\n",
      "-0.0936194835375\n",
      "[ 1.0061001   0.73866441  0.02492435]\n",
      "Iteration:  260 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.0343165219892\n",
      "[ 1.0069184   0.73784611  0.02410605]\n",
      "0.0704779537191\n",
      "[ 1.00523796  0.73616566  0.02242561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.123715557557\n",
      "[ 1.00228842  0.73321612  0.01947607]\n",
      "-0.00259392353439\n",
      "[ 1.00235025  0.73315429  0.01941423]\n",
      "-0.0698039922776\n",
      "[ 1.00068635  0.73149038  0.01775033]\n",
      "-0.0687565843358\n",
      "[ 0.99904757  0.7298516   0.01611155]\n",
      "0.0476961867396\n",
      "[ 0.99791087  0.7287149   0.01724825]\n",
      "0.0519895361008\n",
      "[ 0.99667196  0.727476    0.01600935]\n",
      "0.00151007790964\n",
      "[ 0.99670794  0.72751198  0.01604533]\n",
      "-0.0739809846715\n",
      "[ 0.99494534  0.72574937  0.01780793]\n",
      "Iteration:  270 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0109282081349\n",
      "[ 0.994685    0.72600971  0.01806827]\n",
      "0.0163939742952\n",
      "[ 0.99507551  0.72640022  0.01845878]\n",
      "0.0233643572487\n",
      "[ 0.99451902  0.72695671  0.01901527]\n",
      "-0.0363920638316\n",
      "[ 0.99365234  0.7278234   0.01988195]\n",
      "0.0714356487833\n",
      "[ 0.99195126  0.72612232  0.01818087]\n",
      "0.0085065072908\n",
      "[ 0.99174872  0.72632486  0.01797833]\n",
      "0.00292690927472\n",
      "[ 0.9918184   0.72639454  0.01790865]\n",
      "0.0479209782427\n",
      "[ 0.99067764  0.72525378  0.01904941]\n",
      "0.000289789705789\n",
      "[ 0.99067074  0.72526067  0.01905631]\n",
      "-0.0823733274369\n",
      "[ 0.98871026  0.7233002   0.02101678]\n",
      "Iteration:  280 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.0540439327506\n",
      "[ 0.98999636  0.7220141   0.01973069]\n",
      "0.0344521551439\n",
      "[ 0.98917658  0.72283388  0.01891091]\n",
      "0.0582459683474\n",
      "[ 0.9877908   0.72421966  0.0202967 ]\n",
      "0.106144077707\n",
      "[ 0.98526572  0.72169458  0.01777161]\n",
      "0.0175872978516\n",
      "[ 0.98568406  0.72127624  0.01735327]\n",
      "0.058400997125\n",
      "[ 0.98429507  0.72266523  0.01596428]\n",
      "0.0380409920166\n",
      "[ 0.98339042  0.72176058  0.01505963]\n",
      "0.02563716073\n",
      "[ 0.98400002  0.72237018  0.01445003]\n",
      "0.0476476668014\n",
      "[ 0.98286718  0.72123734  0.01331718]\n",
      "0.0338307640843\n",
      "[ 0.98367142  0.72204159  0.01251294]\n",
      "Iteration:  290 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.00427980733127\n",
      "[ 0.98377315  0.72214332  0.01261467]\n",
      "0.0400836169101\n",
      "[ 0.98472581  0.72309598  0.01356733]\n",
      "-0.00171411745475\n",
      "[ 0.98468508  0.72313671  0.0135266 ]\n",
      "0.00447876451733\n",
      "[ 0.98457866  0.72303029  0.01342018]\n",
      "0.0303322061\n",
      "[ 0.98385802  0.72230965  0.01414081]\n",
      "0.0945290848076\n",
      "[ 0.98161247  0.7200641   0.01189526]\n",
      "0.0693253358695\n",
      "[ 0.97996584  0.72171073  0.01024863]\n",
      "0.0304034198202\n",
      "[ 0.97924378  0.72098867  0.01097068]\n",
      "0.0386980914968\n",
      "[ 0.97832484  0.72006974  0.01005175]\n",
      "0.0366710499102\n",
      "[ 0.97745415  0.72094043  0.00918106]\n",
      "Iteration:  300 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0545753478409\n",
      "[ 0.97874978  0.72223606  0.01047669]\n",
      "-0.105738480292\n",
      "[ 0.97623985  0.71972612  0.00796676]\n",
      "-0.0196612930642\n",
      "[ 0.97577321  0.71925948  0.00750011]\n",
      "0.00916130599012\n",
      "[ 0.97599061  0.71947689  0.00728271]\n",
      "-0.0476190009584\n",
      "[ 0.97486071  0.72060679  0.00841261]\n",
      "0.0188490153449\n",
      "[ 0.97441352  0.72105398  0.00796542]\n",
      "-0.0475258316907\n",
      "[ 0.97328613  0.72218137  0.00683802]\n",
      "-0.0038113332439\n",
      "[ 0.97319573  0.72227177  0.00674762]\n",
      "0.0318088200816\n",
      "[ 0.97395009  0.72302613  0.00750198]\n",
      "-0.0218226765146\n",
      "[ 0.97343262  0.72250867  0.00698452]\n",
      "Iteration:  310 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0926779476872\n",
      "[ 0.97123532  0.72031136  0.00478722]\n",
      "-0.0357566438886\n",
      "[ 0.97208296  0.71946372  0.00393958]\n",
      "0.0112608024644\n",
      "[ 0.97234987  0.71919681  0.00420649]\n",
      "-0.0105359682428\n",
      "[ 0.97210018  0.71894712  0.00445618]\n",
      "0.0498940134374\n",
      "[ 0.97091788  0.71776483  0.00327389]\n",
      "-0.0568007910114\n",
      "[ 0.96957211  0.7191106   0.00461966]\n",
      "-5.43976414065e-05\n",
      "[ 0.96957083  0.71910931  0.00462095]\n",
      "-0.148202452402\n",
      "[ 0.96606047  0.71559895  0.0081313 ]\n",
      "0.036375350226\n",
      "[ 0.96692195  0.71473748  0.00726983]\n",
      "-0.00524003046689\n",
      "[ 0.96704603  0.71486156  0.00739391]\n",
      "Iteration:  320 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.063467924442\n",
      "[ 0.96554335  0.71335888  0.00889659]\n",
      "0.0280401571072\n",
      "[ 0.96487956  0.71269509  0.00956038]\n",
      "0.000815442292605\n",
      "[ 0.96486026  0.71271439  0.00957968]\n",
      "0.0322722989441\n",
      "[ 0.9640965   0.71195063  0.00881592]\n",
      "-0.013180273603\n",
      "[ 0.96440838  0.71226251  0.00850404]\n",
      "0.0384219785958\n",
      "[ 0.96531741  0.71135348  0.00759501]\n",
      "-0.102736900068\n",
      "[ 0.96774774  0.70892315  0.00516468]\n",
      "0.0264359180651\n",
      "[ 0.96837301  0.70829788  0.00578995]\n",
      "0.013778752885\n",
      "[ 0.96804716  0.70862373  0.0054641 ]\n",
      "-0.0493275046261\n",
      "[ 0.96688079  0.7097901   0.00663047]\n",
      "Iteration:  330 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "0.0267374896264\n",
      "[ 0.96751291  0.70915798  0.0072626 ]\n",
      "0.0100787536617\n",
      "[ 0.96727467  0.70939622  0.00750084]\n",
      "-0.0217405279676\n",
      "[ 0.96676083  0.70888239  0.00801468]\n",
      "-0.0182624597658\n",
      "[ 0.96632926  0.70845082  0.00758311]\n",
      "0.0530850882876\n",
      "[ 0.96507498  0.70719653  0.0088374 ]\n",
      "0.0210982184161\n",
      "[ 0.96557341  0.70769496  0.00933583]\n",
      "0.0826486166372\n",
      "[ 0.96752563  0.70574274  0.01128806]\n",
      "0.0981475895817\n",
      "[ 0.9698436   0.70342477  0.00897009]\n",
      "-0.0224009642131\n",
      "[ 0.96931463  0.7028958   0.00844112]\n",
      "-0.0140473230332\n",
      "[ 0.96898298  0.70322746  0.00877278]\n",
      "Iteration:  340 . Current Average Test Hamming Accuracy:  93.9136604137 %.\n",
      "-0.049654378067\n",
      "[ 0.97015514  0.7020553   0.00760061]\n",
      "0.127677644784\n",
      "[ 0.96714159  0.69904175  0.01061416]\n",
      "0.0155782245656\n",
      "[ 0.96677396  0.69867412  0.01098179]\n",
      "-0.0428317951686\n",
      "[ 0.9677846   0.69968476  0.00997116]\n",
      "-0.0097948144803\n",
      "[ 0.96801567  0.69945368  0.00974008]\n",
      "-0.000726981128878\n",
      "[ 0.96803282  0.69943653  0.00972293]\n",
      "0.0208715513506\n",
      "[ 0.96754058  0.69992878  0.00923069]\n",
      "0.136056459059\n",
      "[ 0.96433226  0.69672046  0.00602237]\n",
      "0.0499638047716\n",
      "[ 0.96315426  0.69554246  0.00484437]\n",
      "0.0430685729156\n",
      "[ 0.96416953  0.69655773  0.0038291 ]\n",
      "Iteration:  350 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.00850254031025\n",
      "[ 0.96436993  0.69635733  0.0036287 ]\n",
      "-0.00366013620305\n",
      "[ 0.96428368  0.69644358  0.00354244]\n",
      "-0.0247901627608\n",
      "[ 0.96486779  0.69702769  0.00412655]\n",
      "0.0116697149876\n",
      "[ 0.96514271  0.69730261  0.00385163]\n",
      "-0.015561062047\n",
      "[ 0.96477617  0.69766914  0.0034851 ]\n",
      "-0.00439518074916\n",
      "[ 0.96467266  0.69777266  0.00338159]\n",
      "0.00938946826187\n",
      "[ 0.96445157  0.69799375  0.00316049]\n",
      "0.0106925267372\n",
      "[ 0.96419983  0.69774201  0.00290875]\n",
      "0.0614175705116\n",
      "[ 0.9627541   0.69629628  0.00146302]\n",
      "0.0472913472622\n",
      "[  9.63867126e-01   6.97409309e-01   3.49987982e-04]\n",
      "Iteration:  360 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0830920965431\n",
      "[ 0.96191182  0.695454    0.00230529]\n",
      "-0.0236457876516\n",
      "[ 0.96246816  0.69489767  0.00174896]\n",
      "-0.0321652342336\n",
      "[ 0.9617115   0.69565432  0.0009923 ]\n",
      "-0.0101971060943\n",
      "[ 0.96195134  0.69589416  0.00123214]\n",
      "0.00901111675785\n",
      "[ 0.96216325  0.69568225  0.00102023]\n",
      "-0.0141289133301\n",
      "[  9.62495453e-01   6.96014460e-01   6.88022341e-04]\n",
      "-0.0123881373784\n",
      "[  9.62204225e-01   6.95723232e-01   3.96794552e-04]\n",
      "-0.0221765390784\n",
      "[  9.62725478e-01   6.96244485e-01  -1.24458435e-04]\n",
      "-0.0286302017903\n",
      "[  9.62052645e-01   6.96917317e-01   5.48374127e-04]\n",
      "0.0727860662487\n",
      "[ 0.96376289  0.69520707 -0.00116187]\n",
      "Iteration:  370 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0211402270077\n",
      "[ 0.96425954  0.69471043 -0.00165852]\n",
      "0.0723614444665\n",
      "[ 0.96595924  0.69641012 -0.00335822]\n",
      "-0.094096967919\n",
      "[ 0.96816911  0.69420025 -0.00556809]\n",
      "-0.0043895777124\n",
      "[ 0.96827218  0.69430332 -0.00546502]\n",
      "-0.0708074412999\n",
      "[ 0.96993454  0.69596568 -0.00380266]\n",
      "0.0845144442519\n",
      "[ 0.96795072  0.69398186 -0.00578649]\n",
      "0.0563892621316\n",
      "[ 0.96662731  0.69265844 -0.00446307]\n",
      "-0.0675271393724\n",
      "[ 0.96821185  0.6910739  -0.00287853]\n",
      "0.0267525208498\n",
      "[ 0.96883949  0.69170155 -0.00225089]\n",
      "0.0252524533419\n",
      "[ 0.96943185  0.6911092  -0.00165853]\n",
      "Iteration:  380 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0333014491387\n",
      "[ 0.96865082  0.69189023 -0.00243956]\n",
      "-0.0296153466356\n",
      "[ 0.96795636  0.69258468 -0.0017451 ]\n",
      "-0.0550309747128\n",
      "[ 0.96666615  0.69129447 -0.00303531]\n",
      "0.0821897525441\n",
      "[ 0.96473953  0.68936785 -0.00496194]\n",
      "0.0173648080105\n",
      "[ 0.96433255  0.68977483 -0.00455496]\n",
      "-0.013227991331\n",
      "[ 0.96464252  0.6900848  -0.00486493]\n",
      "-0.0307793676504\n",
      "[ 0.96536378  0.69080606 -0.00558618]\n",
      "0.0473493582617\n",
      "[ 0.96425443  0.6919154  -0.00669553]\n",
      "0.0396232253408\n",
      "[ 0.96332626  0.69284357 -0.00576736]\n",
      "0.000787167183262\n",
      "[ 0.96330782  0.69286201 -0.00574892]\n",
      "0.0289659603156\n",
      "[ 0.96262953  0.69218372 -0.00642721]\n",
      "Iteration:  390 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0444372359755\n",
      "[ 0.96158914  0.69114333 -0.00538682]\n",
      "-0.0372332049891\n",
      "[ 0.96246071  0.6920149  -0.00451524]\n",
      "0.0323982811141\n",
      "[ 0.96170245  0.69125664 -0.00375698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0214287363585\n",
      "[ 0.96220389  0.6907552  -0.00325554]\n",
      "0.0431392622422\n",
      "[ 0.96321319  0.6897459  -0.00426483]\n",
      "-0.0695356229726\n",
      "[ 0.96483977  0.68811932 -0.00263825]\n",
      "-0.0503781917097\n",
      "[ 0.96601802  0.68694107 -0.00381649]\n",
      "-0.0405757147074\n",
      "[ 0.9650692   0.68788989 -0.00476531]\n",
      "0.0859091032364\n",
      "[ 0.96306067  0.68588136 -0.00677384]\n",
      "-0.00986523372558\n",
      "[ 0.96329128  0.68611196 -0.00654323]\n",
      "Iteration:  400 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0397785469178\n",
      "[ 0.9623616   0.68518228 -0.00747291]\n",
      "-0.0466814016064\n",
      "[ 0.96127078  0.68409147 -0.0063821 ]\n",
      "0.0154053079486\n",
      "[ 0.9616307   0.68373155 -0.00674201]\n",
      "0.0439459467713\n",
      "[ 0.96265722  0.68270503 -0.00776854]\n",
      "0.0275561718875\n",
      "[ 0.96201366  0.68334859 -0.00712497]\n",
      "0.0230865519324\n",
      "[ 0.96147458  0.68280951 -0.00658589]\n",
      "0.0213690486271\n",
      "[ 0.96197346  0.68231062 -0.00708478]\n",
      "0.0760697180476\n",
      "[ 0.96374909  0.680535   -0.00886041]\n",
      "-0.00856590181877\n",
      "[ 0.963949    0.68073491 -0.00906032]\n",
      "-0.0474598139107\n",
      "[ 0.96284159  0.6796275  -0.0079529 ]\n",
      "Iteration:  410 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0157595799624\n",
      "[ 0.96247393  0.67999516 -0.00758524]\n",
      "-0.029498210598\n",
      "[ 0.96178588  0.67930711 -0.00827329]\n",
      "-0.0327746991313\n",
      "[ 0.96102154  0.68007144 -0.00903763]\n",
      "-0.0431957986403\n",
      "[ 0.96202872  0.67906426 -0.01004482]\n",
      "-0.00208361403838\n",
      "[ 0.96198015  0.67911283 -0.00999624]\n",
      "0.0410639816291\n",
      "[ 0.96293728  0.6781557  -0.01095337]\n",
      "-0.090787806643\n",
      "[ 0.96082156  0.67603999 -0.01306909]\n",
      "0.0310392282501\n",
      "[ 0.96154477  0.67531678 -0.01234588]\n",
      "0.0121232249826\n",
      "[ 0.96126235  0.6755992  -0.0126283 ]\n",
      "-0.00156596610532\n",
      "[ 0.96122588  0.67556273 -0.01266477]\n",
      "Iteration:  420 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0446334648036\n",
      "[ 0.9601865   0.67452335 -0.0116254 ]\n",
      "-0.00750941399963\n",
      "[ 0.96001166  0.67434852 -0.01145056]\n",
      "-0.0115940571513\n",
      "[ 0.96028155  0.67407863 -0.01118067]\n",
      "-0.0440881563527\n",
      "[ 0.96130766  0.67305252 -0.01220678]\n",
      "0.0197547159273\n",
      "[ 0.96176735  0.67259283 -0.01174709]\n",
      "0.0494331582159\n",
      "[ 0.96291743  0.67374291 -0.01289717]\n",
      "-0.0162513418148\n",
      "[ 0.96329545  0.67336489 -0.01327519]\n",
      "0.132655680153\n",
      "[ 0.96021031  0.67027975 -0.01019006]\n",
      "-0.0324736448208\n",
      "[ 0.9609654   0.67103484 -0.01094515]\n",
      "-0.0828480992163\n",
      "[ 0.95903934  0.66910878 -0.01287121]\n",
      "Iteration:  430 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0918146046256\n",
      "[ 0.95690523  0.66697467 -0.01073709]\n",
      "-0.0820385154898\n",
      "[ 0.95881176  0.66506814 -0.00883056]\n",
      "0.0123250392338\n",
      "[ 0.95909813  0.66478177 -0.00854419]\n",
      "0.0164644789739\n",
      "[ 0.95948061  0.66439929 -0.00892667]\n",
      "0.0275453231291\n",
      "[ 0.96012039  0.66375951 -0.00828689]\n",
      "-0.0129394748037\n",
      "[ 0.95981991  0.66405999 -0.00798641]\n",
      "0.0331753521684\n",
      "[ 0.96059016  0.66483024 -0.00721616]\n",
      "-0.00700072687903\n",
      "[ 0.96042765  0.66499275 -0.00737867]\n",
      "-1.50662112901e-05\n",
      "[ 0.9604273   0.6649931  -0.00737832]\n",
      "0.0185531824145\n",
      "[ 0.96085782  0.66542362 -0.00780884]\n",
      "Iteration:  440 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0134384269567\n",
      "[ 0.96054605  0.66511185 -0.00749706]\n",
      "0.00833907378205\n",
      "[ 0.96073948  0.66530528 -0.00730363]\n",
      "0.0267753184384\n",
      "[ 0.96011852  0.66468432 -0.00668268]\n",
      "-0.0296053877631\n",
      "[ 0.95943206  0.66399786 -0.00599622]\n",
      "-0.0206224672215\n",
      "[ 0.95991014  0.66351978 -0.0064743 ]\n",
      "0.0420052193228\n",
      "[ 0.95893654  0.66449338 -0.0074479 ]\n",
      "-0.016114335468\n",
      "[ 0.95930997  0.66411995 -0.00707447]\n",
      "0.0277641077045\n",
      "[ 0.95995325  0.66476323 -0.00771775]\n",
      "0.0650540059116\n",
      "[ 0.96146022  0.66325626 -0.00621078]\n",
      "-0.0188515762921\n",
      "[ 0.9610236   0.66369287 -0.00577417]\n",
      "Iteration:  450 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.07246256099\n",
      "[ 0.96270155  0.66201492 -0.00745212]\n",
      "0.00330539260233\n",
      "[ 0.96262503  0.6619384  -0.00752864]\n",
      "0.0663590900924\n",
      "[ 0.961089    0.66347443 -0.00906467]\n",
      "-0.00528342440947\n",
      "[ 0.96096673  0.66335215 -0.00918694]\n",
      "-0.104582695265\n",
      "[ 0.95854686  0.66093228 -0.00676707]\n",
      "0.00555009686616\n",
      "[ 0.95841846  0.66106068 -0.00663868]\n",
      "-0.0272338732563\n",
      "[ 0.95904836  0.66043077 -0.00600877]\n",
      "-0.0306550517399\n",
      "[ 0.95975726  0.65972187 -0.00671767]\n",
      "-0.0161557707676\n",
      "[ 0.96013079  0.65934834 -0.00634414]\n",
      "0.0881258818924\n",
      "[ 0.95809367  0.66138547 -0.00838127]\n",
      "Iteration:  460 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0420132880914\n",
      "[ 0.95906466  0.66235647 -0.00935226]\n",
      "-0.0309685866511\n",
      "[ 0.95834907  0.66164087 -0.01006786]\n",
      "-0.0210960350863\n",
      "[ 0.95883644  0.66115349 -0.01055523]\n",
      "-0.043599030372\n",
      "[ 0.95782938  0.66216055 -0.00954817]\n",
      "-0.0180263863003\n",
      "[ 0.95824568  0.66174426 -0.00913188]\n",
      "0.00702063481913\n",
      "[ 0.95840778  0.66190636 -0.00929398]\n",
      "0.0643860691994\n",
      "[ 0.95989412  0.66042002 -0.00780764]\n",
      "-0.0334277317899\n",
      "[ 0.9591226   0.66119154 -0.00703612]\n",
      "-0.00204064365607\n",
      "[ 0.95907551  0.66114445 -0.00708321]\n",
      "-0.060444013311\n",
      "[ 0.96047003  0.66253898 -0.00847773]\n",
      "Iteration:  470 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.113534337301\n",
      "[ 0.95785115  0.6599201  -0.01109661]\n",
      "-0.0239475739179\n",
      "[ 0.95729887  0.66047239 -0.01164889]\n",
      "0.0333620864189\n",
      "[ 0.95806812  0.65970313 -0.01241815]\n",
      "-0.0213578128387\n",
      "[ 0.95856049  0.6601955  -0.01291052]\n",
      "0.0153377534666\n",
      "[ 0.95820698  0.66054901 -0.012557  ]\n",
      "-0.00311937364904\n",
      "[ 0.95813509  0.6606209  -0.01248512]\n",
      "-0.0122771131013\n",
      "[ 0.95785223  0.66090376 -0.01276798]\n",
      "0.0622463047025\n",
      "[ 0.95928609  0.66233762 -0.01420184]\n",
      "-0.00226980760499\n",
      "[ 0.95933837  0.66228534 -0.01414956]\n",
      "-0.0360505183696\n",
      "[ 0.95850826  0.66145524 -0.01497967]\n",
      "Iteration:  480 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0221179359717\n",
      "[ 0.95799907  0.66094605 -0.01447048]\n",
      "0.0208113304743\n",
      "[ 0.95847808  0.66046703 -0.01399146]\n",
      "0.0206549333094\n",
      "[ 0.95895341  0.66094235 -0.01351614]\n",
      "-0.0449727366037\n",
      "[ 0.95791867  0.66197709 -0.01455087]\n",
      "-0.0176062853452\n",
      "[ 0.95832368  0.6623821  -0.01414586]\n",
      "0.0394885307587\n",
      "[ 0.95741548  0.6614739  -0.01505406]\n",
      "-0.0578085813531\n",
      "[ 0.9560862   0.66014462 -0.01638334]\n",
      "-0.00870667182642\n",
      "[ 0.95588604  0.66034479 -0.01618317]\n",
      "0.00380855191884\n",
      "[ 0.95597358  0.66043233 -0.01627072]\n",
      "-0.0411066991695\n",
      "[ 0.95502891  0.65948766 -0.01532605]\n",
      "Iteration:  490 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0733723235021\n",
      "[ 0.95334309  0.65780184 -0.01364023]\n",
      "0.0702526533958\n",
      "[ 0.95495691  0.65618801 -0.01525405]\n",
      "0.0342702986827\n",
      "[ 0.95416982  0.65540092 -0.01446696]\n",
      "-0.0726337235943\n",
      "[ 0.95583768  0.65373306 -0.0127991 ]\n",
      "-0.0227917649802\n",
      "[ 0.95531443  0.65320981 -0.01227585]\n",
      "-0.0397025412767\n",
      "[ 0.95622574  0.6522985  -0.01136453]\n",
      "-0.000443517016436\n",
      "[ 0.95623592  0.65230868 -0.01135436]\n",
      "-0.0329709237748\n",
      "[ 0.95547942  0.65155218 -0.01211085]\n",
      "0.0600100738993\n",
      "[ 0.9541028   0.6529288  -0.01073423]\n",
      "-0.101062350082\n",
      "[ 0.95178492  0.65061091 -0.01305212]\n",
      "Iteration:  500 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0325070075921\n",
      "[ 0.95253032  0.64986551 -0.01230671]\n",
      "0.0776844688021\n",
      "[ 0.95431132  0.6516465  -0.01052572]\n",
      "-0.0292478168943\n",
      "[ 0.95498172  0.65231691 -0.01119612]\n",
      "0.133268185255\n",
      "[ 0.95192763  0.64926282 -0.00814203]\n",
      "-0.0180233400375\n",
      "[ 0.95234059  0.64967577 -0.00772907]\n",
      "0.00217283424627\n",
      "[ 0.95229082  0.649626   -0.00777885]\n",
      "0.0568425075921\n",
      "[ 0.95098894  0.64832413 -0.00647698]\n",
      "0.040186013427\n",
      "[ 0.95190915  0.64740393 -0.00555678]\n",
      "-0.0152167574081\n",
      "[ 0.95225752  0.64705555 -0.0052084 ]\n",
      "0.0137405107839\n",
      "[ 0.95257203  0.64737007 -0.00489389]\n",
      "Iteration:  510 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0650286676747\n",
      "[ 0.95108386  0.6458819  -0.00638206]\n",
      "-0.049328687492\n",
      "[ 0.95221251  0.64701055 -0.00751071]\n",
      "-0.0452813017838\n",
      "[ 0.95117668  0.64597471 -0.00647487]\n",
      "-0.0443330548464\n",
      "[ 0.95219062  0.64496078 -0.00748881]\n",
      "0.00458287051106\n",
      "[ 0.95208582  0.64506557 -0.0075936 ]\n",
      "-0.031866105749\n",
      "[ 0.95281434  0.64579408 -0.00686509]\n",
      "-0.0690653341626\n",
      "[ 0.9512357   0.64421545 -0.00528645]\n",
      "-0.0156919529585\n",
      "[ 0.9508771   0.64385685 -0.00492785]\n",
      "0.0606312240135\n",
      "[ 0.9494918   0.64524214 -0.00631315]\n",
      "0.048433419431\n",
      "[ 0.94838542  0.64413577 -0.00520677]\n",
      "Iteration:  520 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0135044478294\n",
      "[ 0.948077    0.64444419 -0.00551519]\n",
      "-0.0258375793835\n",
      "[ 0.94748702  0.64503417 -0.00610517]\n",
      "0.0199711678172\n",
      "[ 0.94794295  0.64457824 -0.00564924]\n",
      "-0.0276824160894\n",
      "[ 0.94731111  0.64521008 -0.00501739]\n",
      "-0.0218925634151\n",
      "[ 0.94681152  0.64471049 -0.0045178 ]\n",
      "-0.01667502751\n",
      "[ 0.94643106  0.64509094 -0.00489825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0143093024017\n",
      "[ 0.94610466  0.64541735 -0.00522466]\n",
      "0.00509730940223\n",
      "[ 0.94622091  0.6453011  -0.00534091]\n",
      "-0.0360145562955\n",
      "[ 0.9470421   0.6444799  -0.00616211]\n",
      "0.000260248200675\n",
      "[ 0.94703617  0.64447397 -0.00615617]\n",
      "Iteration:  530 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0573747098556\n",
      "[ 0.94572846  0.64578168 -0.00484846]\n",
      "-0.11882023728\n",
      "[ 0.9430208   0.64307403 -0.00755612]\n",
      "0.012861146916\n",
      "[ 0.94331382  0.64278101 -0.0072631 ]\n",
      "0.0900517327495\n",
      "[ 0.94126257  0.64072976 -0.00931435]\n",
      "0.0024355251112\n",
      "[ 0.94131804  0.64067429 -0.00925888]\n",
      "-0.0142767929556\n",
      "[ 0.94164311  0.64099936 -0.00893381]\n",
      "0.0250506040278\n",
      "[ 0.94107284  0.64156963 -0.00836354]\n",
      "0.000837939637677\n",
      "[ 0.94109191  0.64155056 -0.00834447]\n",
      "-0.0648315455971\n",
      "[ 0.94256718  0.64007529 -0.0068692 ]\n",
      "0.0579323398953\n",
      "[ 0.94388518  0.6413933  -0.00818721]\n",
      "Iteration:  540 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.00155981570083\n",
      "[ 0.9438497   0.64142878 -0.00815173]\n",
      "0.0137922782472\n",
      "[ 0.94353605  0.64111512 -0.00846538]\n",
      "0.0131128230168\n",
      "[ 0.94383419  0.64081698 -0.00876353]\n",
      "-0.0627890832368\n",
      "[ 0.94526152  0.64224431 -0.00733619]\n",
      "-0.0358179206679\n",
      "[ 0.94607558  0.64143026 -0.00815025]\n",
      "0.0177861629289\n",
      "[ 0.94567142  0.6410261  -0.0085544 ]\n",
      "-0.11211594127\n",
      "[ 0.94312435  0.63847903 -0.00600732]\n",
      "0.000602318245399\n",
      "[ 0.94311066  0.63846535 -0.006021  ]\n",
      "-0.0539652249124\n",
      "[ 0.94433616  0.63723985 -0.0072465 ]\n",
      "0.04074840725\n",
      "[ 0.94526132  0.63631469 -0.00817166]\n",
      "Iteration:  550 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0381054702884\n",
      "[ 0.94439634  0.63544971 -0.00903664]\n",
      "0.031256937571\n",
      "[ 0.94510572  0.63615908 -0.00974602]\n",
      "-0.0477809448065\n",
      "[ 0.94402155  0.63507492 -0.00866185]\n",
      "0.0480466068483\n",
      "[ 0.94293158  0.63616489 -0.00975182]\n",
      "-0.0216677343076\n",
      "[ 0.94244013  0.63567344 -0.00926038]\n",
      "0.0106148160172\n",
      "[ 0.94268084  0.63591415 -0.00901967]\n",
      "-0.0618105884678\n",
      "[ 0.94127949  0.6373155  -0.01042102]\n",
      "0.0590850337519\n",
      "[ 0.9399402   0.63597622 -0.00908174]\n",
      "0.00166543408739\n",
      "[ 0.93997795  0.63593847 -0.009044  ]\n",
      "0.0944490769748\n",
      "[ 0.93783794  0.63379847 -0.011184  ]\n",
      "Iteration:  560 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.00448761403413\n",
      "[ 0.9379396   0.63390013 -0.01108234]\n",
      "0.0798396859719\n",
      "[ 0.93613136  0.63570837 -0.0092741 ]\n",
      "0.0096997878079\n",
      "[ 0.936351    0.63548873 -0.00905446]\n",
      "0.0317151165892\n",
      "[ 0.935633    0.63477073 -0.00833646]\n",
      "-0.0368609606779\n",
      "[ 0.93479867  0.63560506 -0.00917078]\n",
      "0.00506190961516\n",
      "[ 0.93491322  0.63571961 -0.00928533]\n",
      "-0.00920304155534\n",
      "[ 0.934705    0.63551139 -0.00907711]\n",
      "0.0142338812823\n",
      "[ 0.93438302  0.63518941 -0.00875514]\n",
      "0.00979232614736\n",
      "[ 0.93416156  0.63496795 -0.0089766 ]\n",
      "0.0715415559453\n",
      "[ 0.93254393  0.63335031 -0.01059423]\n",
      "Iteration:  570 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0291730826682\n",
      "[ 0.93320343  0.63400981 -0.00993473]\n",
      "-0.00831969653274\n",
      "[ 0.93301539  0.63419785 -0.01012277]\n",
      "0.00497199521226\n",
      "[ 0.93312774  0.6340855  -0.01001042]\n",
      "-0.0631271209545\n",
      "[ 0.93455394  0.6326593  -0.00858422]\n",
      "-0.0555119898122\n",
      "[ 0.93330004  0.63140541 -0.00983812]\n",
      "0.0429849829575\n",
      "[ 0.93427078  0.63043468 -0.00886738]\n",
      "-0.0663810080168\n",
      "[ 0.93576956  0.62893589 -0.01036616]\n",
      "0.0142790058622\n",
      "[ 0.93544723  0.62861356 -0.01068849]\n",
      "0.0192016554424\n",
      "[ 0.93501386  0.62904693 -0.01112186]\n",
      "-0.0284556805574\n",
      "[ 0.93565608  0.62840471 -0.01176408]\n",
      "0.0478679262692\n",
      "[ 0.9367362   0.62732459 -0.01068396]\n",
      "Iteration:  580 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0241826645824\n",
      "[ 0.93728175  0.62677904 -0.01013841]\n",
      "0.0598959510852\n",
      "[ 0.93593079  0.62542808 -0.01148937]\n",
      "0.0705455035446\n",
      "[ 0.93433996  0.62383725 -0.00989854]\n",
      "0.0936502276923\n",
      "[ 0.93222854  0.62594866 -0.01200995]\n",
      "0.0617485648853\n",
      "[ 0.93083666  0.62455678 -0.01340183]\n",
      "-0.147958439612\n",
      "[ 0.92750221  0.62122233 -0.01006738]\n",
      "-0.0905261675277\n",
      "[ 0.92546249  0.61918261 -0.01210709]\n",
      "-0.00228456218088\n",
      "[ 0.92551396  0.61913115 -0.01215856]\n",
      "0.0341720382443\n",
      "[ 0.92474432  0.61836151 -0.01138892]\n",
      "-0.0244790119331\n",
      "[ 0.92419311  0.6178103  -0.01083771]\n",
      "Iteration:  590 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0410852924373\n",
      "[ 0.92326815  0.61688534 -0.00991275]\n",
      "0.04137301883\n",
      "[ 0.92419939  0.6159541  -0.01084399]\n",
      "0.0435982445014\n",
      "[ 0.92518052  0.61497298 -0.00986287]\n",
      "0.0281809309158\n",
      "[ 0.92454647  0.61433894 -0.01049691]\n",
      "0.0382591143632\n",
      "[ 0.92540709  0.61347832 -0.0096363 ]\n",
      "-0.0187178013754\n",
      "[ 0.92498613  0.61305736 -0.00921534]\n",
      "0.0593519428688\n",
      "[ 0.9236516   0.61172283 -0.00788081]\n",
      "0.0482553162637\n",
      "[ 0.92473639  0.61063804 -0.00896561]\n",
      "0.0596292749671\n",
      "[ 0.9260766   0.60929783 -0.0076254 ]\n",
      "-0.0105163860079\n",
      "[ 0.92584029  0.60953414 -0.00738908]\n",
      "Iteration:  600 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0146704479619\n",
      "[ 0.9255107   0.60986373 -0.00705949]\n",
      "0.00933254985057\n",
      "[ 0.92572032  0.61007336 -0.00726912]\n",
      "-0.0110523727542\n",
      "[ 0.92596853  0.61032156 -0.00751732]\n",
      "0.0250681995528\n",
      "[ 0.92653137  0.60975872 -0.00695448]\n",
      "-0.0232553150728\n",
      "[ 0.92705339  0.60923669 -0.00643245]\n",
      "-0.0113877178845\n",
      "[ 0.92730897  0.60949227 -0.00668803]\n",
      "0.0214460814256\n",
      "[ 0.92682775  0.60901105 -0.00620681]\n",
      "0.0119052995938\n",
      "[ 0.92709483  0.60874397 -0.00593973]\n",
      "0.0101987582127\n",
      "[ 0.92732358  0.60851523 -0.00571099]\n",
      "0.00699122054738\n",
      "[ 0.92716681  0.608672   -0.00555421]\n",
      "Iteration:  610 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0157279620562\n",
      "[ 0.92681419  0.60831939 -0.0052016 ]\n",
      "-0.0210998450757\n",
      "[ 0.92728714  0.60879234 -0.00472865]\n",
      "-0.00299380173567\n",
      "[ 0.92735424  0.60885943 -0.00479574]\n",
      "0.0255406315634\n",
      "[ 0.92792649  0.60943168 -0.00536799]\n",
      "0.0227506366867\n",
      "[ 0.92843612  0.60994132 -0.00485836]\n",
      "0.023797845595\n",
      "[ 0.92896911  0.60940833 -0.00539134]\n",
      "0.00841754631165\n",
      "[ 0.92878062  0.60921985 -0.00520286]\n",
      "-0.033186701482\n",
      "[ 0.92803768  0.6084769  -0.00445991]\n",
      "0.0501552073894\n",
      "[ 0.92691509  0.60735432 -0.00333732]\n",
      "-0.00601133372311\n",
      "[ 0.92678057  0.60748884 -0.00347184]\n",
      "Iteration:  620 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.000553221986365\n",
      "[ 0.9267682   0.60750122 -0.00348422]\n",
      "0.0259149138681\n",
      "[ 0.92618852  0.60808089 -0.00290455]\n",
      "0.0345409215935\n",
      "[ 0.92541607  0.60885334 -0.00213209]\n",
      "-0.00148510830172\n",
      "[ 0.92544927  0.60888655 -0.00209889]\n",
      "-0.00956934871908\n",
      "[ 0.92566319  0.60867263 -0.00188497]\n",
      "0.0498632877338\n",
      "[ 0.92677761  0.60755821 -0.00299939]\n",
      "0.0217120859503\n",
      "[ 0.92726276  0.60804337 -0.00251424]\n",
      "-0.0502161074505\n",
      "[ 0.92614092  0.60692153 -0.0013924 ]\n",
      "0.0327328785534\n",
      "[  9.26872031e-01   6.06190421e-01  -6.61293972e-04]\n",
      "-0.0593409846597\n",
      "[  9.25546895e-01   6.04865285e-01   6.63841956e-04]\n",
      "Iteration:  630 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0394930776056\n",
      "[  9.24665165e-01   6.03983555e-01  -2.17888558e-04]\n",
      "0.0181952488761\n",
      "[  9.25071311e-01   6.04389700e-01  -6.24034475e-04]\n",
      "-0.02151937931\n",
      "[ 0.92459107  0.60486995 -0.00110428]\n",
      "-0.00955489183787\n",
      "[ 0.92437787  0.60465675 -0.00131747]\n",
      "-0.0670196258413\n",
      "[  9.25872918e-01   6.03161712e-01   1.77572435e-04]\n",
      "-0.0374078364664\n",
      "[  9.26707220e-01   6.02327410e-01  -6.56729726e-04]\n",
      "-0.0265914418806\n",
      "[ 0.92730016  0.60292035 -0.00124967]\n",
      "0.0280809759319\n",
      "[  9.27926186e-01   6.03546376e-01  -6.23646783e-04]\n",
      "0.0330103379094\n",
      "[  9.28661949e-01   6.04282139e-01   1.12116567e-04]\n",
      "0.0545771310386\n",
      "[ 0.92744574  0.60306593  0.00132832]\n",
      "Iteration:  640 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0302005885508\n",
      "[  9.28118596e-01   6.03738786e-01   6.55469464e-04]\n",
      "-0.0766518719956\n",
      "[ 0.92982601  0.60203137 -0.00105194]\n",
      "0.00537249830654\n",
      "[ 0.92994565  0.60215102 -0.00117159]\n",
      "0.0329391120206\n",
      "[ 0.93067906  0.60288443 -0.001905  ]\n",
      "0.104170898386\n",
      "[  9.32998000e-01   6.00565491e-01   4.13941151e-04]\n",
      "0.000579392720169\n",
      "[  9.33010896e-01   6.00578386e-01   4.01046048e-04]\n",
      "0.0645156166034\n",
      "[ 0.93444647  0.59914281  0.00183662]\n",
      "-0.00922217987977\n",
      "[ 0.93465163  0.59934798  0.00204179]\n",
      "0.0594888527995\n",
      "[  9.33328468e-01   5.98024810e-01   7.18618951e-04]\n",
      "-0.00563287664204\n",
      "[  9.33203207e-01   5.98150072e-01   5.93357286e-04]\n",
      "Iteration:  650 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0603179505613\n",
      "[  9.31862161e-01   5.96809027e-01  -7.47688292e-04]\n",
      "-0.00628834686847\n",
      "[  9.31722382e-01   5.96948806e-01  -8.87467464e-04]\n",
      "-0.0565807086909\n",
      "[ 0.93046495  0.59569138 -0.0021449 ]\n",
      "0.0533211355616\n",
      "[ 0.92928021  0.59687612 -0.00096016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0390459045223\n",
      "[ 0.93014759  0.59600874 -0.00182753]\n",
      "-0.0165178313412\n",
      "[ 0.93051445  0.5963756  -0.00146068]\n",
      "-0.0549146090394\n",
      "[ 0.92929507  0.59515622 -0.00268006]\n",
      "-0.0488598996675\n",
      "[ 0.93037977  0.59407151 -0.00376476]\n",
      "0.0272491934787\n",
      "[ 0.92977496  0.59346669 -0.00436958]\n",
      "0.0125857829728\n",
      "[ 0.92949567  0.5931874  -0.00464887]\n",
      "Iteration:  660 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0234936102229\n",
      "[ 0.93001691  0.59266616 -0.00517011]\n",
      "0.00199445716476\n",
      "[ 0.93006115  0.5927104  -0.00521435]\n",
      "-0.0460008364114\n",
      "[ 0.93108131  0.59373057 -0.00623452]\n",
      "-0.0054746907158\n",
      "[ 0.93095992  0.59385196 -0.0063559 ]\n",
      "0.0283156027486\n",
      "[ 0.93033223  0.59447965 -0.0069836 ]\n",
      "0.0148752219138\n",
      "[ 0.93066191  0.59480933 -0.00731328]\n",
      "-0.0886659142166\n",
      "[ 0.92869721  0.59284463 -0.00927798]\n",
      "-0.0461362054281\n",
      "[ 0.9297193   0.59386672 -0.00825589]\n",
      "0.0132422171093\n",
      "[ 0.93001261  0.59416003 -0.00854919]\n",
      "-0.0121564234979\n",
      "[ 0.92974341  0.59389083 -0.00827999]\n",
      "Iteration:  670 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0445622724803\n",
      "[ 0.93073001  0.59290422 -0.0092666 ]\n",
      "0.00384150158141\n",
      "[ 0.93081505  0.59281919 -0.00935163]\n",
      "-0.00397254914418\n",
      "[ 0.93090296  0.59273128 -0.00943955]\n",
      "-0.014719030157\n",
      "[ 0.93122863  0.59305695 -0.00911387]\n",
      "0.0139637003983\n",
      "[ 0.93153753  0.59274805 -0.00942277]\n",
      "-0.00377413364663\n",
      "[ 0.93145406  0.59283153 -0.00950624]\n",
      "0.00295765184978\n",
      "[ 0.93138866  0.59289693 -0.00944084]\n",
      "-0.00522702872081\n",
      "[ 0.9312731   0.59278137 -0.00932528]\n",
      "0.0704424420741\n",
      "[ 0.93283008  0.59433834 -0.00776831]\n",
      "0.077057707967\n",
      "[ 0.93112724  0.59263551 -0.00606548]\n",
      "Iteration:  680 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0484597099284\n",
      "[ 0.9300566   0.59156486 -0.00499483]\n",
      "0.0311207075575\n",
      "[ 0.92936918  0.59087744 -0.00430741]\n",
      "-0.0333494794496\n",
      "[ 0.93010567  0.59161394 -0.00504391]\n",
      "-0.00396636284972\n",
      "[ 0.93019325  0.59170152 -0.00495633]\n",
      "-0.0350550682311\n",
      "[ 0.93096709  0.59092768 -0.00418249]\n",
      "0.0443896783773\n",
      "[ 0.92998739  0.58994798 -0.00516219]\n",
      "-0.0457775006153\n",
      "[ 0.93099751  0.58893787 -0.0061723 ]\n",
      "-0.0312634066038\n",
      "[ 0.93168721  0.58824816 -0.0054826 ]\n",
      "-0.0146214467125\n",
      "[ 0.93136472  0.58857066 -0.00580509]\n",
      "0.0422983978286\n",
      "[ 0.93229747  0.5876379  -0.00673785]\n",
      "Iteration:  690 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0504644498341\n",
      "[ 0.93341007  0.5887505  -0.00785045]\n",
      "0.052526835704\n",
      "[ 0.9345679   0.58759268 -0.00669262]\n",
      "-0.00608169447725\n",
      "[ 0.93470193  0.5877267  -0.0065586 ]\n",
      "0.0208679507834\n",
      "[ 0.93424214  0.58818649 -0.00609881]\n",
      "0.0194376194108\n",
      "[ 0.93381395  0.58861468 -0.00652699]\n",
      "-0.0601591129075\n",
      "[ 0.9351389   0.58728973 -0.00520204]\n",
      "-0.0311732284616\n",
      "[ 0.93582532  0.58797615 -0.00588846]\n",
      "-0.0375762068256\n",
      "[ 0.93499809  0.58714891 -0.00671569]\n",
      "0.00888259225212\n",
      "[ 0.93480258  0.58734442 -0.0069112 ]\n",
      "0.0888377604746\n",
      "[ 0.93284765  0.58538949 -0.00886613]\n",
      "Iteration:  700 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.028306865742\n",
      "[ 0.93222487  0.58601227 -0.00948891]\n",
      "0.0465022227197\n",
      "[ 0.93120199  0.58703515 -0.01051179]\n",
      "-0.00187483454249\n",
      "[ 0.93124322  0.58707638 -0.01047056]\n",
      "0.00823060875086\n",
      "[ 0.93106225  0.58725735 -0.01065153]\n",
      "0.0215779662489\n",
      "[ 0.93058791  0.58678301 -0.01017719]\n",
      "-0.0487889705944\n",
      "[ 0.93166019  0.58571073 -0.01124947]\n",
      "0.0339899683019\n",
      "[ 0.93240707  0.5864576  -0.01199634]\n",
      "0.0335114155779\n",
      "[ 0.93167086  0.5857214  -0.01126014]\n",
      "-0.0189145768186\n",
      "[ 0.93125542  0.58530596 -0.01167558]\n",
      "-0.0365421512322\n",
      "[ 0.93205787  0.58610841 -0.01247803]\n",
      "Iteration:  710 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0230530014923\n",
      "[ 0.932564    0.58560228 -0.0119719 ]\n",
      "-0.0852947823341\n",
      "[ 0.93443624  0.58747452 -0.01009966]\n",
      "-0.0142184346039\n",
      "[ 0.93412421  0.58778656 -0.01041169]\n",
      "-0.121884764255\n",
      "[ 0.93144992  0.58511228 -0.00773741]\n",
      "-0.0111321080111\n",
      "[ 0.93169412  0.58486808 -0.00749321]\n",
      "0.0815146131224\n",
      "[ 0.92990636  0.58308031 -0.00570544]\n",
      "-0.031974224068\n",
      "[ 0.93060746  0.5823792  -0.00500433]\n",
      "-0.00630656860153\n",
      "[ 0.93046921  0.58224094 -0.00486608]\n",
      "0.00709693984629\n",
      "[ 0.93031365  0.58208539 -0.00502163]\n",
      "-0.0503155311691\n",
      "[ 0.92921107  0.5809828  -0.00612422]\n",
      "Iteration:  720 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0428313232354\n",
      "[ 0.93014945  0.58192119 -0.00518583]\n",
      "0.0154534309746\n",
      "[ 0.92981096  0.58158269 -0.00484733]\n",
      "-0.0447070764756\n",
      "[ 0.92883188  0.58060362 -0.00386826]\n",
      "0.0249765339347\n",
      "[ 0.92828502  0.58115049 -0.00441513]\n",
      "0.0156405385519\n",
      "[ 0.92794264  0.58149287 -0.00407275]\n",
      "0.0317321920238\n",
      "[ 0.92724815  0.58218735 -0.00337826]\n",
      "0.0473063451921\n",
      "[ 0.92621303  0.58115223 -0.00441338]\n",
      "-0.0774508562208\n",
      "[ 0.9279074   0.5828466  -0.00271901]\n",
      "-0.0288001332807\n",
      "[ 0.92853732  0.58221668 -0.00208909]\n",
      "-0.026366122662\n",
      "[ 0.92911388  0.58164012 -0.00266565]\n",
      "Iteration:  730 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0431571079548\n",
      "[ 0.93005743  0.58258366 -0.00172211]\n",
      "-0.00911303969474\n",
      "[ 0.93025663  0.58238446 -0.00152291]\n",
      "0.0126413689536\n",
      "[ 0.93053289  0.5821082  -0.00124665]\n",
      "0.0223776632786\n",
      "[  9.30043952e-01   5.81619266e-01  -7.57714511e-04]\n",
      "0.0461985763478\n",
      "[ 0.93105315  0.58061007 -0.00176691]\n",
      "0.0224435010791\n",
      "[ 0.93056298  0.5801199  -0.00225708]\n",
      "0.0849687100253\n",
      "[ 0.92870764  0.58197524 -0.00411241]\n",
      "0.020477615668\n",
      "[ 0.92915469  0.58242229 -0.00455946]\n",
      "0.00683453321722\n",
      "[ 0.92900551  0.58257146 -0.00441029]\n",
      "-0.0397515946458\n",
      "[ 0.92813806  0.58170401 -0.00354283]\n",
      "Iteration:  740 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.0652448773279\n",
      "[ 0.9267146   0.58312747 -0.0049663 ]\n",
      "-0.00356286422868\n",
      "[ 0.92679231  0.58320519 -0.00488858]\n",
      "-0.0780617999062\n",
      "[ 0.92849469  0.58150281 -0.0031862 ]\n",
      "0.0418517304936\n",
      "[ 0.92758218  0.58241532 -0.00227369]\n",
      "-0.00477591041704\n",
      "[ 0.92747807  0.58251943 -0.0023778 ]\n",
      "-0.0265272964421\n",
      "[ 0.92689992  0.58309758 -0.00295594]\n",
      "0.0489588632076\n",
      "[ 0.92583312  0.58203077 -0.00402275]\n",
      "-0.00598182706904\n",
      "[ 0.9257028   0.58190046 -0.00415306]\n",
      "-0.037969796616\n",
      "[ 0.92652981  0.58107345 -0.00498007]\n",
      "0.0124786745637\n",
      "[ 0.92680155  0.58134519 -0.00470834]\n",
      "Iteration:  750 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0628047928925\n",
      "[ 0.92543419  0.58271255 -0.0060757 ]\n",
      "-0.00464128516671\n",
      "[ 0.92533316  0.58261152 -0.00617672]\n",
      "-0.00146359236646\n",
      "[ 0.92536501  0.58264337 -0.00620858]\n",
      "-0.0186549096604\n",
      "[ 0.92495912  0.58223748 -0.00580268]\n",
      "-0.0360755869758\n",
      "[ 0.92417435  0.58302225 -0.00501792]\n",
      "0.015739941473\n",
      "[ 0.92451668  0.58267992 -0.00536024]\n",
      "-0.0632768714609\n",
      "[ 0.92589259  0.58405583 -0.00673615]\n",
      "0.0380442189314\n",
      "[ 0.92506552  0.5848829  -0.00590908]\n",
      "0.0286158193051\n",
      "[ 0.92568749  0.58426093 -0.00528711]\n",
      "0.0503830410232\n",
      "[ 0.92459263  0.58316608 -0.00419226]\n",
      "Iteration:  760 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0565237871645\n",
      "[ 0.92336459  0.58193803 -0.0054203 ]\n",
      "-0.0321074573595\n",
      "[ 0.92266716  0.58124061 -0.00472287]\n",
      "0.0246312387053\n",
      "[ 0.92213225  0.58177553 -0.00418796]\n",
      "-0.0227338342526\n",
      "[ 0.92262585  0.58226913 -0.00369435]\n",
      "-0.0197187336539\n",
      "[ 0.9221978   0.58184108 -0.00326629]\n",
      "-0.0243922721982\n",
      "[ 0.92166841  0.58237048 -0.0027369 ]\n",
      "0.0417069225712\n",
      "[ 0.92076341  0.58146548 -0.00183191]\n",
      "-0.0551283393572\n",
      "[ 0.92195939  0.58026951 -0.00302788]\n",
      "-0.043723229074\n",
      "[ 0.92290773  0.57932116 -0.00397623]\n",
      "0.0707024929845\n",
      "[ 0.92444094  0.57778796 -0.00550943]\n",
      "Iteration:  770 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "0.030824293049\n",
      "[ 0.92510923  0.57845625 -0.00484114]\n",
      "0.000293720322759\n",
      "[ 0.92510286  0.57846262 -0.00483477]\n",
      "0.0442531926006\n",
      "[ 0.92606211  0.57942186 -0.00579401]\n",
      "-0.0430010710949\n",
      "[ 0.92699401  0.58035377 -0.00672592]\n",
      "-0.00307897394805\n",
      "[ 0.9269273   0.58042048 -0.0066592 ]\n",
      "-0.0778684680718\n",
      "[ 0.92524046  0.58210732 -0.00834604]\n",
      "0.0907422249957\n",
      "[ 0.92327516  0.58014201 -0.01031135]\n",
      "0.033628846146\n",
      "[ 0.92254697  0.57941383 -0.01103953]\n",
      "0.0400550257273\n",
      "[ 0.92341413  0.57854667 -0.01190669]\n",
      "0.0161181207681\n",
      "[ 0.92306526  0.57889554 -0.01225556]\n",
      "0.00238008332406\n",
      "[ 0.92301375  0.57894705 -0.01230706]\n",
      "Iteration:  780 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0409781638396\n",
      "[ 0.92390033  0.57983363 -0.01142048]\n",
      "-0.0339609712395\n",
      "[ 0.92463495  0.58056824 -0.01215509]\n",
      "0.0113476466591\n",
      "[ 0.92488036  0.58032283 -0.01190968]\n",
      "-0.0446064029588\n",
      "[ 0.92584483  0.58128731 -0.01287416]\n",
      "-0.0126592762797\n",
      "[ 0.9261185   0.58101365 -0.0126005 ]\n",
      "0.0396285828602\n",
      "[ 0.925262    0.58015716 -0.01345699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0327160290901\n",
      "[ 0.92596895  0.5808641  -0.01275004]\n",
      "0.0402751374178\n",
      "[ 0.92683905  0.579994   -0.01187994]\n",
      "-0.00475436902946\n",
      "[ 0.92673636  0.57989131 -0.01177725]\n",
      "0.0221906235078\n",
      "[ 0.92625715  0.58037051 -0.01225645]\n",
      "Iteration:  790 . Current Average Test Hamming Accuracy:  94.284030784 %.\n",
      "-0.0420363288832\n",
      "[ 0.92534957  0.58127809 -0.01134887]\n",
      "-0.0728535789789\n",
      "[ 0.92692218  0.57970548 -0.00977626]\n",
      "-0.0101982249143\n",
      "[ 0.92714228  0.57948539 -0.00955616]\n",
      "0.0313598544417\n",
      "[ 0.92781893  0.57880874 -0.00887951]\n",
      "-0.0504347224234\n",
      "[ 0.92673092  0.57989674 -0.00996752]\n",
      "-0.0560674293099\n",
      "[ 0.92794019  0.57868748 -0.01117678]\n"
     ]
    }
   ],
   "source": [
    "# Simultaneuos Pertubation Stochastic Approximation\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.spatial.distance import hamming \n",
    "\n",
    "alpha, gamma = 0.602, 0.101\n",
    "A, c, a = 1000, 0.0001, 0.0001\n",
    "\n",
    "crf = CRF(feat_func, 2+26**2, 26, C=[1.04812081,0.83590713, 0.36205899], W=\"B\")\n",
    "\n",
    "epoch = 0\n",
    "batch_size = 32\n",
    "\n",
    "acc_test = np.zeros(30)\n",
    "for n in range(30):\n",
    "    acc_test[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "            \n",
    "print('Average test Hamming accuracy with only trained unary features: ',\n",
    "        100* acc_test.mean(), '%.')\n",
    "print(crf.C)         \n",
    "\n",
    "while epoch < 2:\n",
    "    \n",
    "    dims = np.arange(X_tr.shape[0])\n",
    "    np.random.shuffle(dims)\n",
    "    \n",
    "    for b in range(0,6200, batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr[dims[b:b+batch_size]],y_tr[dims[b:b+batch_size]]\n",
    "        k = (6200//batch_size)*epoch + (b // batch_size)\n",
    "        alpha_k = a / (A + k +1)**alpha\n",
    "        c_k = c / (k + 1)**gamma\n",
    "        del_k = 2* c_k * bernoulli.rvs(0.5,size=3) - c_k\n",
    "        crf_p = CRF(feat_func, 2+26**2, 26, crf.C + del_k ,'B')\n",
    "        crf_m = CRF(feat_func, 2+26**2, 26, crf.C - del_k, 'B')\n",
    "    \n",
    "        diff = (crf_p.reg_neg_ll(X_b,y_b) - crf_m.reg_neg_ll(X_b,y_b)) / 2 * batch_size\n",
    "        C = crf.C - (alpha_k * diff) * (1 / del_k)\n",
    "        crf = CRF(feat_func, 2+26**2, 26, C, \"B\")\n",
    "        print(diff)\n",
    "        print(crf.C)     # 12 = (a,m): 9 = (a,j): 30 = (b,e): 51 = (b,z)\n",
    "        if k  % 10 == 0:\n",
    "            \n",
    "            acc_test = np.zeros(30)\n",
    "            \n",
    "            for n in range(30):\n",
    "                acc_test[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "            \n",
    "            print('Iteration: ',k, '. Current Average Test Hamming Accuracy: ',\n",
    "                100* acc_test.mean(), '%.')\n",
    "        \n",
    "        \n",
    "    epoch += 1\n",
    "\n",
    "acc_test = np.zeros(30)\n",
    "            \n",
    "for n in range(30):\n",
    "    acc_test[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "            \n",
    "print('Iteration: ',k, '. Current Average Test Hamming Accuracy: ',\n",
    "        100* acc_test.mean(), '%.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letts0 = '7.38 11.5 12.2 12.1 9.25 10.6 11.6 9.03 12.4 9.03 11.0 13.1 11.9 13.8 7.79 11.4 7.95 13.3 13.0 13.5 11.1 11.6 10.5 9.64 12.0 9.23'\n",
    "letts1 = '11.4 9.00 6.57 6.50 12.4 3.85 3.56 5.33 10.9 8.14 3.56 11.5 6.93 5.61 11.5 5.25 0.1 10.6 10.2 8.52 11.3 7.05 6.57 0.1 11.4 2.71'\n",
    "letts2 = '12.4 4.08 10.4 5.76 12.7 3.00 .69 12.5 11.7 1.10 11.4 11.1 4.89 4.90 12.8 3.76 7.87 11.2 9.47 12.1 11.2 1.95 3.00 .69 9.93 5.82'\n",
    "letts3 = '11.6 7.33 7.73 10.1 12.8 7.46 9.83 7.55 12.2 7.54 5.46 9.76 9.44 9.16 11.4 6.09 6.83 10.7 11.0 7.30 11.0 9.31 8.73 .00 9.98 5.09'\n",
    "letts4 = '12.8 10.2 12.4 13.3 12.2 11.2 11.0 9.36 11.3 7.58 9.97 12.4 12.0 13.4 10.6 11.4 9.52 13.9 13.4 12.3 9.23 11.6 11.5 11.3 11.4 8.43'\n",
    "letts5 = '11.1 4.32 4.78 3.50 11.5 11.3 6.02 3.64 11.9 4.23 5.42 10.1 6.27 5.31 12.4 3.26 0.1 11.5 8.16 10.8 10.5 3.81 4.91 1.39 8.18 2.56'\n",
    "letts6 = '11.4 5.36 3.58 6.81 12.2 6.20 9.57 11.7 11.0 3.09 4.68 9.99 7.66 10.4 11.0 5.28 1.95 11.3 10.3 9.35 10.6 2.94 5.96 2.08 9.12 3.64'\n",
    "letts7 = '13.1 8.20 6.35 7.84 14.1 6.60 5.24 6.21 12.6 3.50 5.91 9.00 8.58 9.71 12.4 5.91 5.12 10.6 9.32 11.2 10.2 5.18 8.07 0.1 9.54 2.64'\n",
    "letts8 = '11.9 10.4 12.8 12.4 12.1 11.1 11.8 6.54 7.10 7.21 10.4 12.5 11.8 14.0 12.7 10.5 8.09 11.9 13.1 13.1 8.71 11.7 6.71 9.25 6.69 10.2'\n",
    "letts9 = '8.52 1.61 3.43 3.56 9.39 2.08 0.1 1.10 7.24 2.30 3.76 2.40 3.93 3.37 10.0 1.61 0.1 1.39 2.30 2.56 10.1 .69 0.1 0.1 1.39 1.79'\n",
    "letts10 = '9.21 6.78 4.55 6.64 11.9 6.73 6.35 7.68 11.0 3.85 6.42 9.22 6.53 9.80 8.42 6.30 0.1 8.04 10.5 6.95 7.46 5.42 7.05 .00 8.70 2.56'\n",
    "letts11 = '12.5 8.60 8.44 11.9 12.9 10.0 7.95 7.18 12.7 4.22 9.54 12.7 9.68 7.78 12.0 9.50 3.43 8.53 11.3 10.9 10.9 9.58 8.49 3.40 12.1 6.25'\n",
    "letts12 = '12.3 10.7 5.82 5.65 12.8 7.59 4.80 5.64 12.0 3.56 4.30 7.21 10.8 7.95 12.0 11.8 1.39 5.81 10.6 5.84 10.7 4.43 4.88 0.1 9.84 2.89'\n",
    "letts13 = '12.0 8.42 12.2 13.3 12.8 10.2 13.2 9.07 12.1 8.40 10.5 10.1 9.81 10.9 12.1 7.93 7.36 8.38 12.4 13.1 10.7 10.3 8.30 7.55 11.1 7.75'\n",
    "letts14 = '10.5 10.6 11.2 11.3 9.82 13.0 10.6 9.43 10.8 8.47 10.6 12.1 12.6 13.6 11.7 11.7 6.27 13.4 11.9 12.2 12.9 11.5 12.0 8.62 9.85 8.30'\n",
    "letts15 = '12.0 6.81 5.74 5.81 12.3 6.47 7.80 10.4 11.0 4.91 6.47 11.8 8.67 5.60 12.0 11.1 2.08 12.2 10.2 10.4 10.9 1.10 5.85 .00 8.97 3.58'\n",
    "letts16 = '3.30 1.95 0.1 .00 .69 .69 .00 0.1 6.64 0.1 0.1 1.10 0.1 .00 .00 0.1 1.10 0.1 1.10 1.95 10.9 1.79 .69 0.1 0.1 0.1'\n",
    "letts17 = '12.8 9.63 11.2 11.6 13.7 9.61 11.0 8.83 12.7 5.58 11.4 10.8 11.3 11.5 12.8 10.1 6.18 11.0 12.5 12.2 11.0 11.0 8.79 5.47 11.6 6.92'\n",
    "letts18 = '12.1 8.59 11.1 9.10 12.9 8.62 6.66 12.0 12.5 4.16 10.2 10.4 10.1 9.18 12.0 11.3 8.25 8.72 12.2 13.2 11.7 6.44 9.15 .00 9.75 5.97'\n",
    "letts19 = '12.5 8.43 9.81 7.32 13.3 8.08 7.71 14.2 13.2 4.17 6.14 10.7 9.83 8.95 13.2 7.33 1.95 12.2 12.2 11.4 11.4 6.49 10.5 2.83 11.5 8.49'\n",
    "letts20 = '10.9 10.8 11.3 10.9 11.2 9.19 11.1 6.29 10.8 5.98 8.08 11.9 11.0 12.1 8.53 11.2 5.73 12.3 12.3 12.4 5.42 7.31 6.43 7.56 8.94 7.43'\n",
    "letts21 = '10.8 .00 6.05 4.20 12.9 .00 4.52 1.39 12.0 .69 3.18 5.15 2.40 5.34 10.4 0.1 0.1 6.23 6.43 3.71 6.76 4.74 0.1 0.1 8.11 1.10'\n",
    "letts22 = '12.1 6.89 6.09 7.88 11.8 6.22 3.71 12.0 12.1 0.1 7.07 8.85 7.31 10.7 11.7 5.53 1.95 9.53 10.0 7.87 4.69 .69 2.94 .00 8.43 2.20'\n",
    "letts23 = '9.11 3.78 9.11 .00 9.61 5.59 1.10 7.76 9.11 0.1 0.1 5.06 4.39 2.94 7.47 10.3 4.76 1.39 4.55 9.75 7.96 4.62 6.11 5.06 6.00 .00'\n",
    "letts24 = '9.16 8.22 8.48 7.77 11.4 6.35 6.34 6.24 9.92 3.09 5.96 9.07 9.49 9.11 10.6 8.63 1.61 8.97 10.7 8.86 6.57 5.64 8.04 4.42 3.43 6.56'\n",
    "letts25 = '9.41 5.86 3.69 4.73 10.1 2.56 5.00 6.32 8.93 .69 5.29 6.95 6.00 4.67 8.13 4.98 3.14 4.75 4.98 4.84 6.85 4.84 5.21 0.1 7.23 8.10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "let_list = [letts0, letts1, letts2, letts3, letts4, letts5, letts6, letts7, letts8, letts9,\n",
    "            letts10, letts11, letts12, letts13, letts14, letts15, letts16, letts17,\n",
    "            letts18, letts19, letts20, letts21, letts22, letts21, letts22, letts23,\n",
    "            letts24, letts25]\n",
    "\n",
    "W_t = np.zeros(26**2)\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        W_t[26*i+j] = np.exp(np.float32(let_list[i].split(sep=' ')[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1603.59\n",
      "98715.8\n",
      "198789.0\n",
      "179872.0\n",
      "10404.6\n",
      "40134.9\n",
      "109098.0\n",
      "8349.86\n",
      "242802.0\n",
      "8349.86\n",
      "59874.1\n",
      "488943.0\n",
      "147267.0\n",
      "984609.0\n",
      "2416.32\n",
      "89321.7\n",
      "2835.57\n",
      "597196.0\n",
      "442413.0\n",
      "729416.0\n",
      "66171.2\n",
      "109098.0\n",
      "36315.5\n",
      "15367.3\n",
      "162755.0\n",
      "10198.5\n"
     ]
    }
   ],
   "source": [
    "for k in let_list[0].split(sep=' '):\n",
    "    print(np.exp(np.float32(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.24160809e-05,   1.99550918e-03,   4.01846107e-03,\n",
       "         3.63605622e-03,   2.10325109e-04,   8.11313753e-04,\n",
       "         2.20537956e-03,   1.68789815e-04,   4.90815872e-03,\n",
       "         1.68789815e-04,   1.21033745e-03,   9.88382504e-03,\n",
       "         2.97694854e-03,   1.99035762e-02,   4.88451171e-05,\n",
       "         1.80561060e-03,   5.73202708e-05,   1.20721295e-02,\n",
       "         8.94325174e-03,   1.47449290e-02,   1.33763032e-03,\n",
       "         2.20537956e-03,   7.34106808e-04,   3.10646254e-04,\n",
       "         3.29003846e-03,   2.06160310e-04,   1.80561060e-03,\n",
       "         1.63801365e-04,   1.44205563e-05,   1.34456353e-05,\n",
       "         4.90815872e-03,   9.49950285e-07,   7.10813268e-07,\n",
       "         4.17308020e-06,   1.09515822e-03,   6.93145481e-05,\n",
       "         7.10813268e-07,   1.99550918e-03,   2.06693990e-05,\n",
       "         5.52152825e-06,   1.99550918e-03,   3.85223886e-06,\n",
       "         2.23406932e-08,   8.11313753e-04,   5.43839591e-04,\n",
       "         1.01357612e-04,   1.63378507e-03,   2.33046924e-05,\n",
       "         1.44205563e-05,   2.23406932e-08,   1.80561060e-03,\n",
       "         3.03812217e-07,   4.90815872e-03,   1.19560751e-06,\n",
       "         6.64247036e-04,   6.41510065e-06,   6.62532245e-03,\n",
       "         4.06022989e-07,   4.03023498e-08,   5.42435610e-03,\n",
       "         2.43731996e-03,   6.07282997e-08,   1.80561060e-03,\n",
       "         1.33763032e-03,   2.68761541e-06,   2.71462715e-06,\n",
       "         7.32211665e-03,   8.68189286e-07,   5.29132799e-05,\n",
       "         1.47830928e-03,   2.62081300e-04,   3.63605622e-03,\n",
       "         1.47830928e-03,   1.42082778e-07,   4.06022989e-07,\n",
       "         4.03023498e-08,   4.15156204e-04,   6.81178811e-06,\n",
       "         2.20537956e-03,   3.08351250e-05,   4.60006046e-05,\n",
       "         4.92086697e-04,   7.32211665e-03,   3.51159171e-05,\n",
       "         3.75648716e-04,   3.84229395e-05,   4.01846107e-03,\n",
       "         3.80406172e-05,   4.75242261e-06,   3.50252624e-04,\n",
       "         2.54335460e-04,   1.92222653e-04,   1.80561060e-03,\n",
       "         8.92320022e-06,   1.87024478e-05,   8.96639899e-04,\n",
       "         1.21033745e-03,   2.99238154e-05,   1.21033745e-03,\n",
       "         2.23330995e-04,   1.25042542e-04,   2.02146943e-08,\n",
       "         4.36441369e-04,   3.28266203e-06,   7.32211665e-03,\n",
       "         5.43839591e-04,   4.90815872e-03,   1.20721295e-02,\n",
       "         4.01846107e-03,   1.47830928e-03,   1.21033745e-03,\n",
       "         2.34781237e-04,   1.63378507e-03,   3.95930820e-05,\n",
       "         4.32099000e-04,   4.90815872e-03,   3.29003846e-03,\n",
       "         1.33417589e-02,   8.11313753e-04,   1.80561060e-03,\n",
       "         2.75518544e-04,   2.19968419e-02,   1.33417589e-02,\n",
       "         4.44108810e-03,   2.06160310e-04,   2.20537956e-03,\n",
       "         1.99550918e-03,   1.63378507e-03,   1.80561060e-03,\n",
       "         9.26338660e-05,   1.33763032e-03,   1.51991546e-06,\n",
       "         2.40765858e-06,   6.69418734e-07,   1.99550918e-03,\n",
       "         1.63378507e-03,   8.31993521e-06,   7.70014876e-07,\n",
       "         2.97694854e-03,   1.38909783e-06,   4.56607766e-06,\n",
       "         4.92086697e-04,   1.06830082e-05,   4.09044782e-06,\n",
       "         4.90815872e-03,   5.26583439e-07,   2.23406932e-08,\n",
       "         1.99550918e-03,   7.07147612e-05,   9.90940658e-04,\n",
       "         7.34106808e-04,   9.12702267e-07,   2.74190878e-06,\n",
       "         8.11589681e-08,   7.21433271e-05,   2.61493581e-07,\n",
       "         1.80561060e-03,   4.30017034e-06,   7.25172622e-07,\n",
       "         1.83321145e-05,   4.01846107e-03,   9.96076900e-06,\n",
       "         2.89644470e-04,   2.43731996e-03,   1.21033745e-03,\n",
       "         4.44259863e-07,   2.17853877e-06,   4.40827760e-04,\n",
       "         4.28906707e-05,   6.64247036e-04,   1.21033745e-03,\n",
       "         3.96955787e-06,   1.42082778e-07,   1.63378507e-03,\n",
       "         6.01035924e-04,   2.32445295e-04,   8.11313753e-04,\n",
       "         3.82378079e-07,   7.83542043e-06,   1.61807873e-07,\n",
       "         1.84685494e-04,   7.70014876e-07,   9.88382504e-03,\n",
       "         7.36006851e-05,   1.15727644e-05,   5.13494739e-05,\n",
       "         2.68670216e-02,   1.48597226e-05,   3.81390756e-06,\n",
       "         1.00608789e-05,   5.99484320e-03,   6.69418734e-07,\n",
       "         7.45328078e-06,   1.63801365e-04,   1.07625154e-04,\n",
       "         3.33170536e-04,   4.90815872e-03,   7.45328078e-06,\n",
       "         3.38263309e-06,   8.11313753e-04,   2.25575339e-04,\n",
       "         1.47830928e-03,   5.43839591e-04,   3.59180317e-06,\n",
       "         6.46284158e-05,   2.23406932e-08,   2.81084258e-04,\n",
       "         2.83272665e-07,   2.97694854e-03,   6.64247036e-04,\n",
       "         7.32211665e-03,   4.90815872e-03,   3.63605622e-03,\n",
       "         1.33763032e-03,   2.69365602e-03,   1.39943612e-05,\n",
       "         2.44995407e-05,   2.73483049e-05,   6.64247036e-04,\n",
       "         5.42435610e-03,   2.69365602e-03,   2.43102772e-02,\n",
       "         6.62532245e-03,   7.34106808e-04,   6.59340254e-05,\n",
       "         2.97694854e-03,   9.88382504e-03,   9.88382504e-03,\n",
       "         1.22566597e-04,   2.43731996e-03,   1.65875854e-05,\n",
       "         2.10325109e-04,   1.62591299e-05,   5.43839591e-04,\n",
       "         1.01357612e-04,   1.01130304e-07,   6.24161921e-07,\n",
       "         7.10813268e-07,   2.41931553e-04,   1.61807873e-07,\n",
       "         2.23406932e-08,   6.07282997e-08,   2.81811765e-05,\n",
       "         2.01625042e-07,   8.68189286e-07,   2.22830156e-07,\n",
       "         1.02906909e-06,   5.87813465e-07,   4.45258252e-04,\n",
       "         1.01130304e-07,   2.23406932e-08,   8.11589681e-08,\n",
       "         2.01625042e-07,   2.61493581e-07,   4.92086697e-04,\n",
       "         4.03023498e-08,   2.23406932e-08,   2.23406932e-08,\n",
       "         8.11589681e-08,   1.21074948e-07,   2.02078165e-04,\n",
       "         1.77903239e-05,   1.91296551e-06,   1.54661597e-05,\n",
       "         2.97694854e-03,   1.69226763e-05,   1.15727644e-05,\n",
       "         4.37571190e-05,   1.21033745e-03,   9.49950285e-07,\n",
       "         1.24118864e-05,   2.04109130e-04,   1.38551186e-05,\n",
       "         3.64546703e-04,   9.17121234e-05,   1.10083569e-05,\n",
       "         2.23406932e-08,   6.27183739e-05,   7.34106808e-04,\n",
       "         2.10869489e-05,   3.51159171e-05,   4.56607766e-06,\n",
       "         2.33046924e-05,   2.02146943e-08,   1.21347013e-04,\n",
       "         2.61493581e-07,   5.42435610e-03,   1.09799379e-04,\n",
       "         9.35647883e-05,   2.97694854e-03,   8.09218532e-03,\n",
       "         4.45258252e-04,   5.73202708e-05,   2.65400354e-05,\n",
       "         6.62532245e-03,   1.37527580e-06,   2.81084258e-04,\n",
       "         6.62532245e-03,   3.23323967e-04,   4.83591156e-05,\n",
       "         3.29003846e-03,   2.70062788e-04,   6.24161921e-07,\n",
       "         1.02376194e-04,   1.63378507e-03,   1.09515822e-03,\n",
       "         1.09515822e-03,   2.92555504e-04,   9.83619681e-05,\n",
       "         6.05715195e-07,   3.63605622e-03,   1.04714707e-05,\n",
       "         4.44108810e-03,   8.96639899e-04,   6.81178811e-06,\n",
       "         5.74686583e-06,   7.32211665e-03,   3.99910095e-05,\n",
       "         2.45629633e-06,   5.68968196e-06,   3.29003846e-03,\n",
       "         7.10813268e-07,   1.48981905e-06,   2.73483049e-05,\n",
       "         9.90940658e-04,   5.73202708e-05,   3.29003846e-03,\n",
       "         2.69365602e-03,   8.11589681e-08,   6.74400831e-06,\n",
       "         8.11313753e-04,   6.94939523e-06,   8.96639899e-04,\n",
       "         1.69664767e-06,   2.66087388e-06,   2.23406932e-08,\n",
       "         3.79424126e-04,   3.63729279e-07,   3.29003846e-03,\n",
       "         9.17121234e-05,   4.01846107e-03,   1.20721295e-02,\n",
       "         7.32211665e-03,   5.43839591e-04,   1.09233095e-02,\n",
       "         1.75678248e-04,   3.63605622e-03,   8.98960581e-05,\n",
       "         7.34106808e-04,   4.92086697e-04,   3.68210537e-04,\n",
       "         1.09515822e-03,   3.63605622e-03,   5.61852522e-05,\n",
       "         3.17742002e-05,   8.81160398e-05,   4.90815872e-03,\n",
       "         9.88382504e-03,   8.96639899e-04,   6.01035924e-04,\n",
       "         8.13413634e-05,   3.84229395e-05,   1.33763032e-03,\n",
       "         4.69298785e-05,   7.34106808e-04,   8.11313753e-04,\n",
       "         1.47830928e-03,   1.63378507e-03,   3.71910853e-04,\n",
       "         8.94325174e-03,   8.11313753e-04,   2.51804951e-04,\n",
       "         9.90940658e-04,   9.64143199e-05,   8.11313753e-04,\n",
       "         3.63605622e-03,   5.99484320e-03,   1.62956727e-02,\n",
       "         2.43731996e-03,   2.43731996e-03,   1.06830082e-05,\n",
       "         1.33417589e-02,   2.97694854e-03,   4.01846107e-03,\n",
       "         8.09218532e-03,   1.99550918e-03,   3.29003846e-03,\n",
       "         1.12017419e-04,   3.83237478e-04,   8.13413634e-05,\n",
       "         3.29003846e-03,   1.83321145e-05,   6.28807035e-06,\n",
       "         6.74400831e-06,   4.44108810e-03,   1.30482532e-05,\n",
       "         4.93360341e-05,   6.64247036e-04,   1.21033745e-03,\n",
       "         2.74190878e-06,   1.30482532e-05,   2.69365602e-03,\n",
       "         1.17760701e-04,   5.46658683e-06,   3.29003846e-03,\n",
       "         1.33763032e-03,   1.61807873e-07,   4.01846107e-03,\n",
       "         5.43839591e-04,   6.64247036e-04,   1.09515822e-03,\n",
       "         6.07282997e-08,   7.01923611e-06,   2.02146943e-08,\n",
       "         1.58960341e-04,   7.25172622e-07,   5.48073697e-07,\n",
       "         1.42082778e-07,   2.23406932e-08,   2.02146943e-08,\n",
       "         4.03023498e-08,   4.03023498e-08,   2.02146943e-08,\n",
       "         2.23406932e-08,   1.54661597e-05,   2.23406932e-08,\n",
       "         2.23406932e-08,   6.07282997e-08,   2.23406932e-08,\n",
       "         2.02146943e-08,   2.02146943e-08,   2.23406932e-08,\n",
       "         6.07282997e-08,   2.23406932e-08,   6.07282997e-08,\n",
       "         1.42082778e-07,   1.09515822e-03,   1.21074948e-07,\n",
       "         4.03023498e-08,   2.23406932e-08,   2.23406932e-08,\n",
       "         2.23406932e-08,   7.32211665e-03,   3.07555202e-04,\n",
       "         1.47830928e-03,   2.20537956e-03,   1.80094935e-02,\n",
       "         3.01465072e-04,   1.21033745e-03,   1.38193434e-04,\n",
       "         6.62532245e-03,   5.35834123e-06,   1.80561060e-03,\n",
       "         9.90940658e-04,   1.63378507e-03,   1.99550918e-03,\n",
       "         7.32211665e-03,   4.92086697e-04,   9.76353323e-06,\n",
       "         1.21033745e-03,   5.42435610e-03,   4.01846107e-03,\n",
       "         1.21033745e-03,   1.21033745e-03,   1.32774800e-04,\n",
       "         4.80018421e-06,   2.20537956e-03,   2.04637407e-05,\n",
       "         3.63605622e-03,   1.08706828e-04,   1.33763032e-03,\n",
       "         1.81028569e-04,   8.09218532e-03,   1.12017419e-04,\n",
       "         1.57785966e-05,   3.29003846e-03,   5.42435610e-03,\n",
       "         1.29518599e-06,   5.43839591e-04,   6.64247036e-04,\n",
       "         4.92086697e-04,   1.96105888e-04,   3.29003846e-03,\n",
       "         1.63378507e-03,   7.73742839e-05,   1.23798440e-04,\n",
       "         4.01846107e-03,   1.09233095e-02,   2.43731996e-03,\n",
       "         1.26626232e-05,   1.90309956e-04,   2.02146943e-08,\n",
       "         3.46767485e-04,   7.91416570e-06,   5.42435610e-03,\n",
       "         9.26338660e-05,   3.68210537e-04,   3.05283166e-05,\n",
       "         1.20721295e-02,   6.52779560e-05,   4.50897293e-05,\n",
       "         2.96926341e-02,   1.09233095e-02,   1.30820312e-06,\n",
       "         9.38069957e-06,   8.96639899e-04,   3.75648716e-04,\n",
       "         1.55812652e-04,   1.09233095e-02,   3.08351250e-05,\n",
       "         1.42082778e-07,   4.01846107e-03,   4.01846107e-03,\n",
       "         1.80561060e-03,   1.80561060e-03,   1.33118450e-05,\n",
       "         7.34106808e-04,   3.42547280e-07,   1.99550918e-03,\n",
       "         9.83619681e-05,   1.09515822e-03,   9.90940658e-04,\n",
       "         1.63378507e-03,   1.09515822e-03,   1.47830928e-03,\n",
       "         1.98076643e-04,   1.33763032e-03,   1.08988195e-05,\n",
       "         9.90940658e-04,   7.99370615e-06,   6.52779560e-05,\n",
       "         2.97694854e-03,   1.21033745e-03,   3.63605622e-03,\n",
       "         1.02376194e-04,   1.47830928e-03,   6.22550461e-06,\n",
       "         4.44108810e-03,   4.44108810e-03,   4.90815872e-03,\n",
       "         4.56607766e-06,   3.02245484e-05,   1.25366243e-05,\n",
       "         3.88090890e-05,   1.54262250e-04,   3.40780782e-05,\n",
       "         9.90940658e-04,   2.02146943e-08,   8.57331661e-06,\n",
       "         1.34804352e-06,   8.09218532e-03,   2.02146943e-08,\n",
       "         1.85642846e-06,   8.11589681e-08,   3.29003846e-03,\n",
       "         4.03023498e-08,   4.86097797e-07,   3.48565012e-06,\n",
       "         2.22830156e-07,   4.21502131e-06,   6.64247036e-04,\n",
       "         2.23406932e-08,   2.23406932e-08,   1.02641221e-05,\n",
       "         1.25366243e-05,   8.25847265e-07,   1.74380523e-05,\n",
       "         2.31325183e-06,   2.23406932e-08,   2.23406932e-08,\n",
       "         6.72659497e-05,   6.07282997e-08,   3.63605622e-03,\n",
       "         1.98589420e-05,   8.92320022e-06,   5.34450804e-05,\n",
       "         2.69365602e-03,   1.01619900e-05,   8.25847265e-07,\n",
       "         3.29003846e-03,   3.63605622e-03,   2.23406932e-08,\n",
       "         2.37754761e-05,   1.40985194e-04,   3.02245484e-05,\n",
       "         8.96639899e-04,   2.43731996e-03,   5.09701320e-06,\n",
       "         1.42082778e-07,   2.78287365e-04,   4.45258252e-04,\n",
       "         5.29132799e-05,   2.20043391e-06,   4.03023498e-08,\n",
       "         3.82378079e-07,   2.02146943e-08,   9.26338660e-05,\n",
       "         1.82437897e-07,   9.90940658e-04,   2.02146943e-08,\n",
       "         8.57331661e-06,   1.34804352e-06,   8.09218532e-03,\n",
       "         2.02146943e-08,   1.85642846e-06,   8.11589681e-08,\n",
       "         3.29003846e-03,   4.03023498e-08,   4.86097797e-07,\n",
       "         3.48565012e-06,   2.22830156e-07,   4.21502131e-06,\n",
       "         6.64247036e-04,   2.23406932e-08,   2.23406932e-08,\n",
       "         1.02641221e-05,   1.25366243e-05,   8.25847265e-07,\n",
       "         1.74380523e-05,   2.31325183e-06,   2.23406932e-08,\n",
       "         2.23406932e-08,   6.72659497e-05,   6.07282997e-08,\n",
       "         3.63605622e-03,   1.98589420e-05,   8.92320022e-06,\n",
       "         5.34450804e-05,   2.69365602e-03,   1.01619900e-05,\n",
       "         8.25847265e-07,   3.29003846e-03,   3.63605622e-03,\n",
       "         2.23406932e-08,   2.37754761e-05,   1.40985194e-04,\n",
       "         3.02245484e-05,   8.96639899e-04,   2.43731996e-03,\n",
       "         5.09701320e-06,   1.42082778e-07,   2.78287365e-04,\n",
       "         4.45258252e-04,   5.29132799e-05,   2.20043391e-06,\n",
       "         4.03023498e-08,   3.82378079e-07,   2.02146943e-08,\n",
       "         9.26338660e-05,   1.82437897e-07,   1.82847812e-04,\n",
       "         8.85727853e-07,   1.82847812e-04,   2.02146943e-08,\n",
       "         3.01465072e-04,   5.41219444e-06,   6.07282997e-08,\n",
       "         4.74015382e-05,   1.82847812e-04,   2.23406932e-08,\n",
       "         2.23406932e-08,   3.18564377e-06,   1.63012126e-06,\n",
       "         3.82378079e-07,   3.54688304e-05,   6.01035924e-04,\n",
       "         2.35998381e-06,   8.11589681e-08,   1.91296551e-06,\n",
       "         3.46767485e-04,   5.78963600e-05,   2.05167055e-06,\n",
       "         9.10346066e-06,   3.18564377e-06,   8.15518990e-06,\n",
       "         2.02146943e-08])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#W_t = W_t / W_t.sum()\n",
    "W_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((128,), batch_shape=(128,128))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dense(26, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model = Model(inp,out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 26)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model.layers[2].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "\n",
    "sgd = adam(0.001,epsilon=1e-7)\n",
    "\n",
    "unary_model.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46936 samples, validate on 5216 samples\n",
      "Epoch 1/20\n",
      "0s - loss: 1.3034 - acc: 0.6475 - val_loss: 0.9553 - val_acc: 0.7406\n",
      "Epoch 2/20\n",
      "0s - loss: 0.7520 - acc: 0.7925 - val_loss: 0.7635 - val_acc: 0.7916\n",
      "Epoch 3/20\n",
      "0s - loss: 0.6015 - acc: 0.8325 - val_loss: 0.6616 - val_acc: 0.8229\n",
      "Epoch 4/20\n",
      "0s - loss: 0.5137 - acc: 0.8554 - val_loss: 0.5828 - val_acc: 0.8395\n",
      "Epoch 5/20\n",
      "0s - loss: 0.4530 - acc: 0.8692 - val_loss: 0.5315 - val_acc: 0.8482\n",
      "Epoch 6/20\n",
      "0s - loss: 0.4098 - acc: 0.8821 - val_loss: 0.5046 - val_acc: 0.8593\n",
      "Epoch 7/20\n",
      "0s - loss: 0.3750 - acc: 0.8910 - val_loss: 0.4845 - val_acc: 0.8625\n",
      "Epoch 8/20\n",
      "0s - loss: 0.3481 - acc: 0.8976 - val_loss: 0.4757 - val_acc: 0.8666\n",
      "Epoch 9/20\n",
      "0s - loss: 0.3240 - acc: 0.9049 - val_loss: 0.4596 - val_acc: 0.8719\n",
      "Epoch 10/20\n",
      "0s - loss: 0.3033 - acc: 0.9113 - val_loss: 0.4575 - val_acc: 0.8712\n",
      "Epoch 11/20\n",
      "0s - loss: 0.2849 - acc: 0.9158 - val_loss: 0.4569 - val_acc: 0.8719\n",
      "Epoch 12/20\n",
      "0s - loss: 0.2693 - acc: 0.9197 - val_loss: 0.4556 - val_acc: 0.8691\n",
      "Epoch 13/20\n",
      "0s - loss: 0.2554 - acc: 0.9232 - val_loss: 0.4389 - val_acc: 0.8756\n",
      "Epoch 14/20\n",
      "0s - loss: 0.2410 - acc: 0.9283 - val_loss: 0.4395 - val_acc: 0.8738\n",
      "Epoch 15/20\n",
      "0s - loss: 0.2293 - acc: 0.9320 - val_loss: 0.4341 - val_acc: 0.8765\n",
      "Epoch 16/20\n",
      "0s - loss: 0.2184 - acc: 0.9349 - val_loss: 0.4210 - val_acc: 0.8815\n",
      "Epoch 17/20\n",
      "0s - loss: 0.2075 - acc: 0.9381 - val_loss: 0.4382 - val_acc: 0.8762\n",
      "Epoch 18/20\n",
      "0s - loss: 0.1992 - acc: 0.9388 - val_loss: 0.4384 - val_acc: 0.8744\n",
      "Epoch 19/20\n",
      "0s - loss: 0.1894 - acc: 0.9427 - val_loss: 0.4255 - val_acc: 0.8823\n",
      "Epoch 20/20\n",
      "0s - loss: 0.1800 - acc: 0.9456 - val_loss: 0.4230 - val_acc: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68bcc5bfd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model.fit(X_n,y_n,batch_size=128,validation_split=0.10,verbose=2, nb_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((128,), (1,128))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "             weights=unary_model.layers[1].get_weights())(inp)\n",
    "out1 = Dense(26, activation='linear', bias=False,\n",
    "             weights = unary_model.layers[2].get_weights())(out1) \n",
    "\n",
    "unary_model1 = Model(inp,out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unary_model1.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.34048787,  -3.9013896 ,  -1.22336733,  -2.52211809,\n",
       "         -4.38753939, -12.0569582 ,  -3.11565065, -11.06820774,\n",
       "        -13.33045006,  -9.76701736,  -8.97757053,  -8.02042866,\n",
       "         -9.29939079,  -2.44977832,   5.64803791, -10.67316437,\n",
       "         -5.57821941,  -6.02261019,  -7.73568821,  -9.66280365,\n",
       "         -3.92789459,  -9.8085146 , -14.479105  , -15.86546421,\n",
       "         -4.8299408 , -10.92585754]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "unary_model1.predict(X_n[0].reshape(1,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34048787"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model1.predict(X_n[0].reshape(1,128))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = {}\n",
    "for x in y_tr:\n",
    "    for k in range(len(x)-1):\n",
    "        if (x[k],x[k+1]) in probs:\n",
    "            probs[(x[k],x[k+1])] += 1\n",
    "        else:\n",
    "            probs[(x[k],x[k+1])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_w = np.zeros(26**2)\n",
    "bin_w[0] = 1\n",
    "\n",
    "for k in range(1,26**2):\n",
    "    bin_w[k] = 0.5 + np.log(W_t[k]) - np.log(W_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_w  = bin_w / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014755393602516324"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def soft_max(y):\n",
    "    num = np.exp(dot(bin_w,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unary features only vs unary and binary model:\n",
      "Unary only average Hamming loss:  95.5184267573  %\n",
      "Unary only complete percent correct: 73.8165680473  %\n",
      ".................................................\n",
      "Unary and binary average Hamming loss:  97.8906460896  %\n",
      "Unary and binary complete percent correct: 90.9763313609  %\n"
     ]
    }
   ],
   "source": [
    "'''crf_u = CRF(feat_func, 1+26**2, 26,1, W='U')\n",
    "crf_b = CRF(feat_func, 1+26**2, 26, 1,best_W)\n",
    "\n",
    "acc_test1, acc_test2 = np.zeros(y_ts.shape[0]),np.zeros(y_ts.shape[0])\n",
    "            \n",
    "for n in range(y_ts.shape[0]):\n",
    "    acc_test1[n] = 1 - hamming(crf_u.MAP(X_ts[n]), y_ts[n])\n",
    "    acc_test2[n] = 1 - hamming(crf_b.MAP(X_ts[n]), y_ts[n])'''   \n",
    "    \n",
    "print('Unary features only vs unary and binary model:')\n",
    "print('Unary only average Hamming loss: ', 100*acc_test1.mean(), ' %')\n",
    "print('Unary only complete percent correct:',\n",
    "      100*acc_test1[acc_test1 == 1].sum() / y_ts.shape[0], ' %')\n",
    "print('.................................................')\n",
    "print('Unary and binary average Hamming loss: ', 100*acc_test2.mean(), ' %')\n",
    "print('Unary and binary complete percent correct:',\n",
    "      100*acc_test2[acc_test2 == 1].sum() / y_ts.shape[0], ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouerninp\n"
     ]
    }
   ],
   "source": [
    "print(''.join([chr(x + 97) for x in crf_u.MAP(X_ts[14])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overning\n"
     ]
    }
   ],
   "source": [
    "print(''.join([chr(x + 97) for x in y_ts[14]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overning\n"
     ]
    }
   ],
   "source": [
    "print(''.join([chr(x + 97) for x in crf_b.MAP(X_ts[14])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overminq\n"
     ]
    }
   ],
   "source": [
    "print(''.join([chr(x + 97) for x in clf_s.predict(X_ts[14])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f68b54b9ef0>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAACWCAYAAABTowcXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbEcjgGjgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68b56eff28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "ax1 = fig.add_subplot(8,12,1)\n",
    "ax1.imshow(np.int32(X_ts[14][0].reshape((16,8))))\n",
    "ax2 = fig.add_subplot(8,12,2)\n",
    "ax2.imshow(np.int32(X_ts[14][1].reshape((16,8))))\n",
    "ax3 = fig.add_subplot(8,12,3)\n",
    "ax3.imshow(np.int32(X_ts[14][2].reshape((16,8))))\n",
    "ax3 = fig.add_subplot(8,12,4)\n",
    "ax3.imshow(np.int32(X_ts[14][3].reshape((16,8))))\n",
    "ax3 = fig.add_subplot(8,12,5)\n",
    "ax3.imshow(np.int32(X_ts[14][4].reshape((16,8))))\n",
    "ax3 = fig.add_subplot(8,12,6)\n",
    "ax3.imshow(np.int32(X_ts[14][5].reshape((16,8))))\n",
    "ax3 = fig.add_subplot(8,12,7)\n",
    "ax3.imshow(np.int32(X_ts[14][6].reshape((16,8))))\n",
    "ax3 = fig.add_subplot(8,12,8)\n",
    "ax3.imshow(np.int32(X_ts[14][7].reshape((16,8))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node = 0\n",
    "for k in range(y_tr.shape[0]):\n",
    "    for j in range(y_tr[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "for k in range(y_ts.shape[0]):\n",
    "    for j in range(y_ts[k].shape[0]):\n",
    "        num_node += 1\n",
    "\n",
    "X_s, y_s = np.zeros((num_node,128)), np.zeros(num_node,dtype='i4')\n",
    "l = 0\n",
    "for k in range(y_tr.shape[0]):\n",
    "    for j in range(y_tr[k].shape[0]):\n",
    "        X_s[l] = X_tr[k][j,:]\n",
    "        y_s[l] = y_tr[k][j]\n",
    "        l+= 1\n",
    "for k in range(y_ts.shape[0]):\n",
    "    for j in range(y_ts[k].shape[0]):\n",
    "        X_s[l] = X_ts[k][j,:]\n",
    "        y_s[l] = y_ts[k][j]\n",
    "        l+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_s = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_s.fit(X_s,y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Avg Hamming:  87.352387504 %\n",
      "SVC Zero-One loss:  46.0059171598\n"
     ]
    }
   ],
   "source": [
    "ham_svc = np.zeros(y_ts.shape[0])\n",
    "\n",
    "for k in range(y_ts.shape[0]):\n",
    "    ham_svc[k] = accuracy_score(y_ts[k], clf_s.predict(X_ts[k]))\n",
    "    \n",
    "print('SVC Avg Hamming: ', 100*ham_svc.mean(), '%')\n",
    "print('SVC Zero-One loss: ', 100*ham_svc[ham_svc==1].sum()/y_ts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model:</th>\n",
       "      <th>Average Hamming:</th>\n",
       "      <th>Zero-One:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unary Only</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unary+Binary</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model:        Average Hamming:  Zero-One:\n",
       "SVC                      0.874      0.460\n",
       "Unary Only               0.955      0.738\n",
       "Unary+Binary             0.979      0.910"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamm = [0.874, 0.955, 0.979]\n",
    "zo = [0.460, 0.738, 0.91]\n",
    "models = ['SVC', 'Unary Only', 'Unary+Binary']\n",
    "met = ['Average Hamming', 'Zero-One']\n",
    "res_df = pd.DataFrame(hamm)\n",
    "res_df.columns = ['Average Hamming:']\n",
    "res_df['Zero-One:'] = zo\n",
    "res_df.columns.name = 'Model:'\n",
    "res_df.index = models\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['color: red' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_4696e7e6_426f_11e7_bda1_d05099aa5affrow2_col0 {\n",
       "            \n",
       "                color:  green;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_4696e7e6_426f_11e7_bda1_d05099aa5affrow2_col1 {\n",
       "            \n",
       "                color:  green;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5aff\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th class=\"index_name level0\" >\n",
       "                  Model:\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col0\" colspan=1>\n",
       "                  Average Hamming:\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col1\" colspan=1>\n",
       "                  Zero-One:\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5aff\"\n",
       "                 class=\"row_heading level0 row0\" rowspan=1>\n",
       "                    SVC\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5affrow0_col0\"\n",
       "                 class=\"data row0 col0\" >\n",
       "                    0.874\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5affrow0_col1\"\n",
       "                 class=\"data row0 col1\" >\n",
       "                    0.46\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5aff\"\n",
       "                 class=\"row_heading level0 row1\" rowspan=1>\n",
       "                    Unary Only\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5affrow1_col0\"\n",
       "                 class=\"data row1 col0\" >\n",
       "                    0.955\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5affrow1_col1\"\n",
       "                 class=\"data row1 col1\" >\n",
       "                    0.738\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5aff\"\n",
       "                 class=\"row_heading level0 row2\" rowspan=1>\n",
       "                    Unary+Binary\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5affrow2_col0\"\n",
       "                 class=\"data row2 col0\" >\n",
       "                    0.979\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_4696e7e6_426f_11e7_bda1_d05099aa5affrow2_col1\"\n",
       "                 class=\"data row2 col1\" >\n",
       "                    0.91\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x7f68b515a828>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
