{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5105)\n",
      "/home/james/anaconda3/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import log, exp, zeros, dot, array\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import timeit\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scipy.io\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(x):\n",
    "    \n",
    "    m = x.max()\n",
    "    x_s = x - m\n",
    "    return m + log((exp(x_s)).sum())\n",
    "\n",
    "\n",
    "def label_seq(l,j):\n",
    "    '''Creates a list of all posible length l sequences taking values in\n",
    "       {0,1,...,j-1}. Out put list is of length j^l'''\n",
    "    \n",
    "    \n",
    "    return list(product(list(range(j)), repeat=l))\n",
    "\n",
    "def find_legit_vals(k,l,n):\n",
    "    '''Finds the only possible label pairs (i,j) with f_k(i,j,x,t) != 0.\n",
    "       Will be used to speed up gradient computation.\n",
    "       l: Number of labels\n",
    "       n: Size of a nodes feature vector'''\n",
    "    \n",
    "    res = []\n",
    "    k_s = k - n*l\n",
    "    \n",
    "    if k_s < 0:  #Means k is in the Unary features\n",
    "        \n",
    "        i = k // n\n",
    "        \n",
    "        for j in range(l):\n",
    "            \n",
    "            res.append((i,j))\n",
    "            \n",
    "    else:  #Means k is a Binary feature\n",
    "        \n",
    "        f = (k_s // n)\n",
    "        j = f % l\n",
    "        i = f // l\n",
    "        res.append((i,j))  \n",
    "    \n",
    "    return res\n",
    "\n",
    "C_init = np.array([1,1,0])\n",
    "\n",
    "class CRF(object):\n",
    "    \n",
    "    def __init__(self, feature_function, K, L, lb=1, W = 'none'):\n",
    "        ''' If our labels belong to space L and our observations belonging to X amd\n",
    "            then length of our chain is T (call {0,1, ... , T-1} = T') then \n",
    "            feature_functions is a vector valued function, f: L^2 x X x T' --> R^K\n",
    "            i.e. f(i,j,x,t) is a K-d real valued vector and has component functions of the form\n",
    "            f_k(i,j,x,t) to be specified, think of (i,j) = (y_t, y_t-1). It will have an optional\n",
    "            keyword argument 'project' which defaults to -1, if a positive integer k,\n",
    "            it will project onto the k-th component.\n",
    "            \n",
    "            K: # of Features\n",
    "            \n",
    "            L: Number of labels. Will assume labels have been encoded as integers in {0,...,L-1} \n",
    "            \n",
    "            lamb: L2 regularization constant'''\n",
    "        \n",
    "        self.K = K\n",
    "        self.L = L\n",
    "        self.N = K//L - L\n",
    "        self.Lambda = lb\n",
    "        self.f_x = feature_function\n",
    "        \n",
    "        if type(W) == str:\n",
    "            if W == 'none':\n",
    "                self.W = np.random.randn(K)\n",
    "            if W == 'U':\n",
    "                self.W = np.zeros(K)\n",
    "                self.W[0] = 1\n",
    "                \n",
    "            if W == 'B':\n",
    "                self.W = np.ones(K)\n",
    "                self.W[1:] = np.random.randn(K-1)\n",
    "        else:\n",
    "            self.W = W\n",
    "            \n",
    "    def get_weights(self):\n",
    "        \n",
    "        return np.asarray(self.W)\n",
    "        \n",
    "    def  log_forward(self, x):\n",
    "        '''This computes the log(alphas) as in the forward-backward algorithm in order to\n",
    "           be used for inference tasks later on.\n",
    "           x is an observation.'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]\n",
    "        alphas = zeros((T, self.L))\n",
    "        \n",
    "        # Initialization\n",
    "        \n",
    "        for l in range(self.L):\n",
    "            \n",
    "            alphas[0,l] = dot(self.W, f(l,0,x,0,self.N,self.L))\n",
    "            \n",
    "        # Recursion\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                psi = array([dot(self.W, f(l,i,x,t,self.N,self.L)) for i in range(self.L)])\n",
    "                \n",
    "                alphas[t,l] = log_sum_exp(psi + alphas[t-1])\n",
    "            \n",
    "        return alphas\n",
    "    \n",
    "        \n",
    "    def log_backward(self, x):\n",
    "        '''This computes the log(betas) as in the forward-backward algorithm in order to\n",
    "           be used for inference tasks later on.\n",
    "           x is an observation.'''\n",
    "        \n",
    "        # Initialization\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]\n",
    "        betas = np.ones((T, self.L))\n",
    "      \n",
    "        # Recursion\n",
    "        \n",
    "        for t in range(T-2,-1,-1):\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                psi = array([dot(self.W, f(i,l,x,t+1,self.N,self.L)) for i in range(self.L)])\n",
    "                \n",
    "                betas[t][l] = log_sum_exp(psi + betas[t+1])\n",
    "                \n",
    "        return betas\n",
    "    \n",
    "    \n",
    "    def log_partition(self, x):\n",
    "        '''Efficient computation of the log of the partition function Z(x) appearing in CRF model.\n",
    "           Input an observation and inital label (for forward algorithm) and output is log(Z(x))'''\n",
    "        \n",
    "        alphas = self.log_forward(x)\n",
    "        \n",
    "        return log_sum_exp(alphas[-1])\n",
    "    \n",
    "    \n",
    "    def MAP(self, x):\n",
    "        '''Viterbi algortithm for computing the most likely label of a sequence with\n",
    "           given observation vector x using maximum a posteriori estimation. Using log\n",
    "           sum version for numeric stability'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]   \n",
    "        # Initialization\n",
    "        \n",
    "        deltas = np.zeros((T, self.L))\n",
    "        delt_arg = np.zeros((T, self.L))\n",
    "        \n",
    "        for l in range(self.L):\n",
    "            \n",
    "            deltas[0][l] = dot(self.W, f(l,0,x,0,self.N,self.L))  # Not sure about this.\n",
    "            \n",
    "        # Recursion\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                psi = array([dot(self.W, f(l,i,x,t,self.N,self.L)) for i in range(self.L)])\n",
    "                \n",
    "                deltas[t][l] = (psi + deltas[t-1]).max()\n",
    "                delt_arg[t][l] = (psi + deltas[t-1]).argmax()\n",
    "            \n",
    "        map_lab = np.zeros(T, dtype='i4')\n",
    "        map_lab[-1] = deltas[-1].argmax()\n",
    "        \n",
    "        for t in range(T-2,-1,-1):\n",
    "            \n",
    "            map_lab[t] = delt_arg[t+1][map_lab[t+1]]\n",
    "            \n",
    "                \n",
    "        return tuple(map_lab)\n",
    "        \n",
    "        \n",
    "    def marginal(self,i,j,x,t):\n",
    "        '''Using the forward backward algorithm to compute the marginal p(y_t-1=i,y_t=j|x)'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        alphas = self.log_forward(x)\n",
    "        betas = self.log_backward(x)\n",
    "        psi = dot(self.W,f(j,i,x,t))\n",
    "        psi_b = np.array([dot(self.W,f(k,0,x,0,self.N,self.L)) for k in range(self.L)])\n",
    "        log_joint = alphas[t-1][i] + psi + betas[t][j] - log_sum_exp(psi_b + betas[0])\n",
    "        \n",
    "        return exp(log_joint)\n",
    "                       \n",
    "    def naive_comp(self, x, out='Z'):\n",
    "        '''Brute force computation of log(Z(x)) or MAP (if out = 'MAP')'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        T = x.shape[0]\n",
    "        \n",
    "        # Get List of all possible label sequences\n",
    "        \n",
    "        lab_seq = label_seq(T, self.L)\n",
    "        \n",
    "        psi = np.zeros(len(lab_seq))\n",
    "        \n",
    "        for k in range(len(lab_seq)):\n",
    "            \n",
    "            lab = lab_seq[k]\n",
    "            temp = np.zeros(T)\n",
    "            temp[0] = dot(self.W, f(lab[0], 0, x, 0,self.N,self.L))\n",
    "            \n",
    "            for t in range(1,T):\n",
    "                \n",
    "                temp[t] = dot(self.W, f(lab[t], lab[t-1], x, t))\n",
    "            \n",
    "            psi[k] = temp.sum()\n",
    "        \n",
    "        arg_m_i = psi.argmax()\n",
    "        \n",
    "        return log_sum_exp(psi) if out == 'Z' else lab_seq[arg_m_i]\n",
    "    \n",
    "    \n",
    "    def log_pseudo_marg(self, i, j, k, x, t):\n",
    "        '''Computes the log probability for pseudolikelihood training.\n",
    "            i = y_t\n",
    "            j = y_t-1\n",
    "            k = y_t+1'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        Z_c = np.zeros(self.L)\n",
    "        L = self.L\n",
    "        M = self.N\n",
    "        W = self.W[1:]\n",
    "        W_u = self.W[:L*M]\n",
    "        if t == 0:\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                Z_c[l] = f(l,0,x,t,M,L)[0] + W[L*k + l]\n",
    "            \n",
    "            return f(i,0,x,t,M,L)[0] + W[L*k + i] - log_sum_exp(Z_c)\n",
    "        \n",
    "        elif 0 < t and t < x.shape[0]-1:\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                Z_c[l] = f(l,0,x,t,M,L)[0] + W[L*l + j] + W[L*k + l]\n",
    "            \n",
    "            return f(i,0,x,t,M,L)[0] + W[L*k + i] + W[L*i + j] - log_sum_exp(Z_c)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for l in range(self.L):\n",
    "                \n",
    "                Z_c[l] = f(l,0,x,t,M,L)[0] + W[L*l + j]\n",
    "            \n",
    "            return f(i,0,x,t,M,L)[0] + W[L*i + j] - log_sum_exp(Z_c)\n",
    "            \n",
    "    def grad_pll(self, X, Y):\n",
    "        '''Gradient of the (negayive) - pseudo log likelihood.'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        lb = self.Lambda\n",
    "        L = self.L\n",
    "        M = self.N\n",
    "        #grad_u = np.zeros(M*L)\n",
    "        grad_b = np.zeros(L**2)\n",
    "        \n",
    "        for n in range(X.shape[0]):\n",
    "            \n",
    "            T_n = X[n].shape[0]\n",
    "            \n",
    "            for t in range(T_n):\n",
    "                \n",
    "                E = np.zeros(L**2)\n",
    "                #E_u = np.zeros(M*L)\n",
    "                for l in range(self.L):\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        \n",
    "                        E += (np.exp(self.log_pseudo_marg(l,0,Y[n][t+1],X[n],0)) * \n",
    "                              f(Y[n][t+1],l,X[n],0,M,L)[1:])\n",
    "                        #E_u += (np.exp(self.log_pseudo_marg(l,0,Y[n][t+1],X[n],0)) * \n",
    "                                #f(l,0,X[n],0,M,L)[:M*L])\n",
    "                        \n",
    "                    elif 0 < t and t < T_n - 1:\n",
    "                        \n",
    "                        E += (np.exp(self.log_pseudo_marg(l,Y[n][t-1],Y[n][t+1],X[n],t))*\n",
    "                              (f(Y[n][t+1],l,X[n],t,M,L)[1:] +\n",
    "                                f(l,Y[n][t-1],X[n],t,M,L)[1:]))\n",
    "                        #E_u += (np.exp(self.log_pseudo_marg(l,Y[n][t-1],Y[n][t+1],X[n],t))*\n",
    "                                #f(l,0,X[n],t,M,L)[:M*L])\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        E += np.exp(self.log_pseudo_marg(l,Y[n][t-1],0,X[n],t)) * f(l,Y[n][t-1],X[n],t,M,L)[1:]\n",
    "                        #E_u += np.exp(self.log_pseudo_marg(l,Y[n][t-1],0,X[n],t)) * f(l,0,X[n],t,M,L)[:M*L]\n",
    "                    \n",
    "                        \n",
    "                if t == 0:\n",
    "                    \n",
    "                    grad_b += f(Y[n][t+1], Y[n][t],X[n],t,M,L)[1:]-E\n",
    "                    \n",
    "                elif 0 < t and t < T_n-1:\n",
    "                    \n",
    "                    grad_b += f(Y[n][t+1],Y[n][t],X[n],t,M,L)[1:]+f(Y[n][t],Y[n][t-1],X[n],t,M,L)[1:]-E\n",
    "                    \n",
    "                else: \n",
    "                    \n",
    "                    grad_b += f(Y[n][t],Y[n][t-1],X[n],t,M,L)[1:]-E\n",
    "                    \n",
    "                #grad_u += f(Y[n][t],0,X[n],t,M,L)[:M*L]-E_u\n",
    "                \n",
    "                    \n",
    "        return lb * self.W[1:] - grad_b   \n",
    "        \n",
    "    \n",
    "    def gradient(self, X, Y):\n",
    "        ''' Creates the gradient vector of the log-likelihood. \n",
    "            X, Y: Are arrays containing training examples.'''\n",
    "        \n",
    "        f = self.f_x\n",
    "        lamb = self.Lambda\n",
    "        grad = np.zeros(self.K)\n",
    "        \n",
    "        for k in range(self.K):\n",
    "            \n",
    "            val_pair = find_legit_vals(k, self.L, X.shape[-1])\n",
    "            first_term = np.zeros((X.shape[0],T))\n",
    "            \n",
    "            for n in range(X.shape[0]):\n",
    "                \n",
    "                T = X[n].shape[0]\n",
    "                for t in range(T):\n",
    "                    \n",
    "                    first_term[n][t] = f(Y[n][t], Y[n][t-1], X[n], t, project=k)\n",
    "            \n",
    "            sec_term = np.zeros((X.shape[0],self.T))\n",
    "            \n",
    "            for n in range(X.shape[0]):\n",
    "                \n",
    "                for t in range(T):\n",
    "                    \n",
    "                    marginals = np.zeros(len(val_pair))\n",
    "                        \n",
    "                    for j in range(len(val_pair)):\n",
    "                        \n",
    "                        y, y_p = val_pair[j]\n",
    "                        marginals[j] = (f(y, y_p, X[n], t, project=k) * \n",
    "                                        self.marginal(y, y_p, X[n], t))\n",
    "                    \n",
    "                    sec_term[n][t] = marginals.sum()\n",
    "                    \n",
    "            grad[k] = (first_term + sec_term).sum() - self.W[k] * lamb\n",
    "            print(k)\n",
    "        return grad\n",
    "    \n",
    "    \n",
    "    def gradient_f(self, X, Y):\n",
    "        \n",
    "        f = self.f_x\n",
    "        lamb = self.Lambda\n",
    "        grad_f = np.zeros(self.K)\n",
    "        lab_pairs = label_seq(2,self.L)\n",
    "        \n",
    "        for n in range(X.shape[0]):\n",
    "            \n",
    "            T = X[n].shape[0]\n",
    "            grad = np.zeros(self.K)\n",
    "            x, y = X[n], Y[n]\n",
    "            \n",
    "            for t in range(T):\n",
    "            \n",
    "                grad = grad + f(y[t],y[t-1],x,t)\n",
    "        \n",
    "            for pair in lab_pairs:\n",
    "                print(pair)\n",
    "                y, y_p = pair[0], pair[1]\n",
    "                grad_temp = np.zeros(self.K)\n",
    "            \n",
    "                for t in range(T):\n",
    "                \n",
    "                    marg = self.marginal(y,y_p,x,t)\n",
    "                    grad_temp = grad_temp + (marg*f(y,y_p,x,t))\n",
    "        \n",
    "                grad = grad - grad_temp\n",
    "            \n",
    "            grad_f = grad_f + grad\n",
    "    \n",
    "        return lamb * self.W  - grad_f\n",
    "    \n",
    "    def reg_neg_ll(self, X, Y):\n",
    "        \n",
    "        f = self.f_x\n",
    "        res = 0\n",
    "        for n in range(X.shape[0]):\n",
    "            \n",
    "            T = X[n].shape[0]\n",
    "            s = 0\n",
    "            \n",
    "            for t in range(T):\n",
    "            \n",
    "                s += np.dot(self.W,f(Y[n][t],Y[n][t-1],X[n],t))\n",
    "            \n",
    "            res += self.log_partition(X[n]) - s\n",
    "         \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel01_data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label_tr', 'videoId_te', 'BOF_tr_M', 'videoId_tr', 'label_te', 'BOF_te_M', 'BOF_tr_K', '__version__', '__globals__', '__header__', 'BOF_te_K'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01],\n",
       "       [  9.93013661e-17,   9.93013661e-17,   9.93013661e-17,\n",
       "          9.93013661e-17,   9.93013661e-17,   9.93013661e-17,\n",
       "          9.93013661e-17,   9.93013661e-17,   9.93013661e-17,\n",
       "          9.93013661e-17,   9.93013661e-17,   9.93013661e-17,\n",
       "          9.93013661e-17,   9.93013661e-17,   9.93013661e-17,\n",
       "          9.93013661e-17,   9.93013661e-17,   8.94427191e-01,\n",
       "          9.93013661e-17,   9.93013661e-17,   9.93013661e-17,\n",
       "          4.47213595e-01,   9.93013661e-17,   9.93013661e-17,\n",
       "          9.93013661e-17,   9.93013661e-17,   9.93013661e-17,\n",
       "          9.93013661e-17,   9.93013661e-17,   9.93013661e-17],\n",
       "       [  6.32351695e-18,   6.32351695e-18,   2.84785886e-02,\n",
       "          6.32351695e-18,   5.69571772e-02,   6.32351695e-18,\n",
       "          6.32351695e-18,   1.70871532e-01,   7.40443303e-01,\n",
       "          3.70221652e-01,   6.32351695e-18,   1.42392943e-01,\n",
       "          2.27828709e-01,   5.69571772e-02,   6.32351695e-18,\n",
       "          2.84785886e-02,   1.99350120e-01,   3.70221652e-01,\n",
       "          2.84785886e-02,   2.84785886e-02,   6.32351695e-18,\n",
       "          8.54357658e-02,   1.13914354e-01,   6.32351695e-18,\n",
       "          6.32351695e-18,   6.32351695e-18,   6.32351695e-18,\n",
       "          5.69571772e-02,   5.69571772e-02,   6.32351695e-18],\n",
       "       [  1.71397793e-02,   5.14193378e-02,   3.42795585e-02,\n",
       "          3.42795585e-02,   1.19978455e-01,   1.88537572e-01,\n",
       "          3.80579551e-18,   1.19978455e-01,   5.65612715e-01,\n",
       "          4.11354702e-01,   3.42795585e-02,   3.77075144e-01,\n",
       "          2.05677351e-01,   3.42795585e-02,   3.80579551e-18,\n",
       "          1.71397793e-01,   2.22817130e-01,   3.25655806e-01,\n",
       "          6.85591170e-02,   1.02838676e-01,   1.71397793e-02,\n",
       "          1.71397793e-01,   8.56988963e-02,   5.14193378e-02,\n",
       "          3.80579551e-18,   3.42795585e-02,   3.42795585e-02,\n",
       "          8.56988963e-02,   6.85591170e-02,   3.80579551e-18],\n",
       "       [  1.16729750e-02,   4.66919001e-02,   4.66919001e-02,\n",
       "          7.00378501e-02,   9.33838002e-02,   3.26843301e-01,\n",
       "          2.59192113e-18,   1.05056775e-01,   4.90264951e-01,\n",
       "          4.08554126e-01,   8.17108251e-02,   3.85208176e-01,\n",
       "          1.75094625e-01,   2.33459500e-02,   2.59192113e-18,\n",
       "          1.75094625e-01,   2.33459500e-01,   2.68478425e-01,\n",
       "          4.66919001e-02,   1.16729750e-01,   1.28402725e-01,\n",
       "          1.86767600e-01,   1.40075700e-01,   7.00378501e-02,\n",
       "          4.66919001e-02,   4.66919001e-02,   8.17108251e-02,\n",
       "          5.83648751e-02,   4.66919001e-02,   7.00378501e-02],\n",
       "       [  1.19702550e-02,   4.78810199e-02,   4.78810199e-02,\n",
       "          7.18215298e-02,   8.37917847e-02,   3.95018414e-01,\n",
       "          2.65793053e-18,   7.18215298e-02,   4.42899434e-01,\n",
       "          3.23196884e-01,   1.07732295e-01,   4.42899434e-01,\n",
       "          1.07732295e-01,   2.65793053e-18,   2.65793053e-18,\n",
       "          1.91524079e-01,   1.91524079e-01,   3.35167139e-01,\n",
       "          5.98512748e-02,   1.19702550e-01,   1.31672805e-01,\n",
       "          1.79553824e-01,   1.07732295e-01,   1.07732295e-01,\n",
       "          4.78810199e-02,   9.57620397e-02,   8.37917847e-02,\n",
       "          3.59107649e-02,   2.39405099e-02,   7.18215298e-02],\n",
       "       [  3.25971439e-02,   2.17314293e-02,   4.34628585e-02,\n",
       "          5.43285732e-02,   1.30388576e-01,   3.25971439e-01,\n",
       "          2.41267331e-18,   7.60600024e-02,   4.02031441e-01,\n",
       "          3.15105724e-01,   1.19522861e-01,   3.25971439e-01,\n",
       "          8.69257170e-02,   2.41267331e-18,   2.41267331e-18,\n",
       "          2.49911436e-01,   2.60777151e-01,   3.47702868e-01,\n",
       "          9.77914317e-02,   1.41254290e-01,   1.30388576e-01,\n",
       "          2.93374295e-01,   1.52120005e-01,   8.69257170e-02,\n",
       "          8.69257170e-02,   1.19522861e-01,   1.19522861e-01,\n",
       "          5.43285732e-02,   4.34628585e-02,   1.41254290e-01],\n",
       "       [  6.38720163e-02,   2.55488065e-02,   2.55488065e-02,\n",
       "          1.27744033e-02,   1.91616049e-01,   2.68262468e-01,\n",
       "          3.83232098e-02,   1.02195226e-01,   3.57683291e-01,\n",
       "          3.19360081e-01,   7.66464195e-02,   2.42713662e-01,\n",
       "          6.38720163e-02,   2.83648732e-18,   2.83648732e-18,\n",
       "          3.06585678e-01,   2.81036872e-01,   4.21555308e-01,\n",
       "          1.53292839e-01,   1.40518436e-01,   6.38720163e-02,\n",
       "          3.32134485e-01,   1.02195226e-01,   6.38720163e-02,\n",
       "          6.38720163e-02,   1.27744033e-01,   1.02195226e-01,\n",
       "          6.38720163e-02,   6.38720163e-02,   1.14969629e-01],\n",
       "       [  8.84459484e-02,   4.42229742e-02,   1.47409914e-02,\n",
       "          1.47409914e-02,   2.06373880e-01,   2.50596854e-01,\n",
       "          3.39042802e-01,   7.37049570e-02,   1.03186940e-01,\n",
       "          3.68524785e-01,   5.89639656e-02,   1.47409914e-01,\n",
       "          5.89639656e-02,   1.47409914e-02,   3.27315761e-18,\n",
       "          3.24301811e-01,   2.80078837e-01,   2.94819828e-01,\n",
       "          1.76891897e-01,   1.47409914e-01,   7.37049570e-02,\n",
       "          4.12747759e-01,   1.62150905e-01,   2.94819828e-02,\n",
       "          7.37049570e-02,   1.03186940e-01,   1.32668923e-01,\n",
       "          7.37049570e-02,   7.37049570e-02,   1.32668923e-01],\n",
       "       [  8.97222907e-02,   5.98148605e-02,   6.64078353e-18,\n",
       "          6.64078353e-18,   1.19629721e-01,   2.69166872e-01,\n",
       "          6.87870895e-01,   8.97222907e-02,   6.64078353e-18,\n",
       "          3.58889163e-01,   6.64078353e-18,   6.64078353e-18,\n",
       "          2.99074302e-02,   2.99074302e-02,   6.64078353e-18,\n",
       "          1.79444581e-01,   1.49537151e-01,   2.99074302e-01,\n",
       "          1.49537151e-01,   5.98148605e-02,   8.97222907e-02,\n",
       "          2.69166872e-01,   1.49537151e-01,   6.64078353e-18,\n",
       "          2.99074302e-02,   5.98148605e-02,   8.97222907e-02,\n",
       "          6.64078353e-18,   2.99074302e-02,   5.98148605e-02],\n",
       "       [  4.61265604e-02,   4.61265604e-02,   1.02421539e-17,\n",
       "          1.02421539e-17,   1.02421539e-17,   4.61265604e-02,\n",
       "          9.22531208e-01,   1.02421539e-17,   1.02421539e-17,\n",
       "          2.30632802e-01,   1.02421539e-17,   1.02421539e-17,\n",
       "          4.61265604e-02,   4.61265604e-02,   1.02421539e-17,\n",
       "          1.02421539e-17,   1.02421539e-17,   1.38379681e-01,\n",
       "          9.22531208e-02,   1.02421539e-17,   1.02421539e-17,\n",
       "          1.38379681e-01,   1.84506242e-01,   1.02421539e-17,\n",
       "          1.02421539e-17,   4.61265604e-02,   4.61265604e-02,\n",
       "          1.02421539e-17,   1.02421539e-17,   1.02421539e-17],\n",
       "       [  1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01],\n",
       "       [  1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01],\n",
       "       [  1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01,\n",
       "          1.82574186e-01,   1.82574186e-01,   1.82574186e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction Training\n",
    "\n",
    "X_tr, y_tr = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data['label_tr'][0][k][t,0]\n",
    "    X_tr.append(feat)\n",
    "    y_tr.append(lab)\n",
    "    \n",
    "X_tr = np.asarray(X_tr, dtype='object')\n",
    "y_tr = np.asarray(y_tr, dtype='object')\n",
    "\n",
    "X_n, y_n = np.zeros((908,60)), np.zeros((908,11), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr[k].shape[0]):\n",
    "        X_n[l] = X_tr[k][j]\n",
    "        y_n[l][y_tr[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.2)(out1)\n",
    "out1 = Dense(11, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model = Model(inp,out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "\n",
    "sgd = adam(0.0007,epsilon=1e-8)\n",
    "\n",
    "unary_model.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 817 samples, validate on 91 samples\n",
      "Epoch 1/100\n",
      "0s - loss: 2.3497 - acc: 0.1579 - val_loss: 2.3700 - val_acc: 0.2747\n",
      "Epoch 2/100\n",
      "0s - loss: 2.2649 - acc: 0.3035 - val_loss: 2.3634 - val_acc: 0.2198\n",
      "Epoch 3/100\n",
      "0s - loss: 2.1922 - acc: 0.3023 - val_loss: 2.3701 - val_acc: 0.1758\n",
      "Epoch 4/100\n",
      "0s - loss: 2.1212 - acc: 0.2815 - val_loss: 2.3788 - val_acc: 0.1538\n",
      "Epoch 5/100\n",
      "0s - loss: 2.0567 - acc: 0.2889 - val_loss: 2.3791 - val_acc: 0.1538\n",
      "Epoch 6/100\n",
      "0s - loss: 1.9950 - acc: 0.3084 - val_loss: 2.3591 - val_acc: 0.1868\n",
      "Epoch 7/100\n",
      "0s - loss: 1.9326 - acc: 0.3623 - val_loss: 2.3302 - val_acc: 0.2527\n",
      "Epoch 8/100\n",
      "0s - loss: 1.8665 - acc: 0.4321 - val_loss: 2.2929 - val_acc: 0.2857\n",
      "Epoch 9/100\n",
      "0s - loss: 1.7903 - acc: 0.5275 - val_loss: 2.2449 - val_acc: 0.3736\n",
      "Epoch 10/100\n",
      "0s - loss: 1.7250 - acc: 0.5838 - val_loss: 2.1756 - val_acc: 0.4066\n",
      "Epoch 11/100\n",
      "0s - loss: 1.6530 - acc: 0.6242 - val_loss: 2.1060 - val_acc: 0.3956\n",
      "Epoch 12/100\n",
      "0s - loss: 1.5723 - acc: 0.6377 - val_loss: 2.0470 - val_acc: 0.3956\n",
      "Epoch 13/100\n",
      "0s - loss: 1.5107 - acc: 0.6634 - val_loss: 1.9933 - val_acc: 0.4066\n",
      "Epoch 14/100\n",
      "0s - loss: 1.4309 - acc: 0.6732 - val_loss: 1.9334 - val_acc: 0.4176\n",
      "Epoch 15/100\n",
      "0s - loss: 1.3770 - acc: 0.6597 - val_loss: 1.8793 - val_acc: 0.4066\n",
      "Epoch 16/100\n",
      "0s - loss: 1.3207 - acc: 0.6744 - val_loss: 1.8056 - val_acc: 0.4286\n",
      "Epoch 17/100\n",
      "0s - loss: 1.2557 - acc: 0.7099 - val_loss: 1.7540 - val_acc: 0.4286\n",
      "Epoch 18/100\n",
      "0s - loss: 1.2006 - acc: 0.7062 - val_loss: 1.6744 - val_acc: 0.4396\n",
      "Epoch 19/100\n",
      "0s - loss: 1.1514 - acc: 0.7283 - val_loss: 1.5955 - val_acc: 0.4945\n",
      "Epoch 20/100\n",
      "0s - loss: 1.1024 - acc: 0.7466 - val_loss: 1.5347 - val_acc: 0.5165\n",
      "Epoch 21/100\n",
      "0s - loss: 1.0645 - acc: 0.7540 - val_loss: 1.5014 - val_acc: 0.5275\n",
      "Epoch 22/100\n",
      "0s - loss: 1.0285 - acc: 0.7613 - val_loss: 1.4780 - val_acc: 0.5275\n",
      "Epoch 23/100\n",
      "0s - loss: 0.9974 - acc: 0.7650 - val_loss: 1.4411 - val_acc: 0.5495\n",
      "Epoch 24/100\n",
      "0s - loss: 0.9590 - acc: 0.7797 - val_loss: 1.3822 - val_acc: 0.5824\n",
      "Epoch 25/100\n",
      "0s - loss: 0.9316 - acc: 0.7944 - val_loss: 1.3334 - val_acc: 0.6044\n",
      "Epoch 26/100\n",
      "0s - loss: 0.8977 - acc: 0.7919 - val_loss: 1.2906 - val_acc: 0.6264\n",
      "Epoch 27/100\n",
      "0s - loss: 0.8751 - acc: 0.7870 - val_loss: 1.2627 - val_acc: 0.6264\n",
      "Epoch 28/100\n",
      "0s - loss: 0.8571 - acc: 0.8078 - val_loss: 1.2153 - val_acc: 0.6374\n",
      "Epoch 29/100\n",
      "0s - loss: 0.8226 - acc: 0.8152 - val_loss: 1.1748 - val_acc: 0.6703\n",
      "Epoch 30/100\n",
      "0s - loss: 0.8077 - acc: 0.8213 - val_loss: 1.1667 - val_acc: 0.6484\n",
      "Epoch 31/100\n",
      "0s - loss: 0.7831 - acc: 0.8176 - val_loss: 1.1365 - val_acc: 0.6923\n",
      "Epoch 32/100\n",
      "0s - loss: 0.7650 - acc: 0.8397 - val_loss: 1.1214 - val_acc: 0.6923\n",
      "Epoch 33/100\n",
      "0s - loss: 0.7375 - acc: 0.8360 - val_loss: 1.0683 - val_acc: 0.7363\n",
      "Epoch 34/100\n",
      "0s - loss: 0.7334 - acc: 0.8421 - val_loss: 1.0359 - val_acc: 0.7473\n",
      "Epoch 35/100\n",
      "0s - loss: 0.7146 - acc: 0.8323 - val_loss: 1.0381 - val_acc: 0.7473\n",
      "Epoch 36/100\n",
      "0s - loss: 0.6973 - acc: 0.8421 - val_loss: 1.0199 - val_acc: 0.7363\n",
      "Epoch 37/100\n",
      "0s - loss: 0.6859 - acc: 0.8482 - val_loss: 0.9866 - val_acc: 0.7582\n",
      "Epoch 38/100\n",
      "0s - loss: 0.6739 - acc: 0.8494 - val_loss: 0.9782 - val_acc: 0.7582\n",
      "Epoch 39/100\n",
      "0s - loss: 0.6579 - acc: 0.8507 - val_loss: 0.9714 - val_acc: 0.7473\n",
      "Epoch 40/100\n",
      "0s - loss: 0.6465 - acc: 0.8446 - val_loss: 0.9352 - val_acc: 0.7692\n",
      "Epoch 41/100\n",
      "0s - loss: 0.6374 - acc: 0.8605 - val_loss: 0.9211 - val_acc: 0.7692\n",
      "Epoch 42/100\n",
      "0s - loss: 0.6218 - acc: 0.8654 - val_loss: 0.9067 - val_acc: 0.7692\n",
      "Epoch 43/100\n",
      "0s - loss: 0.6200 - acc: 0.8605 - val_loss: 0.9052 - val_acc: 0.7802\n",
      "Epoch 44/100\n",
      "0s - loss: 0.6091 - acc: 0.8568 - val_loss: 0.8980 - val_acc: 0.7582\n",
      "Epoch 45/100\n",
      "0s - loss: 0.5900 - acc: 0.8678 - val_loss: 0.8935 - val_acc: 0.7582\n",
      "Epoch 46/100\n",
      "0s - loss: 0.5920 - acc: 0.8629 - val_loss: 0.8876 - val_acc: 0.7802\n",
      "Epoch 47/100\n",
      "0s - loss: 0.5779 - acc: 0.8703 - val_loss: 0.8846 - val_acc: 0.7692\n",
      "Epoch 48/100\n",
      "0s - loss: 0.5666 - acc: 0.8715 - val_loss: 0.8582 - val_acc: 0.8022\n",
      "Epoch 49/100\n",
      "0s - loss: 0.5643 - acc: 0.8739 - val_loss: 0.8371 - val_acc: 0.8022\n",
      "Epoch 50/100\n",
      "0s - loss: 0.5548 - acc: 0.8739 - val_loss: 0.8448 - val_acc: 0.7912\n",
      "Epoch 51/100\n",
      "0s - loss: 0.5571 - acc: 0.8703 - val_loss: 0.8460 - val_acc: 0.7912\n",
      "Epoch 52/100\n",
      "0s - loss: 0.5379 - acc: 0.8776 - val_loss: 0.8347 - val_acc: 0.7912\n",
      "Epoch 53/100\n",
      "0s - loss: 0.5425 - acc: 0.8752 - val_loss: 0.8339 - val_acc: 0.8022\n",
      "Epoch 54/100\n",
      "0s - loss: 0.5402 - acc: 0.8776 - val_loss: 0.8356 - val_acc: 0.8022\n",
      "Epoch 55/100\n",
      "0s - loss: 0.5216 - acc: 0.8776 - val_loss: 0.8149 - val_acc: 0.8022\n",
      "Epoch 56/100\n",
      "0s - loss: 0.5067 - acc: 0.8837 - val_loss: 0.7996 - val_acc: 0.7912\n",
      "Epoch 57/100\n",
      "0s - loss: 0.5144 - acc: 0.8813 - val_loss: 0.7988 - val_acc: 0.7912\n",
      "Epoch 58/100\n",
      "0s - loss: 0.5104 - acc: 0.8776 - val_loss: 0.7981 - val_acc: 0.7912\n",
      "Epoch 59/100\n",
      "0s - loss: 0.4954 - acc: 0.8813 - val_loss: 0.7944 - val_acc: 0.7912\n",
      "Epoch 60/100\n",
      "0s - loss: 0.4933 - acc: 0.8837 - val_loss: 0.7968 - val_acc: 0.8022\n",
      "Epoch 61/100\n",
      "0s - loss: 0.4838 - acc: 0.8886 - val_loss: 0.7979 - val_acc: 0.8022\n",
      "Epoch 62/100\n",
      "0s - loss: 0.4856 - acc: 0.8813 - val_loss: 0.7979 - val_acc: 0.8022\n",
      "Epoch 63/100\n",
      "0s - loss: 0.4718 - acc: 0.8911 - val_loss: 0.7855 - val_acc: 0.8022\n",
      "Epoch 64/100\n",
      "0s - loss: 0.4752 - acc: 0.8898 - val_loss: 0.7789 - val_acc: 0.8022\n",
      "Epoch 65/100\n",
      "0s - loss: 0.4746 - acc: 0.8960 - val_loss: 0.7659 - val_acc: 0.8132\n",
      "Epoch 66/100\n",
      "0s - loss: 0.4622 - acc: 0.8935 - val_loss: 0.7668 - val_acc: 0.8132\n",
      "Epoch 67/100\n",
      "0s - loss: 0.4544 - acc: 0.8898 - val_loss: 0.7615 - val_acc: 0.8132\n",
      "Epoch 68/100\n",
      "0s - loss: 0.4590 - acc: 0.8984 - val_loss: 0.7523 - val_acc: 0.8132\n",
      "Epoch 69/100\n",
      "0s - loss: 0.4523 - acc: 0.8898 - val_loss: 0.7516 - val_acc: 0.8022\n",
      "Epoch 70/100\n",
      "0s - loss: 0.4662 - acc: 0.8886 - val_loss: 0.7354 - val_acc: 0.8132\n",
      "Epoch 71/100\n",
      "0s - loss: 0.4461 - acc: 0.8886 - val_loss: 0.7282 - val_acc: 0.8132\n",
      "Epoch 72/100\n",
      "0s - loss: 0.4510 - acc: 0.8862 - val_loss: 0.7401 - val_acc: 0.8132\n",
      "Epoch 73/100\n",
      "0s - loss: 0.4532 - acc: 0.8886 - val_loss: 0.7556 - val_acc: 0.8132\n",
      "Epoch 74/100\n",
      "0s - loss: 0.4351 - acc: 0.8996 - val_loss: 0.7458 - val_acc: 0.8242\n",
      "Epoch 75/100\n",
      "0s - loss: 0.4442 - acc: 0.8996 - val_loss: 0.7533 - val_acc: 0.8242\n",
      "Epoch 76/100\n",
      "0s - loss: 0.4357 - acc: 0.8996 - val_loss: 0.7644 - val_acc: 0.8132\n",
      "Epoch 77/100\n",
      "0s - loss: 0.4393 - acc: 0.8911 - val_loss: 0.7447 - val_acc: 0.8132\n",
      "Epoch 78/100\n",
      "0s - loss: 0.4307 - acc: 0.8935 - val_loss: 0.7369 - val_acc: 0.8132\n",
      "Epoch 79/100\n",
      "0s - loss: 0.4235 - acc: 0.8984 - val_loss: 0.7361 - val_acc: 0.8242\n",
      "Epoch 80/100\n",
      "0s - loss: 0.4198 - acc: 0.9009 - val_loss: 0.7208 - val_acc: 0.8132\n",
      "Epoch 81/100\n",
      "0s - loss: 0.4157 - acc: 0.8984 - val_loss: 0.7434 - val_acc: 0.8132\n",
      "Epoch 82/100\n",
      "0s - loss: 0.4121 - acc: 0.9033 - val_loss: 0.7386 - val_acc: 0.8242\n",
      "Epoch 83/100\n",
      "0s - loss: 0.4121 - acc: 0.9033 - val_loss: 0.7224 - val_acc: 0.8132\n",
      "Epoch 84/100\n",
      "0s - loss: 0.4060 - acc: 0.9021 - val_loss: 0.7227 - val_acc: 0.8132\n",
      "Epoch 85/100\n",
      "0s - loss: 0.4122 - acc: 0.9045 - val_loss: 0.7153 - val_acc: 0.8242\n",
      "Epoch 86/100\n",
      "0s - loss: 0.3965 - acc: 0.9106 - val_loss: 0.7211 - val_acc: 0.8242\n",
      "Epoch 87/100\n",
      "0s - loss: 0.3981 - acc: 0.9045 - val_loss: 0.7170 - val_acc: 0.8352\n",
      "Epoch 88/100\n",
      "0s - loss: 0.3932 - acc: 0.9119 - val_loss: 0.7305 - val_acc: 0.8132\n",
      "Epoch 89/100\n",
      "0s - loss: 0.3883 - acc: 0.9131 - val_loss: 0.7334 - val_acc: 0.8132\n",
      "Epoch 90/100\n",
      "0s - loss: 0.3870 - acc: 0.9119 - val_loss: 0.7273 - val_acc: 0.8132\n",
      "Epoch 91/100\n",
      "0s - loss: 0.3766 - acc: 0.9033 - val_loss: 0.7220 - val_acc: 0.8352\n",
      "Epoch 92/100\n",
      "0s - loss: 0.3761 - acc: 0.9119 - val_loss: 0.7226 - val_acc: 0.8242\n",
      "Epoch 93/100\n",
      "0s - loss: 0.3810 - acc: 0.9106 - val_loss: 0.7138 - val_acc: 0.8242\n",
      "Epoch 94/100\n",
      "0s - loss: 0.3879 - acc: 0.9058 - val_loss: 0.7269 - val_acc: 0.8242\n",
      "Epoch 95/100\n",
      "0s - loss: 0.3855 - acc: 0.9070 - val_loss: 0.7075 - val_acc: 0.8352\n",
      "Epoch 96/100\n",
      "0s - loss: 0.3674 - acc: 0.9106 - val_loss: 0.7110 - val_acc: 0.8352\n",
      "Epoch 97/100\n",
      "0s - loss: 0.3704 - acc: 0.9131 - val_loss: 0.7176 - val_acc: 0.8352\n",
      "Epoch 98/100\n",
      "0s - loss: 0.3703 - acc: 0.9119 - val_loss: 0.7307 - val_acc: 0.8352\n",
      "Epoch 99/100\n",
      "0s - loss: 0.3609 - acc: 0.9094 - val_loss: 0.7182 - val_acc: 0.8352\n",
      "Epoch 100/100\n",
      "0s - loss: 0.3663 - acc: 0.9168 - val_loss: 0.7133 - val_acc: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6299258eb8>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model.fit(X_n,y_n,batch_size=128,validation_split=0.10,verbose=2, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "             weights=unary_model.layers[1].get_weights())(inpp)\n",
    "out1 = Dropout(0.2)(out1)\n",
    "out1 = Dense(11, activation='linear', bias=False,\n",
    "             weights=unary_model.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model1 = Model(inpp,out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.71292162, -1.44587445, -1.01723075, -2.1560452 , -2.98591805,\n",
       "       -2.20095158, -2.36557651, -3.10711026, -2.39063001, -1.84378684,\n",
       "       -2.5490005 ], dtype=float32)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model1.predict(X_tr[0][0].reshape((1,60)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Extraction Testing\n",
    "\n",
    "X_ts, y_ts = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data['label_te'][0][k][t,0]\n",
    "    X_ts.append(feat)\n",
    "    y_ts.append(lab)\n",
    "    \n",
    "X_ts = np.asarray(X_ts, dtype='object')\n",
    "y_ts = np.asarray(y_ts, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0,\n",
       "       0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_l = 0 \n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    max_l = max(max_l, y_tr[k].max())\n",
    "    \n",
    "for k in range(17):\n",
    "    \n",
    "    max_l = max(max_l, y_ts[k].max())\n",
    "    \n",
    "max_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model1.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  87.224640692 %.\n",
      "Accuracy score Unary only:  77.5708621153 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  87.3137672518 %.\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  87.4134681491 %.\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  86.5063048378 %.\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  87.2733558443 %.\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  87.1736549469 %.\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  87.742914909 %.\n",
      "Final accuracy score:  87.742914909 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Unary Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 1\n",
    "\n",
    "from scipy.spatial.distance import hamming \n",
    "\n",
    "crf = CRF(feat_func,1+11**2,11, 1e-7, best_W)\n",
    "crf_u = CRF(feat_func,1+11**2,11, 1e-7, 'U')\n",
    "alpha = 0.07\n",
    "B1, B2 = 0.9, 0.9999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf.K-1), np.zeros(crf.K-1)\n",
    "num_epochs = 2\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "#best_W = np.zeros(11**2)\n",
    "#best_acc = 0\n",
    "\n",
    "acc_t1 = np.zeros(17)\n",
    "acc_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc_t1[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "    acc_u[n] = 1 - hamming(crf_u.MAP(X_ts[n]), y_ts[n])\n",
    "print('Initial accuracy score Binary: ',100* acc_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr[min_batch[k:k+batch_size]],y_tr[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf.W[1:] = crf.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc_test[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc <= acc_test.mean():\n",
    "                best_acc = acc_test.mean()\n",
    "                best_W = crf.W\n",
    "        \n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc_f = np.zeros(X_ts.shape[0])\n",
    "\n",
    "for n in range(X_ts.shape[0]):\n",
    "    acc_f[n] = 1 - hamming(crf.MAP(X_ts[n]), y_ts[n])\n",
    "    \n",
    "print('Final accuracy score: ',100* acc_f.mean(), '%.')\n",
    "print('Zero-one-loss: ', 100*acc_f[acc_f==1].sum()/17, '%')\n",
    "print('Unary Zero-one-loss: ', 100*acc_u[acc_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel02_data.mat')\n",
    "data3 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel03_data.mat')\n",
    "data4 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel04_data.mat')\n",
    "data5 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel05_data.mat')\n",
    "data6 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel06_data.mat')\n",
    "data7 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel07_data.mat')\n",
    "data8 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel08_data.mat')\n",
    "data9 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel09_data.mat')\n",
    "data10 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel10_data.mat')\n",
    "data11 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel11_data.mat')\n",
    "data12 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel12_data.mat')\n",
    "data13 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel13_data.mat')\n",
    "data14 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel14_data.mat')\n",
    "data15 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel15_data.mat')\n",
    "data16 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel16_data.mat')\n",
    "data17 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel17_data.mat')\n",
    "data18 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel18_data.mat')\n",
    "data19 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel19_data.mat')\n",
    "data20 = scipy.io.loadmat('/home/james/anaconda3/data/HW/Chalearn/BOFData/devel20_data.mat')\n",
    "\n",
    "Data = [data2, data3, data4, data5, data6, data7, data8, data9, data10, data11,\n",
    "        data12, data13, data14, data15, data16, data17, data18, data19, data20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction Training\n",
    "\n",
    "X_tr2, y_tr2 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data2['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data2['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data2['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data2['label_tr'][0][k][t,0]\n",
    "    X_tr2.append(feat)\n",
    "    y_tr2.append(lab)\n",
    "    \n",
    "X_tr2 = np.asarray(X_tr2, dtype='object')\n",
    "y_tr2 = np.asarray(y_tr2, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts2, y_ts2 = [], []\n",
    "\n",
    "for k in range(16):\n",
    "    \n",
    "    T = data2['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data2['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data2['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data2['label_te'][0][k][t,0]\n",
    "    X_ts2.append(feat)\n",
    "    y_ts2.append(lab)\n",
    "    \n",
    "X_ts2 = np.asarray(X_ts2, dtype='object')\n",
    "y_ts2 = np.asarray(y_ts2, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr2[k].shape[0]):\n",
    "        num_node += 1\n",
    "\n",
    "\n",
    "X_n2, y_n2 = np.zeros((num_node,60)), np.zeros((num_node,11), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr2[k].shape[0]):\n",
    "        X_n2[l] = X_tr2[k][j]\n",
    "        y_n2[l][y_tr2[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(11, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model2 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model2.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 998 samples, validate on 53 samples\n",
      "Epoch 1/11\n",
      "0s - loss: 2.0741 - acc: 0.2725 - val_loss: 1.9937 - val_acc: 0.4528\n",
      "Epoch 2/11\n",
      "0s - loss: 1.5252 - acc: 0.5391 - val_loss: 1.5151 - val_acc: 0.5660\n",
      "Epoch 3/11\n",
      "0s - loss: 1.1647 - acc: 0.6623 - val_loss: 1.1849 - val_acc: 0.6792\n",
      "Epoch 4/11\n",
      "0s - loss: 0.9527 - acc: 0.7445 - val_loss: 1.0245 - val_acc: 0.6981\n",
      "Epoch 5/11\n",
      "0s - loss: 0.8181 - acc: 0.7695 - val_loss: 1.0228 - val_acc: 0.6981\n",
      "Epoch 6/11\n",
      "0s - loss: 0.7175 - acc: 0.8076 - val_loss: 0.8631 - val_acc: 0.7547\n",
      "Epoch 7/11\n",
      "0s - loss: 0.6377 - acc: 0.8176 - val_loss: 0.9610 - val_acc: 0.7170\n",
      "Epoch 8/11\n",
      "0s - loss: 0.5986 - acc: 0.8407 - val_loss: 0.8335 - val_acc: 0.7547\n",
      "Epoch 9/11\n",
      "0s - loss: 0.5634 - acc: 0.8477 - val_loss: 0.9124 - val_acc: 0.7547\n",
      "Epoch 10/11\n",
      "0s - loss: 0.5344 - acc: 0.8517 - val_loss: 0.8691 - val_acc: 0.7547\n",
      "Epoch 11/11\n",
      "0s - loss: 0.5009 - acc: 0.8737 - val_loss: 0.8268 - val_acc: 0.7547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6296f5a128>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model2.fit(X_n2,y_n2,batch_size=128,nb_epoch=11,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model2.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(11, activation='linear', bias=False,\n",
    "            weights= unary_model2.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model2b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model2b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_func2(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model2b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  78.2494315765 %.\n",
      "Accuracy score Unary only:  73.8793777848 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  78.1789235067 %.\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  77.4197685263 %.\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  77.6150810263 %.\n",
      "Final accuracy score:  77.8719303414 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Unary Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 2\n",
    "\n",
    "from scipy.spatial.distance import hamming \n",
    "\n",
    "crf2 = CRF(feat_func2,1+11**2,11, 1e-7, best_W2)\n",
    "crf_u2 = CRF(feat_func2,1+11**2,11, 1e-7, 'U')\n",
    "alpha = 0.07\n",
    "B1, B2 = 0.9, 0.9999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf2.K-1), np.zeros(crf2.K-1)\n",
    "num_epochs = 1\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "#best_W2 = np.zeros(11**2)\n",
    "#best_acc2 = 0\n",
    "\n",
    "acc2_t1 = np.zeros(16)\n",
    "acc2_u = np.zeros(16)\n",
    "for n in range(16):\n",
    "    acc2_t1[n] = 1 - hamming(crf2.MAP(X_ts2[n]), y_ts2[n])\n",
    "    acc2_u[n] = 1 - hamming(crf_u2.MAP(X_ts2[n]), y_ts2[n])\n",
    "print('Initial accuracy score Binary: ',100* acc2_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc2_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr2.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr2.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr2[min_batch[k:k+batch_size]],y_tr2[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr2.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf2.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf2.W[1:] = crf2.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc2_test = np.zeros(16)\n",
    "            \n",
    "            for n in range(16):\n",
    "                acc2_test[n] = 1 - hamming(crf2.MAP(X_ts2[n]), y_ts2[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc2_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc2 <= acc2_test.mean():\n",
    "                best_acc2 = acc2_test.mean()\n",
    "                best_W2 = crf2.W\n",
    "        \n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc2_f = np.zeros(X_ts2.shape[0])\n",
    "\n",
    "for n in range(X_ts2.shape[0]):\n",
    "    acc2_f[n] = 1 - hamming(crf2.MAP(X_ts2[n]), y_ts2[n])\n",
    "    \n",
    "print('Final accuracy score: ',100* acc2_f.mean(), '%.')\n",
    "print('Zero-one-loss: ', 100*acc2_f[acc2_f==1].sum()/17, '%')\n",
    "print('Unary Zero-one-loss: ', 100*acc2_u[acc2_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 3\n",
    "\n",
    "X_tr3, y_tr3 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data3['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data3['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data3['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data3['label_tr'][0][k][t,0]\n",
    "    X_tr3.append(feat)\n",
    "    y_tr3.append(lab)\n",
    "    \n",
    "X_tr3 = np.asarray(X_tr3, dtype='object')\n",
    "y_tr3 = np.asarray(y_tr3, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts3, y_ts3 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data3['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data3['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data3['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data3['label_te'][0][k][t,0]\n",
    "    X_ts3.append(feat)\n",
    "    y_ts3.append(lab)\n",
    "    \n",
    "X_ts3 = np.asarray(X_ts3, dtype='object')\n",
    "y_ts3 = np.asarray(y_ts3, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr3[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr3[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts3[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n3, y_n3 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr3[k].shape[0]):\n",
    "        X_n3[l] = X_tr3[k][j]\n",
    "        y_n3[l][y_tr3[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 3\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.05)(out1)\n",
    "out1 = Dense(9, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model3 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.005,epsilon=1e-7)\n",
    "\n",
    "unary_model3.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 917 samples, validate on 49 samples\n",
      "Epoch 1/19\n",
      "0s - loss: 2.0276 - acc: 0.2683 - val_loss: 1.8521 - val_acc: 0.4082\n",
      "Epoch 2/19\n",
      "0s - loss: 1.7108 - acc: 0.4885 - val_loss: 1.6269 - val_acc: 0.6327\n",
      "Epoch 3/19\n",
      "0s - loss: 1.4265 - acc: 0.6074 - val_loss: 1.3396 - val_acc: 0.6735\n",
      "Epoch 4/19\n",
      "0s - loss: 1.1904 - acc: 0.6478 - val_loss: 1.1540 - val_acc: 0.6735\n",
      "Epoch 5/19\n",
      "0s - loss: 1.0030 - acc: 0.7034 - val_loss: 0.9808 - val_acc: 0.6939\n",
      "Epoch 6/19\n",
      "0s - loss: 0.8807 - acc: 0.7383 - val_loss: 1.0030 - val_acc: 0.7143\n",
      "Epoch 7/19\n",
      "0s - loss: 0.7900 - acc: 0.7699 - val_loss: 0.9493 - val_acc: 0.7143\n",
      "Epoch 8/19\n",
      "0s - loss: 0.7205 - acc: 0.8048 - val_loss: 0.9628 - val_acc: 0.7347\n",
      "Epoch 9/19\n",
      "0s - loss: 0.6574 - acc: 0.8201 - val_loss: 1.0813 - val_acc: 0.7143\n",
      "Epoch 10/19\n",
      "0s - loss: 0.6116 - acc: 0.8244 - val_loss: 0.9943 - val_acc: 0.6939\n",
      "Epoch 11/19\n",
      "0s - loss: 0.5641 - acc: 0.8212 - val_loss: 1.0343 - val_acc: 0.6939\n",
      "Epoch 12/19\n",
      "0s - loss: 0.5216 - acc: 0.8680 - val_loss: 1.0883 - val_acc: 0.6531\n",
      "Epoch 13/19\n",
      "0s - loss: 0.5022 - acc: 0.8561 - val_loss: 1.1462 - val_acc: 0.7143\n",
      "Epoch 14/19\n",
      "0s - loss: 0.4604 - acc: 0.8811 - val_loss: 1.2014 - val_acc: 0.7143\n",
      "Epoch 15/19\n",
      "0s - loss: 0.4333 - acc: 0.8942 - val_loss: 1.0500 - val_acc: 0.7143\n",
      "Epoch 16/19\n",
      "0s - loss: 0.4247 - acc: 0.8855 - val_loss: 1.3364 - val_acc: 0.6939\n",
      "Epoch 17/19\n",
      "0s - loss: 0.3993 - acc: 0.9117 - val_loss: 1.0635 - val_acc: 0.7143\n",
      "Epoch 18/19\n",
      "0s - loss: 0.3720 - acc: 0.9215 - val_loss: 1.2475 - val_acc: 0.6939\n",
      "Epoch 19/19\n",
      "0s - loss: 0.3487 - acc: 0.9335 - val_loss: 1.2695 - val_acc: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6295825828>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model3.fit(X_n3,y_n3,batch_size=128,nb_epoch=19,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model3.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(9, activation='linear', bias=False,\n",
    "            weights= unary_model3.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model3b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model3b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func3(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model3b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  62.3404770581 %.\n",
      "Accuracy score Unary only:  55.198712337 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  62.5805730965 %.\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  62.917958605 %.\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  61.6441701899 %.\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  61.7642182091 %.\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  61.8437094651 %.\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  61.6863509596 %.\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  61.6863509596 %.\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  61.3521263607 %.\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  61.4571683775 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  61.819424717 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  61.819424717 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  61.739933461 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  61.4272678542 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  61.2837958313 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  60.330502905 %.\n",
      "Final accuracy score:  61.2249451889 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Unary Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 3\n",
    "\n",
    "\n",
    "crf3 = CRF(feat_func3,1+9**2,9, 1e-10, best_W3)\n",
    "crf_u3 = CRF(feat_func3,1+9**2,9, 1e-7, 'U')\n",
    "alpha = 0.09\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-8\n",
    "m, v = np.zeros(crf3.K-1), np.zeros(crf3.K-1)\n",
    "num_epochs = 5\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "#best_W3 = np.zeros(9**2)\n",
    "#best_acc3 = 0\n",
    "\n",
    "acc3_t1 = np.zeros(17)\n",
    "acc3_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc3_t1[n] = 1 - hamming(crf3.MAP(X_ts3[n]), y_ts3[n])\n",
    "    acc3_u[n] = 1 - hamming(crf_u3.MAP(X_ts3[n]), y_ts3[n])\n",
    "print('Initial accuracy score Binary: ',100* acc3_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc3_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr3.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr3.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr3[min_batch[k:k+batch_size]],y_tr3[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr3.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf3.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf3.W[1:] = crf3.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc3_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc3_test[n] = 1 - hamming(crf3.MAP(X_ts3[n]), y_ts3[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc3_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc3 <= acc3_test.mean():\n",
    "                best_acc3 = acc3_test.mean()\n",
    "                best_W3 = crf3.W\n",
    "        \n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc3_f = np.zeros(X_ts3.shape[0])\n",
    "\n",
    "for n in range(X_ts3.shape[0]):\n",
    "    acc3_f[n] = 1 - hamming(crf3.MAP(X_ts3[n]), y_ts3[n])\n",
    "    \n",
    "print('Final accuracy score: ',100* acc3_f.mean(), '%.')\n",
    "print('Zero-one-loss: ', 100*acc3_f[acc3_f==1].sum()/17, '%')\n",
    "print('Unary Zero-one-loss: ', 100*acc3_u[acc3_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49928405209559845"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 4\n",
    "\n",
    "X_tr4, y_tr4 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data4['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data4['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data4['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data4['label_tr'][0][k][t,0]\n",
    "    X_tr4.append(feat)\n",
    "    y_tr4.append(lab)\n",
    "    \n",
    "X_tr4 = np.asarray(X_tr4, dtype='object')\n",
    "y_tr4 = np.asarray(y_tr4, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts4, y_ts4 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data4['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data4['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data4['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data4['label_te'][0][k][t,0]\n",
    "    X_ts4.append(feat)\n",
    "    y_ts4.append(lab)\n",
    "    \n",
    "X_ts4 = np.asarray(X_ts4, dtype='object')\n",
    "y_ts4 = np.asarray(y_ts4, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr4[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr4[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts4[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n4, y_n4 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr4[k].shape[0]):\n",
    "        X_n4[l] = X_tr4[k][j]\n",
    "        y_n4[l][y_tr4[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 4\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.05)(out1)\n",
    "out1 = Dense(11, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model4 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.005,epsilon=1e-7)\n",
    "\n",
    "unary_model4.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 757 samples, validate on 40 samples\n",
      "Epoch 1/19\n",
      "0s - loss: 2.1023 - acc: 0.3448 - val_loss: 2.1474 - val_acc: 0.1750\n",
      "Epoch 2/19\n",
      "0s - loss: 1.7874 - acc: 0.3910 - val_loss: 1.7994 - val_acc: 0.3500\n",
      "Epoch 3/19\n",
      "0s - loss: 1.4960 - acc: 0.5456 - val_loss: 1.3197 - val_acc: 0.6000\n",
      "Epoch 4/19\n",
      "0s - loss: 1.2372 - acc: 0.6129 - val_loss: 1.1409 - val_acc: 0.6250\n",
      "Epoch 5/19\n",
      "0s - loss: 1.0116 - acc: 0.7332 - val_loss: 0.9643 - val_acc: 0.6250\n",
      "Epoch 6/19\n",
      "0s - loss: 0.8448 - acc: 0.7807 - val_loss: 0.8762 - val_acc: 0.6500\n",
      "Epoch 7/19\n",
      "0s - loss: 0.7168 - acc: 0.8203 - val_loss: 0.7747 - val_acc: 0.7000\n",
      "Epoch 8/19\n",
      "0s - loss: 0.6334 - acc: 0.8402 - val_loss: 0.7089 - val_acc: 0.7250\n",
      "Epoch 9/19\n",
      "0s - loss: 0.5674 - acc: 0.8692 - val_loss: 0.7013 - val_acc: 0.7250\n",
      "Epoch 10/19\n",
      "0s - loss: 0.5198 - acc: 0.8719 - val_loss: 0.7320 - val_acc: 0.7250\n",
      "Epoch 11/19\n",
      "0s - loss: 0.4792 - acc: 0.8877 - val_loss: 0.6241 - val_acc: 0.7250\n",
      "Epoch 12/19\n",
      "0s - loss: 0.4468 - acc: 0.8983 - val_loss: 0.7078 - val_acc: 0.7250\n",
      "Epoch 13/19\n",
      "0s - loss: 0.4174 - acc: 0.9036 - val_loss: 0.5869 - val_acc: 0.7500\n",
      "Epoch 14/19\n",
      "0s - loss: 0.3966 - acc: 0.9155 - val_loss: 0.6036 - val_acc: 0.8250\n",
      "Epoch 15/19\n",
      "0s - loss: 0.3727 - acc: 0.9194 - val_loss: 0.6283 - val_acc: 0.7750\n",
      "Epoch 16/19\n",
      "0s - loss: 0.3628 - acc: 0.9155 - val_loss: 0.5772 - val_acc: 0.8000\n",
      "Epoch 17/19\n",
      "0s - loss: 0.3424 - acc: 0.9181 - val_loss: 0.5817 - val_acc: 0.8000\n",
      "Epoch 18/19\n",
      "0s - loss: 0.3400 - acc: 0.9247 - val_loss: 0.5795 - val_acc: 0.8000\n",
      "Epoch 19/19\n",
      "0s - loss: 0.3212 - acc: 0.9260 - val_loss: 0.5881 - val_acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6295322470>"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model4.fit(X_n4,y_n4,batch_size=128,nb_epoch=19,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model4.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(11, activation='linear', bias=False,\n",
    "            weights= unary_model4.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model4b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model4b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func4(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model4b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  77.0903514201 %.\n",
      "Accuracy score Unary only:  80.8538756905 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  77.3874399525 %.\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  79.1406169945 %.\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  80.658215116 %.\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  81.4442398 %.\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  81.8448678875 %.\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  82.7038781583 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  83.3940088019 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  83.0637908562 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  82.7198166299 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  83.2692883978 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  83.8243748662 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  83.1381003564 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  83.282149204 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  83.6050151925 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  83.7139476544 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  83.3011509568 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  83.6009520366 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  83.6009520366 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  83.7925554047 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  83.7925554047 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  83.6082802204 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  83.6082802204 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  84.1844756109 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  84.1844756109 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  83.7923187481 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  83.7923187481 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  83.7923187481 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  84.6637784431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  84.6637784431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  84.6637784431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  84.6637784431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  84.6637784431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  84.6637784431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  84.6637784431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  84.83184567 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  84.83184567 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  84.9407781319 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  84.9407781319 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  85.1965326076 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  85.1923488572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  85.1923488572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  85.1923488572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  85.1923488572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Final accuracy score:  85.58450572 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Unary Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 4\n",
    "\n",
    "\n",
    "crf4 = CRF(feat_func4,1+11**2,11, 0, 'B')\n",
    "crf_u4 = CRF(feat_func4,1+11**2,11, 1e-7, 'U')\n",
    "alpha = 0.085\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf4.K-1), np.zeros(crf4.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc4 = 0\n",
    "\n",
    "acc4_t1 = np.zeros(17)\n",
    "acc4_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc4_t1[n] = 1 - hamming(crf4.MAP(X_ts4[n]), y_ts4[n])\n",
    "    acc4_u[n] = 1 - hamming(crf_u4.MAP(X_ts4[n]), y_ts4[n])\n",
    "print('Initial accuracy score Binary: ',100* acc4_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc4_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr4.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr4.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr4[min_batch[k:k+batch_size]],y_tr4[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr4.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf4.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf4.W[1:] = crf4.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc4_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc4_test[n] = 1 - hamming(crf4.MAP(X_ts4[n]), y_ts4[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc4_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc4 < acc4_test.mean():\n",
    "                print('Zero-one-loss: ', 100*acc4_test[acc4_test==1].sum()/17, '%')\n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc4_f = np.zeros(X_ts4.shape[0])\n",
    "\n",
    "for n in range(X_ts4.shape[0]):\n",
    "    acc4_f[n] = 1 - hamming(crf4.MAP(X_ts4[n]), y_ts4[n])\n",
    "    \n",
    "print('Final accuracy score: ',100* acc4_f.mean(), '%.')\n",
    "print('Zero-one-loss: ', 100*acc4_f[acc4_f==1].sum()/17, '%')\n",
    "print('Unary Zero-one-loss: ', 100*acc4_u[acc4_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 5\n",
    "\n",
    "X_tr5, y_tr5 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data5['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data5['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data5['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data5['label_tr'][0][k][t,0]\n",
    "    X_tr5.append(feat)\n",
    "    y_tr5.append(lab)\n",
    "    \n",
    "X_tr5 = np.asarray(X_tr5, dtype='object')\n",
    "y_tr5 = np.asarray(y_tr5, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts5, y_ts5 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data5['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data5['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data5['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data5['label_te'][0][k][t,0]\n",
    "    X_ts5.append(feat)\n",
    "    y_ts5.append(lab)\n",
    "    \n",
    "X_ts5 = np.asarray(X_ts5, dtype='object')\n",
    "y_ts5 = np.asarray(y_ts5, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr5[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr5[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts5[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n5, y_n5 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr5[k].shape[0]):\n",
    "        X_n5[l] = X_tr5[k][j]\n",
    "        y_n5[l][y_tr5[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 5\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.37)(out1)\n",
    "out1 = Dense(9, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model5 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.005,epsilon=1e-7)\n",
    "\n",
    "unary_model5.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1190 samples, validate on 63 samples\n",
      "Epoch 1/35\n",
      "0s - loss: 2.0220 - acc: 0.2294 - val_loss: 2.1924 - val_acc: 0.0159\n",
      "Epoch 2/35\n",
      "0s - loss: 1.6465 - acc: 0.4983 - val_loss: 1.9448 - val_acc: 0.2063\n",
      "Epoch 3/35\n",
      "0s - loss: 1.3419 - acc: 0.5933 - val_loss: 1.6893 - val_acc: 0.3968\n",
      "Epoch 4/35\n",
      "0s - loss: 1.1421 - acc: 0.6655 - val_loss: 1.4846 - val_acc: 0.4762\n",
      "Epoch 5/35\n",
      "0s - loss: 1.0104 - acc: 0.6983 - val_loss: 1.4763 - val_acc: 0.4762\n",
      "Epoch 6/35\n",
      "0s - loss: 0.9149 - acc: 0.7345 - val_loss: 1.2549 - val_acc: 0.6032\n",
      "Epoch 7/35\n",
      "0s - loss: 0.8587 - acc: 0.7429 - val_loss: 1.3980 - val_acc: 0.4921\n",
      "Epoch 8/35\n",
      "0s - loss: 0.8157 - acc: 0.7555 - val_loss: 1.3950 - val_acc: 0.5238\n",
      "Epoch 9/35\n",
      "0s - loss: 0.7503 - acc: 0.7790 - val_loss: 1.2061 - val_acc: 0.5873\n",
      "Epoch 10/35\n",
      "0s - loss: 0.6915 - acc: 0.8000 - val_loss: 1.1748 - val_acc: 0.6349\n",
      "Epoch 11/35\n",
      "0s - loss: 0.6694 - acc: 0.8034 - val_loss: 1.2649 - val_acc: 0.5873\n",
      "Epoch 12/35\n",
      "0s - loss: 0.6403 - acc: 0.8168 - val_loss: 1.3470 - val_acc: 0.6032\n",
      "Epoch 13/35\n",
      "0s - loss: 0.6075 - acc: 0.8286 - val_loss: 1.2600 - val_acc: 0.6032\n",
      "Epoch 14/35\n",
      "0s - loss: 0.5839 - acc: 0.8328 - val_loss: 1.2680 - val_acc: 0.6032\n",
      "Epoch 15/35\n",
      "0s - loss: 0.5497 - acc: 0.8454 - val_loss: 1.2507 - val_acc: 0.6349\n",
      "Epoch 16/35\n",
      "0s - loss: 0.5474 - acc: 0.8454 - val_loss: 1.2293 - val_acc: 0.6825\n",
      "Epoch 17/35\n",
      "0s - loss: 0.5320 - acc: 0.8555 - val_loss: 1.3018 - val_acc: 0.5714\n",
      "Epoch 18/35\n",
      "0s - loss: 0.4961 - acc: 0.8647 - val_loss: 1.2328 - val_acc: 0.6984\n",
      "Epoch 19/35\n",
      "0s - loss: 0.4779 - acc: 0.8748 - val_loss: 1.1948 - val_acc: 0.6667\n",
      "Epoch 20/35\n",
      "0s - loss: 0.4518 - acc: 0.8815 - val_loss: 1.3495 - val_acc: 0.6667\n",
      "Epoch 21/35\n",
      "0s - loss: 0.4495 - acc: 0.8765 - val_loss: 1.2950 - val_acc: 0.6667\n",
      "Epoch 22/35\n",
      "0s - loss: 0.4280 - acc: 0.8891 - val_loss: 1.2790 - val_acc: 0.6667\n",
      "Epoch 23/35\n",
      "0s - loss: 0.4138 - acc: 0.8933 - val_loss: 1.3518 - val_acc: 0.6667\n",
      "Epoch 24/35\n",
      "0s - loss: 0.4070 - acc: 0.9008 - val_loss: 1.3216 - val_acc: 0.6508\n",
      "Epoch 25/35\n",
      "0s - loss: 0.3909 - acc: 0.9034 - val_loss: 1.2495 - val_acc: 0.6984\n",
      "Epoch 26/35\n",
      "0s - loss: 0.3790 - acc: 0.9025 - val_loss: 1.2963 - val_acc: 0.7143\n",
      "Epoch 27/35\n",
      "0s - loss: 0.3671 - acc: 0.9034 - val_loss: 1.3314 - val_acc: 0.6984\n",
      "Epoch 28/35\n",
      "0s - loss: 0.3541 - acc: 0.9126 - val_loss: 1.3506 - val_acc: 0.6984\n",
      "Epoch 29/35\n",
      "0s - loss: 0.3515 - acc: 0.9160 - val_loss: 1.2948 - val_acc: 0.7143\n",
      "Epoch 30/35\n",
      "0s - loss: 0.3491 - acc: 0.9227 - val_loss: 1.2565 - val_acc: 0.7143\n",
      "Epoch 31/35\n",
      "0s - loss: 0.3396 - acc: 0.9134 - val_loss: 1.3118 - val_acc: 0.6825\n",
      "Epoch 32/35\n",
      "0s - loss: 0.3150 - acc: 0.9286 - val_loss: 1.3214 - val_acc: 0.6825\n",
      "Epoch 33/35\n",
      "0s - loss: 0.3173 - acc: 0.9218 - val_loss: 1.3422 - val_acc: 0.6984\n",
      "Epoch 34/35\n",
      "0s - loss: 0.3150 - acc: 0.9235 - val_loss: 1.3853 - val_acc: 0.6825\n",
      "Epoch 35/35\n",
      "0s - loss: 0.3111 - acc: 0.9185 - val_loss: 1.2541 - val_acc: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6292747b70>"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model5.fit(X_n5,y_n5,batch_size=128,nb_epoch=35,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model5.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.37)(out1)\n",
    "out1 = Dense(9, activation='linear', bias=False,\n",
    "            weights= unary_model5.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model5b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model5b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func5(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model5b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  63.5845216199 %.\n",
      "Accuracy score Unary only:  73.0905279198 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  64.2421926099 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  65.2247225824 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  67.2368467457 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  67.1884852014 %.\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  67.833728834 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  67.8983700752 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  69.1191110701 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  69.8836299142 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  70.1431454851 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  72.0975175757 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  71.9296834019 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  72.4049866453 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  72.318481455 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  72.8399208 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  72.9264259903 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  73.663336139 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  74.026161597 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  74.1126667874 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  74.2302499881 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  74.4330897447 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  74.8641739431 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  74.8641739431 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  74.8641739431 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  74.8641739431 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  74.7171151195 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  74.7171151195 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  74.7171151195 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  74.7171151195 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  74.8036203099 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  74.8036203099 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  74.8036203099 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  74.5493002458 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  75.3336139713 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  75.506624352 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  75.506624352 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  75.506624352 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  75.506624352 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  75.506624352 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  75.7027027833 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  75.7027027833 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  75.7027027833 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  75.7027027833 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  75.7027027833 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  75.7027027833 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  75.7027027833 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  75.5772702574 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  75.5772702574 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  75.7453374843 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  75.4639579641 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  75.4639579641 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  75.4639579641 %.\n",
      "Epoch/Iteration:  21 / 120 . Current Average Test Hamming Accuracy:  75.4639579641 %.\n",
      "Epoch/Iteration:  21 / 122 . Current Average Test Hamming Accuracy:  75.4639579641 %.\n",
      "Epoch/Iteration:  21 / 124 . Current Average Test Hamming Accuracy:  76.3449860511 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  22 / 126 . Current Average Test Hamming Accuracy:  76.3449860511 %.\n",
      "Epoch/Iteration:  22 / 128 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  22 / 130 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  23 / 132 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  23 / 134 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  23 / 136 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  24 / 138 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  24 / 140 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  24 / 142 . Current Average Test Hamming Accuracy:  76.050868404 %.\n",
      "Epoch/Iteration:  25 / 144 . Current Average Test Hamming Accuracy:  77.7315406729 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  25 / 146 . Current Average Test Hamming Accuracy:  77.7315406729 %.\n",
      "Epoch/Iteration:  25 / 148 . Current Average Test Hamming Accuracy:  77.7315406729 %.\n",
      "Final accuracy score:  77.7315406729 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Unary Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 5\n",
    "\n",
    "\n",
    "crf5 = CRF(feat_func5,1+9**2,9, 1e-8, 'B')\n",
    "crf_u5 = CRF(feat_func5,1+9**2,9, 1e-7, 'U')\n",
    "alpha = 0.085\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf5.K-1), np.zeros(crf5.K-1)\n",
    "num_epochs = 25\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc5 = 0\n",
    "\n",
    "\n",
    "acc5_t1 = np.zeros(17)\n",
    "acc5_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc5_t1[n] = 1 - hamming(crf5.MAP(X_ts5[n]), y_ts5[n])\n",
    "    acc5_u[n] = 1 - hamming(crf_u5.MAP(X_ts5[n]), y_ts5[n])\n",
    "print('Initial accuracy score Binary: ',100* acc5_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc5_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr5.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr5.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr5[min_batch[k:k+batch_size]],y_tr5[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr5.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf5.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf5.W[1:] = crf5.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc5_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc5_test[n] = 1 - hamming(crf5.MAP(X_ts5[n]), y_ts5[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc5_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc5 < acc5_test.mean():\n",
    "                best_acc5 = acc5_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc5_test[acc5_test==1].sum()/17, '%')\n",
    "        \n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc5_f = np.zeros(X_ts5.shape[0])\n",
    "\n",
    "for n in range(X_ts5.shape[0]):\n",
    "    acc5_f[n] = 1 - hamming(crf5.MAP(X_ts5[n]), y_ts5[n])\n",
    "    \n",
    "print('Final accuracy score: ',100* acc5_f.mean(), '%.')\n",
    "print('Zero-one-loss: ', 100*acc5_f[acc5_f==1].sum()/17, '%')\n",
    "print('Unary Zero-one-loss: ', 100*acc5_u[acc5_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 6\n",
    "\n",
    "X_tr6, y_tr6 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data6['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data6['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data6['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data6['label_tr'][0][k][t,0]\n",
    "    X_tr6.append(feat)\n",
    "    y_tr6.append(lab)\n",
    "    \n",
    "X_tr6 = np.asarray(X_tr6, dtype='object')\n",
    "y_tr6 = np.asarray(y_tr6, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts6, y_ts6 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data6['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data6['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data6['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data6['label_te'][0][k][t,0]\n",
    "    X_ts6.append(feat)\n",
    "    y_ts6.append(lab)\n",
    "    \n",
    "X_ts6 = np.asarray(X_ts6, dtype='object')\n",
    "y_ts6 = np.asarray(y_ts6, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr6[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr6[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts6[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n6, y_n6 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr6[k].shape[0]):\n",
    "        X_n6[l] = X_tr6[k][j]\n",
    "        y_n6[l][y_tr6[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 6\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.45)(out1)\n",
    "out1 = Dense(11, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model6 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model6.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 647 samples, validate on 35 samples\n",
      "Epoch 1/14\n",
      "0s - loss: 0.4738 - acc: 0.8764 - val_loss: 1.3932 - val_acc: 0.6000\n",
      "Epoch 2/14\n",
      "0s - loss: 0.4479 - acc: 0.8794 - val_loss: 1.6526 - val_acc: 0.5429\n",
      "Epoch 3/14\n",
      "0s - loss: 0.4486 - acc: 0.8903 - val_loss: 1.5723 - val_acc: 0.5714\n",
      "Epoch 4/14\n",
      "0s - loss: 0.4299 - acc: 0.8841 - val_loss: 1.5688 - val_acc: 0.5429\n",
      "Epoch 5/14\n",
      "0s - loss: 0.4592 - acc: 0.8702 - val_loss: 1.3920 - val_acc: 0.5714\n",
      "Epoch 6/14\n",
      "0s - loss: 0.3987 - acc: 0.8856 - val_loss: 1.5188 - val_acc: 0.5714\n",
      "Epoch 7/14\n",
      "0s - loss: 0.4001 - acc: 0.9026 - val_loss: 1.8112 - val_acc: 0.4857\n",
      "Epoch 8/14\n",
      "0s - loss: 0.3852 - acc: 0.9042 - val_loss: 1.5527 - val_acc: 0.5429\n",
      "Epoch 9/14\n",
      "0s - loss: 0.3918 - acc: 0.8964 - val_loss: 1.8474 - val_acc: 0.5429\n",
      "Epoch 10/14\n",
      "0s - loss: 0.4243 - acc: 0.8609 - val_loss: 1.9108 - val_acc: 0.5143\n",
      "Epoch 11/14\n",
      "0s - loss: 0.3645 - acc: 0.9057 - val_loss: 1.7349 - val_acc: 0.5429\n",
      "Epoch 12/14\n",
      "0s - loss: 0.3747 - acc: 0.9026 - val_loss: 1.5747 - val_acc: 0.5714\n",
      "Epoch 13/14\n",
      "0s - loss: 0.4061 - acc: 0.8856 - val_loss: 1.5317 - val_acc: 0.5714\n",
      "Epoch 14/14\n",
      "0s - loss: 0.4350 - acc: 0.8825 - val_loss: 1.6063 - val_acc: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f628cac1240>"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model6.fit(X_n6,y_n6,batch_size=128,nb_epoch=14,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model6.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.45)(out1)\n",
    "out1 = Dense(11, activation='linear', bias=False,\n",
    "            weights= unary_model6.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model6b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model6b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func6(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model6b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  61.0963109994 %.\n",
      "Accuracy score Unary only:  64.949889014 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  62.0314093978 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  63.152594714 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  63.7128188036 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  64.6379256885 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  64.780136419 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  66.2252599229 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  66.1419067436 %.\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  66.3428416067 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  66.2774821296 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  66.3576728746 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  66.626338033 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  66.226318376 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  66.226318376 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  67.2067105328 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  67.9728993613 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  67.3426472605 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  67.1878484989 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  66.8143657724 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  67.2345338397 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  67.2345338397 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  67.2345338397 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  67.2345338397 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  67.1294918229 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  67.1294918229 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  67.5216486856 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  67.9741373734 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  67.2388432557 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  67.6737540622 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  67.3936420173 %.\n",
      "Final accuracy score:  67.3936420173 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Unary Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 6\n",
    "\n",
    "\n",
    "crf6 = CRF(feat_func6,1+11**2,11, 0, 'B')\n",
    "crf_u6 = CRF(feat_func6,1+11**2,11, 1e-7, 'U')\n",
    "alpha = 0.085\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf6.K-1), np.zeros(crf6.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc6 = 0\n",
    "\n",
    "acc6_t1 = np.zeros(17)\n",
    "acc6_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc6_t1[n] = 1 - hamming(crf6.MAP(X_ts6[n]), y_ts6[n])\n",
    "    acc6_u[n] = 1 - hamming(crf_u6.MAP(X_ts6[n]), y_ts6[n])\n",
    "print('Initial accuracy score Binary: ',100* acc6_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc6_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr6.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr6.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr6[min_batch[k:k+batch_size]],y_tr6[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr6.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf6.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf6.W[1:] = crf6.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc6_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc6_test[n] = 1 - hamming(crf6.MAP(X_ts6[n]), y_ts6[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc6_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc6 < acc6_test.mean():\n",
    "                best_acc6 = acc6_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc6_test[acc6_test==1].sum()/17, '%')\n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc6_f = np.zeros(X_ts6.shape[0])\n",
    "\n",
    "for n in range(X_ts6.shape[0]):\n",
    "    acc6_f[n] = 1 - hamming(crf6.MAP(X_ts6[n]), y_ts6[n])\n",
    "    \n",
    "print('Final accuracy score: ',100* acc6_f.mean(), '%.')\n",
    "print('Zero-one-loss: ', 100*acc6_f[acc6_f==1].sum()/17, '%')\n",
    "print('Unary Zero-one-loss: ', 100*acc6_u[acc6_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 7\n",
    "\n",
    "X_tr7, y_tr7 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data7['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data7['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data7['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data7['label_tr'][0][k][t,0]\n",
    "    X_tr7.append(feat)\n",
    "    y_tr7.append(lab)\n",
    "    \n",
    "X_tr7 = np.asarray(X_tr7, dtype='object')\n",
    "y_tr7 = np.asarray(y_tr7, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts7, y_ts7 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data7['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data7['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data7['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data7['label_te'][0][k][t,0]\n",
    "    X_ts7.append(feat)\n",
    "    y_ts7.append(lab)\n",
    "    \n",
    "X_ts7 = np.asarray(X_ts7, dtype='object')\n",
    "y_ts7 = np.asarray(y_ts7, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr7[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr7[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts7[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n7, y_n7 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr7[k].shape[0]):\n",
    "        X_n7[l] = X_tr7[k][j]\n",
    "        y_n7[l][y_tr7[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 7\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.45)(out1)\n",
    "out1 = Dense(10, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model7 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model7.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 693 samples, validate on 37 samples\n",
      "Epoch 1/11\n",
      "0s - loss: 1.9752 - acc: 0.2929 - val_loss: 1.6129 - val_acc: 0.6486\n",
      "Epoch 2/11\n",
      "0s - loss: 1.3585 - acc: 0.6436 - val_loss: 1.0993 - val_acc: 0.8378\n",
      "Epoch 3/11\n",
      "0s - loss: 0.9465 - acc: 0.7633 - val_loss: 0.9304 - val_acc: 0.7838\n",
      "Epoch 4/11\n",
      "0s - loss: 0.7419 - acc: 0.8081 - val_loss: 0.8800 - val_acc: 0.7838\n",
      "Epoch 5/11\n",
      "0s - loss: 0.6555 - acc: 0.8110 - val_loss: 0.6912 - val_acc: 0.8649\n",
      "Epoch 6/11\n",
      "0s - loss: 0.5627 - acc: 0.8485 - val_loss: 0.7260 - val_acc: 0.8649\n",
      "Epoch 7/11\n",
      "0s - loss: 0.4987 - acc: 0.8600 - val_loss: 0.7816 - val_acc: 0.8378\n",
      "Epoch 8/11\n",
      "0s - loss: 0.4578 - acc: 0.8817 - val_loss: 0.6645 - val_acc: 0.8919\n",
      "Epoch 9/11\n",
      "0s - loss: 0.4159 - acc: 0.8903 - val_loss: 0.7301 - val_acc: 0.8649\n",
      "Epoch 10/11\n",
      "0s - loss: 0.4129 - acc: 0.8918 - val_loss: 0.6430 - val_acc: 0.8919\n",
      "Epoch 11/11\n",
      "0s - loss: 0.3908 - acc: 0.9033 - val_loss: 0.6194 - val_acc: 0.8919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f628b965e48>"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model7.fit(X_n7,y_n7,batch_size=128,nb_epoch=11,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model7.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.45)(out1)\n",
    "out1 = Dense(10, activation='linear', bias=False,\n",
    "            weights= unary_model7.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model7b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model7b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func7(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model7b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  70.668075565 %.\n",
      "Accuracy score Unary only:  73.1019640753 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  69.9186050451 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  71.5882436322 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  72.1410186638 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  74.1882122641 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  74.3669896574 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  74.8201027208 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  76.0608368193 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  74.7769439692 %.\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  74.4060719362 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  73.9668521306 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  74.1985811859 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  72.7528575891 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  72.9489360205 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  72.458739942 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  72.458739942 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  72.7216850314 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  70.0033249601 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  70.0033249601 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  70.2340054676 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  70.2340054676 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  70.7045937029 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  70.7045937029 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  70.8135261647 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  70.8135261647 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  70.8135261647 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  70.8135261647 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  70.8135261647 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  70.8135261647 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  72.7211932563 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  72.7211932563 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  72.7211932563 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  72.9050167858 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  72.9050167858 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  72.9050167858 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  72.9050167858 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  74.7504608457 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  74.7504608457 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  74.6819775701 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  72.7211932563 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  74.4981540407 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  74.6819775701 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  74.6819775701 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  74.6819775701 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  74.4858991387 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  74.4858991387 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  73.9957030603 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  75.5643305112 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  75.5643305112 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  75.5643305112 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  75.5643305112 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  76.7408010995 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  76.7408010995 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  76.7408010995 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  76.7408010995 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  77.9121787415 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  77.9121787415 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  77.9121787415 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  77.9121787415 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  77.9121787415 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  77.9121787415 %.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The 1d arrays must have equal lengths.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-631327977d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ts7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0macc7_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhamming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ts6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final accuracy score: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0macc7_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mhamming\u001b[0;34m(u, v)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The 1d arrays must have equal lengths.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The 1d arrays must have equal lengths."
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 7\n",
    "\n",
    "\n",
    "crf7 = CRF(feat_func7,1+10**2,10, 0, 'B')\n",
    "crf_u7 = CRF(feat_func7,1+10**2,10, 1e-7, 'U')\n",
    "alpha = 0.09\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf7.K-1), np.zeros(crf7.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc7 = 0\n",
    "\n",
    "acc7_t1 = np.zeros(17)\n",
    "acc7_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc7_t1[n] = 1 - hamming(crf7.MAP(X_ts7[n]), y_ts7[n])\n",
    "    acc7_u[n] = 1 - hamming(crf_u7.MAP(X_ts7[n]), y_ts7[n])\n",
    "print('Initial accuracy score Binary: ',100* acc7_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc7_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr7.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr7.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr7[min_batch[k:k+batch_size]],y_tr7[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr7.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf7.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf7.W[1:] = crf7.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc7_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc7_test[n] = 1 - hamming(crf7.MAP(X_ts7[n]), y_ts7[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc7_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc7 < acc7_test.mean():\n",
    "                best_acc7 = acc7_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc7_test[acc7_test==1].sum()/17, '%')\n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "acc7_f = np.zeros(X_ts7.shape[0])\n",
    "\n",
    "for n in range(X_ts7.shape[0]):\n",
    "    acc7_f[n] = 1 - hamming(crf7.MAP(X_ts7[n]), y_ts7[n])\n",
    "    \n",
    "print('Final accuracy score: ',100* acc7_f.mean(), '%.')\n",
    "print('Zero-one-loss: ', 100*acc7_f[acc7_f==1].sum()/17, '%')\n",
    "print('Unary Zero-one-loss: ', 100*acc7_u[acc7_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 8\n",
    "\n",
    "X_tr8, y_tr8 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data8['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data8['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data8['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data8['label_tr'][0][k][t,0]\n",
    "    X_tr8.append(feat)\n",
    "    y_tr8.append(lab)\n",
    "    \n",
    "X_tr8 = np.asarray(X_tr8, dtype='object')\n",
    "y_tr8 = np.asarray(y_tr8, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts8, y_ts8 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data8['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data8['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data8['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data8['label_te'][0][k][t,0]\n",
    "    X_ts8.append(feat)\n",
    "    y_ts8.append(lab)\n",
    "    \n",
    "X_ts8 = np.asarray(X_ts8, dtype='object')\n",
    "y_ts8 = np.asarray(y_ts8, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr8[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr8[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts8[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n8, y_n8 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr8[k].shape[0]):\n",
    "        X_n8[l] = X_tr8[k][j]\n",
    "        y_n8[l][y_tr8[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 8\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(12, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model8 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model8.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 923 samples, validate on 49 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 0.3008 - acc: 0.9339 - val_loss: 1.5073 - val_acc: 0.6735\n",
      "Epoch 2/15\n",
      "0s - loss: 0.2925 - acc: 0.9404 - val_loss: 1.4760 - val_acc: 0.6939\n",
      "Epoch 3/15\n",
      "0s - loss: 0.2822 - acc: 0.9458 - val_loss: 1.4657 - val_acc: 0.6735\n",
      "Epoch 4/15\n",
      "0s - loss: 0.2781 - acc: 0.9426 - val_loss: 1.6300 - val_acc: 0.6531\n",
      "Epoch 5/15\n",
      "0s - loss: 0.2894 - acc: 0.9426 - val_loss: 1.5378 - val_acc: 0.7143\n",
      "Epoch 6/15\n",
      "0s - loss: 0.3039 - acc: 0.9361 - val_loss: 1.5663 - val_acc: 0.6531\n",
      "Epoch 7/15\n",
      "0s - loss: 0.2855 - acc: 0.9382 - val_loss: 1.5934 - val_acc: 0.6735\n",
      "Epoch 8/15\n",
      "0s - loss: 0.2756 - acc: 0.9393 - val_loss: 1.5122 - val_acc: 0.6939\n",
      "Epoch 9/15\n",
      "0s - loss: 0.2744 - acc: 0.9404 - val_loss: 1.8205 - val_acc: 0.6122\n",
      "Epoch 10/15\n",
      "0s - loss: 0.2642 - acc: 0.9437 - val_loss: 1.3949 - val_acc: 0.7143\n",
      "Epoch 11/15\n",
      "0s - loss: 0.2668 - acc: 0.9480 - val_loss: 1.5483 - val_acc: 0.6939\n",
      "Epoch 12/15\n",
      "0s - loss: 0.2658 - acc: 0.9447 - val_loss: 1.7157 - val_acc: 0.6531\n",
      "Epoch 13/15\n",
      "0s - loss: 0.2658 - acc: 0.9458 - val_loss: 1.5015 - val_acc: 0.6939\n",
      "Epoch 14/15\n",
      "0s - loss: 0.2493 - acc: 0.9469 - val_loss: 1.5707 - val_acc: 0.6939\n",
      "Epoch 15/15\n",
      "0s - loss: 0.2609 - acc: 0.9458 - val_loss: 1.5858 - val_acc: 0.6939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f628a942358>"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model8.fit(X_n8,y_n8,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model8.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(12, activation='linear', bias=False,\n",
    "            weights= unary_model8.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model8b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model8b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func8(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model8b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  59.4707474531 %.\n",
      "Accuracy score Unary only:  63.3089368797 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  60.4123507057 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  61.4748467969 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  61.6838804104 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  61.8925449573 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  62.2529477391 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  63.644359383 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  64.2439470441 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  64.3002195531 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  63.8296313178 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  63.8296313178 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  64.3350347247 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  64.3350347247 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  64.3350347247 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  64.2501930957 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  63.267943432 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  63.8281675216 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  63.8281675216 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  63.8281675216 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  64.1461325454 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  64.2794781914 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  63.7031665857 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  63.7031665857 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  64.6916230728 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  64.6916230728 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  64.8116710921 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  64.4426045465 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  64.4426045465 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  64.6777649237 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  64.6777649237 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  64.6777649237 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  64.4749251671 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  64.3392187106 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  64.3392187106 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  64.52304224 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  64.52304224 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  64.52304224 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  64.8410072638 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  64.0006711294 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  64.1844946588 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  64.1844946588 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  64.1844946588 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  64.1844946588 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  64.3434771707 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  64.3434771707 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  64.1596536413 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  64.1596536413 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  64.1596536413 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  64.5273007001 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  64.5273007001 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  64.2715462244 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  63.9038991656 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  63.9038991656 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  63.9038991656 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 8\n",
    "\n",
    "\n",
    "crf8 = CRF(feat_func8,1+12**2,12, 0, 'B')\n",
    "crf_u8 = CRF(feat_func8,1+12**2,12, 1e-7, 'U')\n",
    "alpha = 0.09\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf8.K-1), np.zeros(crf8.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc8 = 0\n",
    "\n",
    "acc8_t1 = np.zeros(17)\n",
    "acc8_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc8_t1[n] = 1 - hamming(crf8.MAP(X_ts8[n]), y_ts8[n])\n",
    "    acc8_u[n] = 1 - hamming(crf_u8.MAP(X_ts8[n]), y_ts8[n])\n",
    "print('Initial accuracy score Binary: ',100* acc8_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc8_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr8.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr8.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr8[min_batch[k:k+batch_size]],y_tr8[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr8.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf8.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf8.W[1:] = crf8.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc8_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc8_test[n] = 1 - hamming(crf8.MAP(X_ts8[n]), y_ts8[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc8_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc8 < acc8_test.mean():\n",
    "                best_acc8 = acc8_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc8_test[acc8_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 9\n",
    "\n",
    "X_tr9, y_tr9 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data9['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data9['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data9['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data9['label_tr'][0][k][t,0]\n",
    "    X_tr9.append(feat)\n",
    "    y_tr9.append(lab)\n",
    "    \n",
    "X_tr9 = np.asarray(X_tr9, dtype='object')\n",
    "y_tr9 = np.asarray(y_tr9, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts9, y_ts9 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data9['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data9['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data9['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data9['label_te'][0][k][t,0]\n",
    "    X_ts9.append(feat)\n",
    "    y_ts9.append(lab)\n",
    "    \n",
    "X_ts9 = np.asarray(X_ts9, dtype='object')\n",
    "y_ts9 = np.asarray(y_ts9, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr9[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr9[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts9[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n9, y_n9 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr9[k].shape[0]):\n",
    "        X_n9[l] = X_tr9[k][j]\n",
    "        y_n9[l][y_tr9[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 9\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(10, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model9 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model9.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 850 samples, validate on 45 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 2.0189 - acc: 0.2741 - val_loss: 2.3105 - val_acc: 0.2000\n",
      "Epoch 2/15\n",
      "0s - loss: 1.3779 - acc: 0.6600 - val_loss: 1.3189 - val_acc: 0.6444\n",
      "Epoch 3/15\n",
      "0s - loss: 0.9468 - acc: 0.7435 - val_loss: 1.1118 - val_acc: 0.6444\n",
      "Epoch 4/15\n",
      "0s - loss: 0.7121 - acc: 0.7906 - val_loss: 0.8718 - val_acc: 0.7556\n",
      "Epoch 5/15\n",
      "0s - loss: 0.6035 - acc: 0.8165 - val_loss: 0.7318 - val_acc: 0.7778\n",
      "Epoch 6/15\n",
      "0s - loss: 0.5263 - acc: 0.8376 - val_loss: 0.7762 - val_acc: 0.7556\n",
      "Epoch 7/15\n",
      "0s - loss: 0.4621 - acc: 0.8576 - val_loss: 0.6208 - val_acc: 0.8000\n",
      "Epoch 8/15\n",
      "0s - loss: 0.4229 - acc: 0.8776 - val_loss: 0.6478 - val_acc: 0.8222\n",
      "Epoch 9/15\n",
      "0s - loss: 0.3892 - acc: 0.8847 - val_loss: 0.5280 - val_acc: 0.8444\n",
      "Epoch 10/15\n",
      "0s - loss: 0.3608 - acc: 0.9000 - val_loss: 0.6813 - val_acc: 0.7333\n",
      "Epoch 11/15\n",
      "0s - loss: 0.3298 - acc: 0.9165 - val_loss: 0.4961 - val_acc: 0.8444\n",
      "Epoch 12/15\n",
      "0s - loss: 0.3146 - acc: 0.9176 - val_loss: 0.5990 - val_acc: 0.8000\n",
      "Epoch 13/15\n",
      "0s - loss: 0.2836 - acc: 0.9329 - val_loss: 0.5292 - val_acc: 0.8667\n",
      "Epoch 14/15\n",
      "0s - loss: 0.2754 - acc: 0.9365 - val_loss: 0.5409 - val_acc: 0.8222\n",
      "Epoch 15/15\n",
      "0s - loss: 0.2495 - acc: 0.9388 - val_loss: 0.5313 - val_acc: 0.8222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62896275f8>"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model9.fit(X_n9,y_n9,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model9.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(10, activation='linear', bias=False,\n",
    "            weights= unary_model9.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model9b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model9b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_func9(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model9b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  75.531951209 %.\n",
      "Accuracy score Unary only:  81.2996471213 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  75.8944901691 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  77.1673764355 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  79.1027395447 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  80.7935920546 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  81.9724454711 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  83.4408244117 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  83.4614128325 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  84.369808845 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  84.3609709283 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  84.6746964185 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  85.2647665311 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  85.2647665311 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  85.8502785136 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  85.945155174 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  86.1412336053 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  86.2426534836 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  86.2426534836 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  86.3861255066 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  86.3861255066 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  86.3861255066 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  86.4810021669 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  86.2849237356 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  86.2849237356 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  86.2849237356 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  86.2849237356 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  86.2849237356 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  86.2849237356 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  86.8731590297 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  87.0629123504 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  87.2411654698 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  87.2411654698 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  87.2411654698 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  87.2411654698 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  87.2411654698 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  87.6206721112 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  87.6206721112 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  87.6206721112 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  87.6206721112 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  87.6206721112 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  87.6206721112 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  87.6206721112 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  87.7155487715 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  87.8590207945 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  87.8590207945 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  87.8590207945 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  87.8590207945 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 9\n",
    "\n",
    "\n",
    "crf9 = CRF(feat_func9,1+10**2,10, 0, 'B')\n",
    "crf_u9 = CRF(feat_func9,1+10**2,10, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf9.K-1), np.zeros(crf9.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc9 = 0\n",
    "\n",
    "acc9_t1 = np.zeros(17)\n",
    "acc9_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc9_t1[n] = 1 - hamming(crf9.MAP(X_ts9[n]), y_ts9[n])\n",
    "    acc9_u[n] = 1 - hamming(crf_u9.MAP(X_ts9[n]), y_ts9[n])\n",
    "print('Initial accuracy score Binary: ',100* acc9_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc9_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr9.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr9.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr9[min_batch[k:k+batch_size]],y_tr9[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr9.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf9.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf9.W[1:] = crf9.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc9_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc9_test[n] = 1 - hamming(crf9.MAP(X_ts9[n]), y_ts9[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc9_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc9 < acc9_test.mean():\n",
    "                best_acc9 = acc9_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc9_test[acc8_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 10\n",
    "\n",
    "X_tr10, y_tr10 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data10['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data10['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data10['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data10['label_tr'][0][k][t,0]\n",
    "    X_tr10.append(feat)\n",
    "    y_tr10.append(lab)\n",
    "    \n",
    "X_tr10 = np.asarray(X_tr10, dtype='object')\n",
    "y_tr10 = np.asarray(y_tr10, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts10, y_ts10 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data10['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data10['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data10['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data10['label_te'][0][k][t,0]\n",
    "    X_ts10.append(feat)\n",
    "    y_ts10.append(lab)\n",
    "    \n",
    "X_ts10 = np.asarray(X_ts10, dtype='object')\n",
    "y_ts10 = np.asarray(y_ts10, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr10[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr10[k].max())\n",
    "for k in range(16):\n",
    "    max_l = max(max_l, y_ts10[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n10, y_n10 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr10[k].shape[0]):\n",
    "        X_n10[l] = X_tr10[k][j]\n",
    "        y_n10[l][y_tr10[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 10\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(10, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model10 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model10.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 780 samples, validate on 42 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 2.1094 - acc: 0.2667 - val_loss: 1.9310 - val_acc: 0.2143\n",
      "Epoch 2/15\n",
      "0s - loss: 1.6737 - acc: 0.4603 - val_loss: 1.4802 - val_acc: 0.6190\n",
      "Epoch 3/15\n",
      "0s - loss: 1.4023 - acc: 0.5936 - val_loss: 1.2965 - val_acc: 0.5952\n",
      "Epoch 4/15\n",
      "0s - loss: 1.2225 - acc: 0.6385 - val_loss: 1.0750 - val_acc: 0.6905\n",
      "Epoch 5/15\n",
      "0s - loss: 1.1032 - acc: 0.6744 - val_loss: 1.0581 - val_acc: 0.6667\n",
      "Epoch 6/15\n",
      "0s - loss: 1.0228 - acc: 0.6923 - val_loss: 1.0479 - val_acc: 0.7381\n",
      "Epoch 7/15\n",
      "0s - loss: 0.9118 - acc: 0.7423 - val_loss: 0.8458 - val_acc: 0.7381\n",
      "Epoch 8/15\n",
      "0s - loss: 0.8836 - acc: 0.7385 - val_loss: 0.8744 - val_acc: 0.7857\n",
      "Epoch 9/15\n",
      "0s - loss: 0.7957 - acc: 0.7846 - val_loss: 0.9787 - val_acc: 0.7619\n",
      "Epoch 10/15\n",
      "0s - loss: 0.7398 - acc: 0.8038 - val_loss: 0.9947 - val_acc: 0.6429\n",
      "Epoch 11/15\n",
      "0s - loss: 0.7023 - acc: 0.8026 - val_loss: 0.8509 - val_acc: 0.8333\n",
      "Epoch 12/15\n",
      "0s - loss: 0.7024 - acc: 0.8103 - val_loss: 1.0256 - val_acc: 0.7381\n",
      "Epoch 13/15\n",
      "0s - loss: 0.6435 - acc: 0.8308 - val_loss: 0.9283 - val_acc: 0.6905\n",
      "Epoch 14/15\n",
      "0s - loss: 0.6011 - acc: 0.8410 - val_loss: 0.8658 - val_acc: 0.7857\n",
      "Epoch 15/15\n",
      "0s - loss: 0.6026 - acc: 0.8590 - val_loss: 0.9568 - val_acc: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6289137390>"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model10.fit(X_n10,y_n10,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model10.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(10, activation='linear', bias=False,\n",
    "            weights= unary_model10.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model10b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model10b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func10(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model10b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  55.7538696592 %.\n",
      "Accuracy score Unary only:  57.2903694797 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  57.1915751226 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  56.7903801845 %.\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  62.0465625674 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  61.875980095 %.\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  62.8319195804 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  62.8949937611 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  63.5170471301 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  63.8165123707 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  64.3786952859 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  65.3372262111 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  64.2242948117 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  62.5130648652 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  63.1597957984 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  62.5062010271 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  62.5062010271 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  64.110479102 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  64.110479102 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  62.238821348 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  62.238821348 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  62.238821348 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  62.4741154656 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  62.6249450282 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  62.6249450282 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  63.2282632786 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  63.0648645858 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  63.1758523771 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  63.1758523771 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  63.1758523771 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  63.1758523771 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  64.2486003169 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  65.2289924737 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  65.2289924737 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  65.2289924737 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  65.2289924737 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  65.2289924737 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  66.3727833234 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  66.3727833234 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  66.3727833234 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  66.3727833234 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  65.882587245 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  65.7317576824 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  66.9082282706 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  67.0590578332 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  67.0590578332 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  67.0590578332 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  67.0590578332 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  67.0590578332 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  66.9082282706 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  67.8707951155 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  67.8707951155 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  68.0927706982 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  68.6042796496 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  68.6042796496 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 10\n",
    "\n",
    "\n",
    "crf10 = CRF(feat_func10,1+10**2,10, 0, 'B')\n",
    "crf_u10 = CRF(feat_func10,1+10**2,10, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf10.K-1), np.zeros(crf10.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc10 = 0\n",
    "\n",
    "acc10_t1 = np.zeros(17)\n",
    "acc10_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc10_t1[n] = 1 - hamming(crf10.MAP(X_ts10[n]), y_ts10[n])\n",
    "    acc10_u[n] = 1 - hamming(crf_u10.MAP(X_ts10[n]), y_ts10[n])\n",
    "print('Initial accuracy score Binary: ',100* acc10_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc10_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr10.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr10.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr10[min_batch[k:k+batch_size]],y_tr10[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr10.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf10.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf10.W[1:] = crf10.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc10_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc10_test[n] = 1 - hamming(crf10.MAP(X_ts10[n]), y_ts10[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc10_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc10 < acc10_test.mean():\n",
    "                best_acc10 = acc10_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc10_test[acc10_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 11\n",
    "\n",
    "X_tr11, y_tr11 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data11['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data11['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data11['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data11['label_tr'][0][k][t,0]\n",
    "    X_tr11.append(feat)\n",
    "    y_tr11.append(lab)\n",
    "    \n",
    "X_tr11 = np.asarray(X_tr11, dtype='object')\n",
    "y_tr11 = np.asarray(y_tr11, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts11, y_ts11 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data11['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data11['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data11['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data11['label_te'][0][k][t,0]\n",
    "    X_ts11.append(feat)\n",
    "    y_ts11.append(lab)\n",
    "    \n",
    "X_ts11 = np.asarray(X_ts11, dtype='object')\n",
    "y_ts11 = np.asarray(y_ts11, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr11[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr11[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts11[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n11, y_n11 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr11[k].shape[0]):\n",
    "        X_n11[l] = X_tr11[k][j]\n",
    "        y_n11[l][y_tr11[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 11\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(9, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model11 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model11.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1099 samples, validate on 58 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 1.7607 - acc: 0.4149 - val_loss: 1.6187 - val_acc: 0.3793\n",
      "Epoch 2/15\n",
      "0s - loss: 1.3091 - acc: 0.5905 - val_loss: 1.4998 - val_acc: 0.4655\n",
      "Epoch 3/15\n",
      "0s - loss: 1.0276 - acc: 0.6770 - val_loss: 1.0756 - val_acc: 0.5862\n",
      "Epoch 4/15\n",
      "0s - loss: 0.8592 - acc: 0.7370 - val_loss: 1.1573 - val_acc: 0.5690\n",
      "Epoch 5/15\n",
      "0s - loss: 0.7647 - acc: 0.7698 - val_loss: 1.0189 - val_acc: 0.6897\n",
      "Epoch 6/15\n",
      "0s - loss: 0.7088 - acc: 0.7898 - val_loss: 0.9729 - val_acc: 0.6552\n",
      "Epoch 7/15\n",
      "0s - loss: 0.6741 - acc: 0.8025 - val_loss: 1.0212 - val_acc: 0.6552\n",
      "Epoch 8/15\n",
      "0s - loss: 0.6539 - acc: 0.7925 - val_loss: 0.9475 - val_acc: 0.7069\n",
      "Epoch 9/15\n",
      "0s - loss: 0.5972 - acc: 0.8089 - val_loss: 0.9729 - val_acc: 0.7069\n",
      "Epoch 10/15\n",
      "0s - loss: 0.5711 - acc: 0.8280 - val_loss: 0.9407 - val_acc: 0.7069\n",
      "Epoch 11/15\n",
      "0s - loss: 0.5562 - acc: 0.8253 - val_loss: 0.9430 - val_acc: 0.6207\n",
      "Epoch 12/15\n",
      "0s - loss: 0.5207 - acc: 0.8417 - val_loss: 0.8972 - val_acc: 0.6724\n",
      "Epoch 13/15\n",
      "0s - loss: 0.5005 - acc: 0.8590 - val_loss: 1.0116 - val_acc: 0.6552\n",
      "Epoch 14/15\n",
      "0s - loss: 0.4870 - acc: 0.8581 - val_loss: 0.9327 - val_acc: 0.6724\n",
      "Epoch 15/15\n",
      "0s - loss: 0.4573 - acc: 0.8690 - val_loss: 0.8943 - val_acc: 0.6724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62873e7f98>"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model11.fit(X_n11,y_n11,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model11.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(9, activation='linear', bias=False,\n",
    "            weights= unary_model11.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model11b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model11b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func11(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model11b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  59.0958235196 %.\n",
      "Accuracy score Unary only:  66.2351178692 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  59.9206412389 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  60.6744245143 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  62.7519810036 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  63.86754377 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  64.6202588599 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  64.9132589557 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  64.9807379319 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  65.5679032898 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  66.0588582924 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  66.791261819 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  67.417932942 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  67.417932942 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  67.7639537032 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  68.1207876132 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  68.1207876132 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  67.8529304704 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  67.9357805118 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  67.8517468984 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  67.8517468984 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  68.3561574447 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  68.5151399566 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  68.4475267044 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  68.4475267044 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  68.4475267044 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  68.5394384691 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  68.5394384691 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  68.5394384691 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  68.5394384691 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  68.6746649735 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  68.6746649735 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  68.6746649735 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  68.6746649735 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  69.1548570503 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  69.1548570503 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  69.1548570503 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  69.7430923445 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  69.7430923445 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  69.7430923445 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  70.3848035744 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  70.3848035744 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  70.6369044147 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  71.1170964916 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  71.5766553151 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  71.5766553151 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  71.6606889286 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  71.6606889286 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  71.6606889286 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  71.6606889286 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  71.9273624994 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  71.9273624994 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  71.9273624994 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 11\n",
    "\n",
    "\n",
    "crf11 = CRF(feat_func11,1+9**2,9, 0, 'B')\n",
    "crf_u11 = CRF(feat_func11,1+9**2,9, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf11.K-1), np.zeros(crf11.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc11 = 0\n",
    "\n",
    "acc11_t1 = np.zeros(17)\n",
    "acc11_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc11_t1[n] = 1 - hamming(crf11.MAP(X_ts11[n]), y_ts11[n])\n",
    "    acc11_u[n] = 1 - hamming(crf_u11.MAP(X_ts11[n]), y_ts11[n])\n",
    "print('Initial accuracy score Binary: ',100* acc11_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc11_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr11.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr11.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr11[min_batch[k:k+batch_size]],y_tr11[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr11.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf11.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf11.W[1:] = crf11.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc11_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc11_test[n] = 1 - hamming(crf11.MAP(X_ts11[n]), y_ts11[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc11_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc11 < acc11_test.mean():\n",
    "                best_acc11 = acc11_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc11_test[acc11_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 12\n",
    "\n",
    "X_tr12, y_tr12 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data12['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data12['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data12['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data12['label_tr'][0][k][t,0]\n",
    "    X_tr12.append(feat)\n",
    "    y_tr12.append(lab)\n",
    "    \n",
    "X_tr12 = np.asarray(X_tr12, dtype='object')\n",
    "y_tr12 = np.asarray(y_tr12, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts12, y_ts12 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data12['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data12['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data12['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data12['label_te'][0][k][t,0]\n",
    "    X_ts12.append(feat)\n",
    "    y_ts12.append(lab)\n",
    "    \n",
    "X_ts12 = np.asarray(X_ts12, dtype='object')\n",
    "y_ts12 = np.asarray(y_ts12, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr12[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr12[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts12[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n12, y_n12 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr12[k].shape[0]):\n",
    "        X_n12[l] = X_tr12[k][j]\n",
    "        y_n12[l][y_tr12[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 12\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(12, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model12 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model12.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 760 samples, validate on 41 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 0.1709 - acc: 0.9671 - val_loss: 0.7452 - val_acc: 0.7317\n",
      "Epoch 2/15\n",
      "0s - loss: 0.1736 - acc: 0.9592 - val_loss: 0.8788 - val_acc: 0.7073\n",
      "Epoch 3/15\n",
      "0s - loss: 0.1471 - acc: 0.9618 - val_loss: 0.8328 - val_acc: 0.6829\n",
      "Epoch 4/15\n",
      "0s - loss: 0.1455 - acc: 0.9658 - val_loss: 0.7914 - val_acc: 0.7073\n",
      "Epoch 5/15\n",
      "0s - loss: 0.1417 - acc: 0.9671 - val_loss: 0.8839 - val_acc: 0.6829\n",
      "Epoch 6/15\n",
      "0s - loss: 0.1384 - acc: 0.9658 - val_loss: 0.7742 - val_acc: 0.7073\n",
      "Epoch 7/15\n",
      "0s - loss: 0.1451 - acc: 0.9658 - val_loss: 0.8902 - val_acc: 0.7073\n",
      "Epoch 8/15\n",
      "0s - loss: 0.1327 - acc: 0.9724 - val_loss: 0.5981 - val_acc: 0.7561\n",
      "Epoch 9/15\n",
      "0s - loss: 0.1370 - acc: 0.9724 - val_loss: 0.9623 - val_acc: 0.6341\n",
      "Epoch 10/15\n",
      "0s - loss: 0.1240 - acc: 0.9697 - val_loss: 0.7176 - val_acc: 0.7073\n",
      "Epoch 11/15\n",
      "0s - loss: 0.1181 - acc: 0.9697 - val_loss: 0.8667 - val_acc: 0.6829\n",
      "Epoch 12/15\n",
      "0s - loss: 0.1113 - acc: 0.9789 - val_loss: 0.7933 - val_acc: 0.7073\n",
      "Epoch 13/15\n",
      "0s - loss: 0.1177 - acc: 0.9789 - val_loss: 0.8991 - val_acc: 0.7073\n",
      "Epoch 14/15\n",
      "0s - loss: 0.1141 - acc: 0.9776 - val_loss: 0.8866 - val_acc: 0.7073\n",
      "Epoch 15/15\n",
      "0s - loss: 0.1057 - acc: 0.9816 - val_loss: 0.7504 - val_acc: 0.7317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6286a31898>"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model12.fit(X_n12,y_n12,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model12.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(12, activation='linear', bias=False,\n",
    "            weights= unary_model12.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model12b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model12b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func12(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model12b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  79.8969317384 %.\n",
      "Accuracy score Unary only:  80.4504612906 %.\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  79.6757150466 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  80.9993063105 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  81.0860130362 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  81.7113204797 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  82.2269018204 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  82.2269018204 %.\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  82.7543642674 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  83.3947817247 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  82.9179792305 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  83.3381472977 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  83.1700800708 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  83.2529301122 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  83.0719346371 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  82.852223924 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  82.9350739655 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  82.8575044761 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  83.4352355686 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  83.4352355686 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  83.8554036358 %.\n",
      "Zero-one-loss:  23.5294117647 %\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  83.6453196022 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  83.7386902838 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  83.8335669441 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  83.8335669441 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  83.8335669441 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  83.8335669441 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  83.8335669441 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  83.8335669441 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  84.0514318679 %.\n",
      "Zero-one-loss:  23.5294117647 %\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  84.2542716245 %.\n",
      "Zero-one-loss:  23.5294117647 %\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  84.2542716245 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  84.2542716245 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  84.1609009429 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  84.5810690101 %.\n",
      "Zero-one-loss:  29.4117647059 %\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  84.5810690101 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  84.6639190515 %.\n",
      "Zero-one-loss:  29.4117647059 %\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  84.6639190515 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  84.6639190515 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  84.6639190515 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  84.6639190515 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  84.6639190515 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  84.3371216659 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  84.3371216659 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  84.3371216659 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  84.3371216659 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  84.3371216659 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  84.6639190515 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  84.2437509843 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  84.5332000973 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  84.5332000973 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  84.5332000973 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  84.5332000973 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  84.5332000973 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  84.5332000973 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 12\n",
    "\n",
    "\n",
    "crf12 = CRF(feat_func12,1+12**2,12, 0, 'B')\n",
    "crf_u12 = CRF(feat_func12,1+12**2,12, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf12.K-1), np.zeros(crf12.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc12 = 0\n",
    "\n",
    "acc12_t1 = np.zeros(17)\n",
    "acc12_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc12_t1[n] = 1 - hamming(crf12.MAP(X_ts12[n]), y_ts12[n])\n",
    "    acc12_u[n] = 1 - hamming(crf_u12.MAP(X_ts12[n]), y_ts12[n])\n",
    "print('Initial accuracy score Binary: ',100* acc12_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc12_u.mean(), '%.')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr12.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr12.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr12[min_batch[k:k+batch_size]],y_tr12[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr12.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf12.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf12.W[1:] = crf12.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc12_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc12_test[n] = 1 - hamming(crf12.MAP(X_ts12[n]), y_ts12[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc12_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc12 < acc12_test.mean():\n",
    "                best_acc12 = acc12_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc12_test[acc12_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Zero-one-loss: ', 100*acc12_u[acc12_u==1].sum()/17, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 13\n",
    "\n",
    "X_tr13, y_tr13 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data13['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data13['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data13['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data13['label_tr'][0][k][t,0]\n",
    "    X_tr13.append(feat)\n",
    "    y_tr13.append(lab)\n",
    "    \n",
    "X_tr13 = np.asarray(X_tr13, dtype='object')\n",
    "y_tr13 = np.asarray(y_tr13, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts13, y_ts13 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data13['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data13['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data13['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data13['label_te'][0][k][t,0]\n",
    "    X_ts13.append(feat)\n",
    "    y_ts13.append(lab)\n",
    "    \n",
    "X_ts13 = np.asarray(X_ts13, dtype='object')\n",
    "y_ts13 = np.asarray(y_ts13, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr13[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr13[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts13[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n13, y_n13 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr13[k].shape[0]):\n",
    "        X_n13[l] = X_tr13[k][j]\n",
    "        y_n13[l][y_tr13[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 13\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(13, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model13 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model13.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 520 samples, validate on 28 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 0.3233 - acc: 0.9346 - val_loss: 0.8757 - val_acc: 0.8571\n",
      "Epoch 2/15\n",
      "0s - loss: 0.2989 - acc: 0.9404 - val_loss: 0.8583 - val_acc: 0.8571\n",
      "Epoch 3/15\n",
      "0s - loss: 0.2752 - acc: 0.9519 - val_loss: 1.0194 - val_acc: 0.7500\n",
      "Epoch 4/15\n",
      "0s - loss: 0.2745 - acc: 0.9481 - val_loss: 0.9423 - val_acc: 0.7857\n",
      "Epoch 5/15\n",
      "0s - loss: 0.2585 - acc: 0.9558 - val_loss: 0.8303 - val_acc: 0.8571\n",
      "Epoch 6/15\n",
      "0s - loss: 0.2397 - acc: 0.9596 - val_loss: 0.8874 - val_acc: 0.8214\n",
      "Epoch 7/15\n",
      "0s - loss: 0.2951 - acc: 0.9308 - val_loss: 0.9701 - val_acc: 0.7857\n",
      "Epoch 8/15\n",
      "0s - loss: 0.2715 - acc: 0.9481 - val_loss: 0.8807 - val_acc: 0.8214\n",
      "Epoch 9/15\n",
      "0s - loss: 0.3108 - acc: 0.9327 - val_loss: 1.0153 - val_acc: 0.7500\n",
      "Epoch 10/15\n",
      "0s - loss: 0.2720 - acc: 0.9481 - val_loss: 1.3624 - val_acc: 0.7500\n",
      "Epoch 11/15\n",
      "0s - loss: 0.2968 - acc: 0.9385 - val_loss: 1.0666 - val_acc: 0.8214\n",
      "Epoch 12/15\n",
      "0s - loss: 0.2503 - acc: 0.9519 - val_loss: 0.9303 - val_acc: 0.8214\n",
      "Epoch 13/15\n",
      "0s - loss: 0.2691 - acc: 0.9500 - val_loss: 0.7733 - val_acc: 0.8571\n",
      "Epoch 14/15\n",
      "0s - loss: 0.2420 - acc: 0.9596 - val_loss: 0.9633 - val_acc: 0.7857\n",
      "Epoch 15/15\n",
      "0s - loss: 0.2364 - acc: 0.9500 - val_loss: 1.0536 - val_acc: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62869ec320>"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model13.fit(X_n13,y_n13,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model13.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.3)(out1)\n",
    "out1 = Dense(13, activation='linear', bias=False,\n",
    "            weights= unary_model13.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model13b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model13b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func13(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model13b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  77.3069015212 %.\n",
      "Accuracy score Unary only:  76.9220227042 %.\n",
      "Zero-one-loss Unary:  5.88235294118 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  77.9750674198 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  77.3046085459 %.\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  78.5488724138 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  79.188668549 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  79.6835413614 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  80.2137981996 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  80.7201545883 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  80.830411457 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  80.3999953881 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  80.6178603119 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  80.3825661942 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  80.3825661942 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  80.3825661942 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  80.3825661942 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  80.662678239 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  80.662678239 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  81.0380283791 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  80.4122461513 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  80.1564916756 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  80.0257727213 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  79.4240590408 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  79.554777995 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  79.6854969493 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  80.5559857245 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  80.8827831101 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  80.7549058723 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  80.1486967219 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  79.7945751402 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  80.3293344985 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  80.3293344985 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  79.7945751402 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  79.824085272 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  79.824085272 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  80.1508826576 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  80.0108266352 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  80.0108266352 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  80.0108266352 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  81.64852717 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  81.64852717 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  80.9760020624 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  81.1160580848 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  81.1160580848 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  81.1160580848 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  81.1160580848 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  81.1160580848 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  81.246777039 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  81.6222463757 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  80.0179683008 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  80.0179683008 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  80.0179683008 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  80.2794062093 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 13\n",
    "\n",
    "\n",
    "crf13 = CRF(feat_func13,1+13**2,13, 0, 'B')\n",
    "crf_u13 = CRF(feat_func13,1+13**2,13, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf13.K-1), np.zeros(crf13.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc13 = 0\n",
    "\n",
    "acc13_t1 = np.zeros(17)\n",
    "acc13_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc13_t1[n] = 1 - hamming(crf13.MAP(X_ts13[n]), y_ts13[n])\n",
    "    acc13_u[n] = 1 - hamming(crf_u13.MAP(X_ts13[n]), y_ts13[n])\n",
    "print('Initial accuracy score Binary: ',100* acc13_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc13_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc13_u[acc13_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr13.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr13.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr13[min_batch[k:k+batch_size]],y_tr13[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr13.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf13.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf13.W[1:] = crf13.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc13_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc13_test[n] = 1 - hamming(crf13.MAP(X_ts13[n]), y_ts13[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc13_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc13 < acc13_test.mean():\n",
    "                best_acc13 = acc13_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc13_test[acc13_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 14\n",
    "\n",
    "X_tr14, y_tr14 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data14['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data14['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data14['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data14['label_tr'][0][k][t,0]\n",
    "    X_tr14.append(feat)\n",
    "    y_tr14.append(lab)\n",
    "    \n",
    "X_tr14 = np.asarray(X_tr14, dtype='object')\n",
    "y_tr14 = np.asarray(y_tr14, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts14, y_ts14 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data14['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data14['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data14['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data14['label_te'][0][k][t,0]\n",
    "    X_ts14.append(feat)\n",
    "    y_ts14.append(lab)\n",
    "    \n",
    "X_ts14 = np.asarray(X_ts14, dtype='object')\n",
    "y_ts14 = np.asarray(y_ts14, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr14[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr14[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts14[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n14, y_n14 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr14[k].shape[0]):\n",
    "        X_n14[l] = X_tr14[k][j]\n",
    "        y_n14[l][y_tr14[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 14\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.15)(out1)\n",
    "out1 = Dense(9, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model14 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model14.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 519 samples, validate on 28 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 1.8796 - acc: 0.3507 - val_loss: 1.4164 - val_acc: 0.5000\n",
      "Epoch 2/15\n",
      "0s - loss: 1.5005 - acc: 0.5202 - val_loss: 1.1665 - val_acc: 0.7143\n",
      "Epoch 3/15\n",
      "0s - loss: 1.2478 - acc: 0.5761 - val_loss: 0.9721 - val_acc: 0.6071\n",
      "Epoch 4/15\n",
      "0s - loss: 0.9833 - acc: 0.7013 - val_loss: 0.9844 - val_acc: 0.6786\n",
      "Epoch 5/15\n",
      "0s - loss: 0.8342 - acc: 0.7881 - val_loss: 0.8006 - val_acc: 0.7143\n",
      "Epoch 6/15\n",
      "0s - loss: 0.6924 - acc: 0.7938 - val_loss: 0.7636 - val_acc: 0.7857\n",
      "Epoch 7/15\n",
      "0s - loss: 0.5995 - acc: 0.8150 - val_loss: 0.7314 - val_acc: 0.7857\n",
      "Epoch 8/15\n",
      "0s - loss: 0.5575 - acc: 0.8401 - val_loss: 0.7293 - val_acc: 0.7500\n",
      "Epoch 9/15\n",
      "0s - loss: 0.5016 - acc: 0.8459 - val_loss: 0.7681 - val_acc: 0.7500\n",
      "Epoch 10/15\n",
      "0s - loss: 0.4837 - acc: 0.8709 - val_loss: 0.7424 - val_acc: 0.7500\n",
      "Epoch 11/15\n",
      "0s - loss: 0.4440 - acc: 0.8844 - val_loss: 0.7816 - val_acc: 0.7857\n",
      "Epoch 12/15\n",
      "0s - loss: 0.4613 - acc: 0.8902 - val_loss: 0.9298 - val_acc: 0.7500\n",
      "Epoch 13/15\n",
      "0s - loss: 0.4111 - acc: 0.8844 - val_loss: 0.9322 - val_acc: 0.7143\n",
      "Epoch 14/15\n",
      "0s - loss: 0.4035 - acc: 0.8728 - val_loss: 0.7386 - val_acc: 0.8214\n",
      "Epoch 15/15\n",
      "0s - loss: 0.3993 - acc: 0.9056 - val_loss: 0.7833 - val_acc: 0.8214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62851dcda0>"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model14.fit(X_n14,y_n14,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model14.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.15)(out1)\n",
    "out1 = Dense(9, activation='linear', bias=False,\n",
    "            weights= unary_model14.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model14b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model14b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func14(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model14b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  70.6027385303 %.\n",
      "Accuracy score Unary only:  79.6715793024 %.\n",
      "Zero-one-loss Unary:  0.0 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  70.4583824602 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  71.2822079253 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  72.4427739653 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  73.0243798625 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  74.1084673437 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  74.2514056784 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  75.9292768269 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  75.9362348863 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  77.465646651 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  77.2303525334 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  77.3221746281 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  78.1625107625 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  78.3059827855 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  78.9145020553 %.\n",
      "Zero-one-loss:  11.7647058824 %\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  78.6792079376 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  78.2133694283 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  77.9332573835 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  77.9332573835 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  77.9332573835 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  77.9332573835 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  77.8352181678 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  77.5597518837 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  78.8669414262 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  78.2647005299 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  78.3823475887 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  78.3823475887 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  78.1651530185 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  77.4592706656 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  77.4592706656 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  77.2035161899 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  77.2035161899 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  77.2035161899 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  76.6881100274 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  76.6881100274 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  77.1783061059 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  77.1381567128 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  76.9028625951 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  76.9028625951 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 14\n",
    "\n",
    "\n",
    "crf14 = CRF(feat_func14,1+9**2,9, 0, 'B')\n",
    "crf_u14 = CRF(feat_func14,1+9**2,9, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf14.K-1), np.zeros(crf14.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc14 = 0\n",
    "\n",
    "acc14_t1 = np.zeros(17)\n",
    "acc14_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc14_t1[n] = 1 - hamming(crf14.MAP(X_ts14[n]), y_ts14[n])\n",
    "    acc14_u[n] = 1 - hamming(crf_u14.MAP(X_ts14[n]), y_ts14[n])\n",
    "print('Initial accuracy score Binary: ',100* acc14_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc14_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc14_u[acc14_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr14.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr14.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr14[min_batch[k:k+batch_size]],y_tr14[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr14.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf14.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf14.W[1:] = crf14.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc14_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc14_test[n] = 1 - hamming(crf14.MAP(X_ts14[n]), y_ts14[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc14_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc14 < acc14_test.mean():\n",
    "                best_acc14 = acc14_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc14_test[acc14_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 15\n",
    "\n",
    "X_tr15, y_tr15 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data15['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data15['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data15['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data15['label_tr'][0][k][t,0]\n",
    "    X_tr15.append(feat)\n",
    "    y_tr15.append(lab)\n",
    "    \n",
    "X_tr15 = np.asarray(X_tr15, dtype='object')\n",
    "y_tr15 = np.asarray(y_tr15, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts15, y_ts15 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data15['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data15['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data15['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data15['label_te'][0][k][t,0]\n",
    "    X_ts15.append(feat)\n",
    "    y_ts15.append(lab)\n",
    "    \n",
    "X_ts15 = np.asarray(X_ts15, dtype='object')\n",
    "y_ts15 = np.asarray(y_ts15, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr15[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr15[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts15[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n15, y_n15 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr15[k].shape[0]):\n",
    "        X_n15[l] = X_tr15[k][j]\n",
    "        y_n15[l][y_tr15[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 15\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.35)(out1)\n",
    "out1 = Dense(9, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model15 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model15.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 707 samples, validate on 38 samples\n",
      "Epoch 1/15\n",
      "0s - loss: 1.8414 - acc: 0.3352 - val_loss: 1.5960 - val_acc: 0.5000\n",
      "Epoch 2/15\n",
      "0s - loss: 1.1888 - acc: 0.6478 - val_loss: 1.4013 - val_acc: 0.5526\n",
      "Epoch 3/15\n",
      "0s - loss: 0.8557 - acc: 0.7553 - val_loss: 0.9763 - val_acc: 0.6316\n",
      "Epoch 4/15\n",
      "0s - loss: 0.6669 - acc: 0.8020 - val_loss: 0.9042 - val_acc: 0.6579\n",
      "Epoch 5/15\n",
      "0s - loss: 0.5936 - acc: 0.8416 - val_loss: 0.8835 - val_acc: 0.6579\n",
      "Epoch 6/15\n",
      "0s - loss: 0.5175 - acc: 0.8444 - val_loss: 0.9500 - val_acc: 0.6579\n",
      "Epoch 7/15\n",
      "0s - loss: 0.4869 - acc: 0.8769 - val_loss: 0.9673 - val_acc: 0.6842\n",
      "Epoch 8/15\n",
      "0s - loss: 0.4761 - acc: 0.8755 - val_loss: 0.7327 - val_acc: 0.7632\n",
      "Epoch 9/15\n",
      "0s - loss: 0.4292 - acc: 0.8854 - val_loss: 0.8557 - val_acc: 0.7368\n",
      "Epoch 10/15\n",
      "0s - loss: 0.4198 - acc: 0.8868 - val_loss: 0.8126 - val_acc: 0.7632\n",
      "Epoch 11/15\n",
      "0s - loss: 0.4152 - acc: 0.8911 - val_loss: 0.7538 - val_acc: 0.7632\n",
      "Epoch 12/15\n",
      "0s - loss: 0.3821 - acc: 0.9066 - val_loss: 0.8334 - val_acc: 0.7632\n",
      "Epoch 13/15\n",
      "0s - loss: 0.3594 - acc: 0.9010 - val_loss: 0.7103 - val_acc: 0.7895\n",
      "Epoch 14/15\n",
      "0s - loss: 0.3477 - acc: 0.9165 - val_loss: 0.7864 - val_acc: 0.7105\n",
      "Epoch 15/15\n",
      "0s - loss: 0.3546 - acc: 0.9095 - val_loss: 0.7330 - val_acc: 0.7895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62844c11d0>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model15.fit(X_n15,y_n15,batch_size=128,nb_epoch=15,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model15.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.35)(out1)\n",
    "out1 = Dense(9, activation='linear', bias=False,\n",
    "            weights= unary_model15.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model15b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model15b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func15(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model15b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  69.4455978133 %.\n",
      "Accuracy score Unary only:  75.2605210397 %.\n",
      "Zero-one-loss Unary:  0.0 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  70.2524007535 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  71.7300842007 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  74.307650664 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  75.2091603692 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  76.3968472043 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  77.351174407 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  77.7245759415 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  77.4335673605 %.\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  78.6724149287 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  79.2933299614 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  80.0459726675 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  80.7643554669 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  80.7643554669 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  80.0001055809 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  79.7822406572 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  79.6393701061 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  78.9473285837 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  79.0562610455 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  79.0562610455 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  78.9672423872 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  78.9672423872 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  78.8602905156 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  78.9672423872 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  78.9672423872 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  79.2511658199 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  79.2511658199 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  79.4864599376 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  79.8875294563 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  80.10539438 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  80.10539438 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  81.0287113855 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  81.3914177329 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  82.8075397373 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  82.8075397373 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  82.8075397373 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  82.5134220902 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  82.2193044431 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  82.2193044431 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  82.1123525715 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  82.0619857017 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  81.95503383 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  82.1280442107 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  82.1280442107 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  81.8339265636 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  82.1280442107 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  82.1280442107 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  82.1280442107 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  82.1280442107 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  81.7358873479 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  81.2652991126 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  81.7358873479 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  81.9711814656 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  81.9711814656 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 14\n",
    "\n",
    "\n",
    "crf15 = CRF(feat_func15,1+9**2,9, 0, 'B')\n",
    "crf_u15 = CRF(feat_func15,1+9**2,9, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf15.K-1), np.zeros(crf15.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc15 = 0\n",
    "\n",
    "acc15_t1 = np.zeros(17)\n",
    "acc15_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc15_t1[n] = 1 - hamming(crf15.MAP(X_ts15[n]), y_ts15[n])\n",
    "    acc15_u[n] = 1 - hamming(crf_u15.MAP(X_ts15[n]), y_ts15[n])\n",
    "print('Initial accuracy score Binary: ',100* acc15_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc15_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc15_u[acc14_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr15.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr15.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr15[min_batch[k:k+batch_size]],y_tr15[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr14.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf15.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf15.W[1:] = crf15.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc15_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc15_test[n] = 1 - hamming(crf15.MAP(X_ts15[n]), y_ts15[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc15_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc15 < acc15_test.mean():\n",
    "                best_acc15 = acc15_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc15_test[acc15_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 16\n",
    "\n",
    "X_tr16, y_tr16 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data16['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data16['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data16['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data16['label_tr'][0][k][t,0]\n",
    "    X_tr16.append(feat)\n",
    "    y_tr16.append(lab)\n",
    "    \n",
    "X_tr16 = np.asarray(X_tr16, dtype='object')\n",
    "y_tr16 = np.asarray(y_tr16, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts16, y_ts16 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data16['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data16['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data16['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data16['label_te'][0][k][t,0]\n",
    "    X_ts16.append(feat)\n",
    "    y_ts16.append(lab)\n",
    "    \n",
    "X_ts16 = np.asarray(X_ts16, dtype='object')\n",
    "y_ts16 = np.asarray(y_ts16, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr16[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr16[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts16[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n16, y_n16 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr16[k].shape[0]):\n",
    "        X_n16[l] = X_tr16[k][j]\n",
    "        y_n16[l][y_tr16[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 16\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.40)(out1)\n",
    "out1 = Dense(14, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model16 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model16.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 797 samples, validate on 42 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 0.3574 - acc: 0.8984 - val_loss: 0.7826 - val_acc: 0.7619\n",
      "Epoch 2/10\n",
      "0s - loss: 0.3420 - acc: 0.9134 - val_loss: 0.7573 - val_acc: 0.7143\n",
      "Epoch 3/10\n",
      "0s - loss: 0.3112 - acc: 0.9159 - val_loss: 0.7961 - val_acc: 0.7381\n",
      "Epoch 4/10\n",
      "0s - loss: 0.2792 - acc: 0.9297 - val_loss: 0.7625 - val_acc: 0.7381\n",
      "Epoch 5/10\n",
      "0s - loss: 0.2837 - acc: 0.9260 - val_loss: 0.8701 - val_acc: 0.7143\n",
      "Epoch 6/10\n",
      "0s - loss: 0.2428 - acc: 0.9423 - val_loss: 0.8138 - val_acc: 0.7857\n",
      "Epoch 7/10\n",
      "0s - loss: 0.2623 - acc: 0.9385 - val_loss: 0.7710 - val_acc: 0.7619\n",
      "Epoch 8/10\n",
      "0s - loss: 0.2275 - acc: 0.9511 - val_loss: 0.9564 - val_acc: 0.7143\n",
      "Epoch 9/10\n",
      "0s - loss: 0.2098 - acc: 0.9460 - val_loss: 0.9023 - val_acc: 0.7619\n",
      "Epoch 10/10\n",
      "0s - loss: 0.2046 - acc: 0.9598 - val_loss: 0.7823 - val_acc: 0.7619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6283a74898>"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model16.fit(X_n16,y_n16,batch_size=128,nb_epoch=10,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model16.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.40)(out1)\n",
    "out1 = Dense(14, activation='linear', bias=False,\n",
    "            weights= unary_model16.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model16b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model16b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func16(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model16b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  65.4286784413 %.\n",
      "Accuracy score Unary only:  68.1657007768 %.\n",
      "Zero-one-loss Unary:  0.0 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  65.7158686593 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  67.4601762245 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  68.3489180182 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  69.0193060706 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  69.7878531848 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  70.1498467919 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  69.672442949 %.\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  71.9618824599 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  72.6245305742 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  72.7907486955 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  73.0548778765 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  72.907819053 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  72.0038210902 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  71.7356924484 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  73.581058125 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  73.581058125 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  73.2767984901 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  72.6248753167 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  72.6248753167 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  72.6248753167 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  72.726295195 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  72.726295195 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  73.1674716656 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  73.1674716656 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  73.1674716656 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  73.1674716656 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  73.1674716656 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  72.6845198642 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  72.8873596208 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  73.0381891834 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  73.0381891834 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  72.8353494268 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  72.5336903016 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  72.5336903016 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  72.6884890632 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  72.9901481884 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  72.9901481884 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  72.9901481884 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  71.4064377812 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  71.4064377812 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  71.5612365428 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  71.5612365428 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  71.5612365428 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  71.5612365428 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  71.6477417331 %.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-607-ff0f77b349c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0macc16_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhamming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ts16\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts16\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n\u001b[1;32m     48\u001b[0m                   100* acc16_test.mean(), '%.')\n",
      "\u001b[0;32m<ipython-input-380-6f7b0157f09d>\u001b[0m in \u001b[0;36mMAP\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpsi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-380-6f7b0157f09d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpsi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-606-232a65fb64f6>\u001b[0m in \u001b[0;36mfeat_func16\u001b[0;34m(i, j, x, t, N, L)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#unary_chi = np.zeros(N*L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#unary_chi[i*N:(i+1)*N] = x[t]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0munary_chi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munary_model16b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1197\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;31m# do not slice the training phase flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/james/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mslice_X\u001b[0;34m(X, start, stop)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;31m# hdf5 datasets only support list objects as indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 16\n",
    "\n",
    "\n",
    "crf16 = CRF(feat_func16,1+14**2,14, 0, 'B')\n",
    "crf_u16 = CRF(feat_func16,1+14**2,14, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf16.K-1), np.zeros(crf16.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc16 = 0\n",
    "\n",
    "acc16_t1 = np.zeros(17)\n",
    "acc16_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc16_t1[n] = 1 - hamming(crf16.MAP(X_ts16[n]), y_ts16[n])\n",
    "    acc16_u[n] = 1 - hamming(crf_u16.MAP(X_ts16[n]), y_ts16[n])\n",
    "print('Initial accuracy score Binary: ',100* acc16_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc16_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc16_u[acc16_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr16.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr16.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr16[min_batch[k:k+batch_size]],y_tr16[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr16.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf16.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf16.W[1:] = crf16.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc16_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc16_test[n] = 1 - hamming(crf16.MAP(X_ts16[n]), y_ts16[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc16_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc16 < acc16_test.mean():\n",
    "                best_acc16 = acc16_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc16_test[acc16_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 17\n",
    "\n",
    "X_tr17, y_tr17 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data17['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data17['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data17['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data17['label_tr'][0][k][t,0]\n",
    "    X_tr17.append(feat)\n",
    "    y_tr17.append(lab)\n",
    "    \n",
    "X_tr17 = np.asarray(X_tr17, dtype='object')\n",
    "y_tr17 = np.asarray(y_tr17, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts17, y_ts17 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data17['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data17['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data17['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data17['label_te'][0][k][t,0]\n",
    "    X_ts17.append(feat)\n",
    "    y_ts17.append(lab)\n",
    "    \n",
    "X_ts17 = np.asarray(X_ts17, dtype='object')\n",
    "y_ts17 = np.asarray(y_ts17, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr17[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr17[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts17[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n17, y_n17 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr17[k].shape[0]):\n",
    "        X_n17[l] = X_tr17[k][j]\n",
    "        y_n17[l][y_tr17[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 17\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(9, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model17 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model17.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 880 samples, validate on 47 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 0.3407 - acc: 0.9148 - val_loss: 0.7082 - val_acc: 0.7447\n",
      "Epoch 2/10\n",
      "0s - loss: 0.3209 - acc: 0.9250 - val_loss: 0.7192 - val_acc: 0.7447\n",
      "Epoch 3/10\n",
      "0s - loss: 0.3184 - acc: 0.9307 - val_loss: 0.6746 - val_acc: 0.7660\n",
      "Epoch 4/10\n",
      "0s - loss: 0.3131 - acc: 0.9318 - val_loss: 0.7668 - val_acc: 0.7447\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3206 - acc: 0.9330 - val_loss: 0.6985 - val_acc: 0.7447\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3058 - acc: 0.9227 - val_loss: 0.7776 - val_acc: 0.7447\n",
      "Epoch 7/10\n",
      "0s - loss: 0.2978 - acc: 0.9386 - val_loss: 0.6820 - val_acc: 0.7660\n",
      "Epoch 8/10\n",
      "0s - loss: 0.2892 - acc: 0.9307 - val_loss: 0.8635 - val_acc: 0.7447\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3118 - acc: 0.9250 - val_loss: 0.7591 - val_acc: 0.7447\n",
      "Epoch 10/10\n",
      "0s - loss: 0.2897 - acc: 0.9330 - val_loss: 0.7198 - val_acc: 0.7660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f628358b128>"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model17.fit(X_n17,y_n17,batch_size=128,nb_epoch=10,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model17.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(9, activation='linear', bias=False,\n",
    "            weights= unary_model17.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model17b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model17b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func17(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model17b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  55.2974393272 %.\n",
      "Accuracy score Unary only:  65.7816537461 %.\n",
      "Zero-one-loss Unary:  0.0 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  59.2798587809 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  62.7439420119 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  63.5492089873 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  64.7568941809 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  65.2420180161 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  65.9020901217 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  66.2884966451 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  66.9101886267 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  66.9101886267 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  67.2331597732 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  67.71597944 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  67.208806874 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  67.208806874 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  67.208806874 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  67.0751170345 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  66.1826087697 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  67.4850740111 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  67.0325853233 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  67.461937392 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  67.2836842726 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  66.9136544459 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  67.6247080981 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  67.7647641205 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  67.7647641205 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  67.7647641205 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  67.9155936831 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  67.9155936831 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  67.9155936831 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  67.9155936831 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  67.9155936831 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  67.9155936831 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  68.6677348944 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  68.1329755361 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  68.2838050987 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  67.3034129418 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  68.2838050987 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  68.2838050987 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  68.2838050987 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  68.2838050987 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  68.2838050987 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  68.0035341701 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  68.0035341701 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  68.0035341701 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  68.1470061931 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  68.2870622155 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  68.2870622155 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  68.6570920421 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  68.6570920421 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  68.6570920421 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  68.9838894278 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  68.9838894278 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  68.9838894278 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  68.3768211136 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  68.1985679942 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  68.5253653798 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  70.3376054273 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  70.3376054273 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  70.3376054273 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  70.3376054273 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  70.6178763559 %.\n",
      "Zero-one-loss:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 17\n",
    "\n",
    "\n",
    "crf17 = CRF(feat_func17,1+9**2,9, 0, 'B')\n",
    "crf_u17 = CRF(feat_func17,1+9**2,9, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf17.K-1), np.zeros(crf17.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc17 = 0\n",
    "\n",
    "acc17_t1 = np.zeros(17)\n",
    "acc17_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc17_t1[n] = 1 - hamming(crf17.MAP(X_ts17[n]), y_ts17[n])\n",
    "    acc17_u[n] = 1 - hamming(crf_u17.MAP(X_ts17[n]), y_ts17[n])\n",
    "print('Initial accuracy score Binary: ',100* acc17_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc17_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc17_u[acc17_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr17.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr17.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr17[min_batch[k:k+batch_size]],y_tr17[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr17.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf17.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf17.W[1:] = crf17.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc17_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc17_test[n] = 1 - hamming(crf17.MAP(X_ts17[n]), y_ts17[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc17_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc17 < acc17_test.mean():\n",
    "                best_acc17 = acc17_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc17_test[acc17_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 18\n",
    "\n",
    "X_tr18, y_tr18 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data18['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data18['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data18['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data18['label_tr'][0][k][t,0]\n",
    "    X_tr18.append(feat)\n",
    "    y_tr18.append(lab)\n",
    "    \n",
    "X_tr18 = np.asarray(X_tr18, dtype='object')\n",
    "y_tr18 = np.asarray(y_tr18, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts18, y_ts18 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data18['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data18['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data18['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data18['label_te'][0][k][t,0]\n",
    "    X_ts18.append(feat)\n",
    "    y_ts18.append(lab)\n",
    "    \n",
    "X_ts18 = np.asarray(X_ts18, dtype='object')\n",
    "y_ts18 = np.asarray(y_ts18, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr18[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr18[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts18[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n18, y_n18 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr18[k].shape[0]):\n",
    "        X_n18[l] = X_tr18[k][j]\n",
    "        y_n18[l][y_tr18[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 18\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(11, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model18 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model18.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 561 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 0.1674 - acc: 0.9715 - val_loss: 1.0387 - val_acc: 0.7333\n",
      "Epoch 2/10\n",
      "0s - loss: 0.1734 - acc: 0.9697 - val_loss: 1.0699 - val_acc: 0.7667\n",
      "Epoch 3/10\n",
      "0s - loss: 0.1721 - acc: 0.9697 - val_loss: 0.9753 - val_acc: 0.7667\n",
      "Epoch 4/10\n",
      "0s - loss: 0.1857 - acc: 0.9661 - val_loss: 1.2478 - val_acc: 0.7333\n",
      "Epoch 5/10\n",
      "0s - loss: 0.1677 - acc: 0.9697 - val_loss: 1.0765 - val_acc: 0.7333\n",
      "Epoch 6/10\n",
      "0s - loss: 0.1686 - acc: 0.9679 - val_loss: 1.0514 - val_acc: 0.7333\n",
      "Epoch 7/10\n",
      "0s - loss: 0.1724 - acc: 0.9697 - val_loss: 1.0847 - val_acc: 0.7333\n",
      "Epoch 8/10\n",
      "0s - loss: 0.1666 - acc: 0.9679 - val_loss: 1.0502 - val_acc: 0.7667\n",
      "Epoch 9/10\n",
      "0s - loss: 0.1701 - acc: 0.9697 - val_loss: 1.1422 - val_acc: 0.7667\n",
      "Epoch 10/10\n",
      "0s - loss: 0.1732 - acc: 0.9679 - val_loss: 1.0268 - val_acc: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6283017c88>"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model18.fit(X_n18,y_n18,batch_size=128,nb_epoch=10,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model18.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(11, activation='linear', bias=False,\n",
    "            weights= unary_model18.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model18b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model18b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func18(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model18b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  69.3901327097 %.\n",
      "Accuracy score Unary only:  74.0365061781 %.\n",
      "Zero-one-loss Unary:  0.0 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  71.9122395916 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  71.5662188304 %.\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  72.0564149088 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  72.7484564313 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  72.4024356701 %.\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  71.814200376 %.\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  71.814200376 %.\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  72.32361983 %.\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  72.32361983 %.\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  72.32361983 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  72.32361983 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  73.6884794994 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  74.5267858364 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  74.1807650752 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  74.8343598464 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  75.8531987545 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  75.5071779933 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  75.5071779933 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  75.5071779933 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  75.5071779933 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  76.0954132874 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  76.0954132874 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  76.0954132874 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  75.7493925261 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  75.7493925261 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  76.9258631144 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  76.2722683431 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  76.5990657287 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  76.5990657287 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  76.343311253 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  76.343311253 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  76.343311253 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  75.6512697306 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  75.2264331292 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  75.2264331292 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 18\n",
    "\n",
    "\n",
    "crf18 = CRF(feat_func18,1+11**2,11, 0, 'B')\n",
    "crf_u18 = CRF(feat_func18,1+11**2,11, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf18.K-1), np.zeros(crf18.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc18 = 0\n",
    "\n",
    "acc18_t1 = np.zeros(17)\n",
    "acc18_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc18_t1[n] = 1 - hamming(crf18.MAP(X_ts18[n]), y_ts18[n])\n",
    "    acc18_u[n] = 1 - hamming(crf_u18.MAP(X_ts18[n]), y_ts18[n])\n",
    "print('Initial accuracy score Binary: ',100* acc18_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc18_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc18_u[acc18_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr18.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr18.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr18[min_batch[k:k+batch_size]],y_tr18[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr18.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf18.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf18.W[1:] = crf18.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc18_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc18_test[n] = 1 - hamming(crf18.MAP(X_ts18[n]), y_ts18[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc18_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc18 < acc18_test.mean():\n",
    "                best_acc18 = acc18_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc18_test[acc18_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 19\n",
    "\n",
    "X_tr19, y_tr19 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data19['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data19['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data19['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data19['label_tr'][0][k][t,0]\n",
    "    X_tr19.append(feat)\n",
    "    y_tr19.append(lab)\n",
    "    \n",
    "X_tr19 = np.asarray(X_tr19, dtype='object')\n",
    "y_tr19 = np.asarray(y_tr19, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts19, y_ts19 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data19['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data19['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data19['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data19['label_te'][0][k][t,0]\n",
    "    X_ts19.append(feat)\n",
    "    y_ts19.append(lab)\n",
    "    \n",
    "X_ts19 = np.asarray(X_ts19, dtype='object')\n",
    "y_ts19 = np.asarray(y_ts19, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr19[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr19[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts19[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n19, y_n19 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr19[k].shape[0]):\n",
    "        X_n19[l] = X_tr19[k][j]\n",
    "        y_n19[l][y_tr19[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 19\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu')(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(10, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model19 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model19.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 917 samples, validate on 49 samples\n",
      "Epoch 1/12\n",
      "0s - loss: 1.8860 - acc: 0.3871 - val_loss: 1.6566 - val_acc: 0.5102\n",
      "Epoch 2/12\n",
      "0s - loss: 1.4009 - acc: 0.5703 - val_loss: 1.2791 - val_acc: 0.5714\n",
      "Epoch 3/12\n",
      "0s - loss: 1.0432 - acc: 0.6848 - val_loss: 0.9339 - val_acc: 0.6735\n",
      "Epoch 4/12\n",
      "0s - loss: 0.8388 - acc: 0.7503 - val_loss: 0.6305 - val_acc: 0.7959\n",
      "Epoch 5/12\n",
      "0s - loss: 0.6999 - acc: 0.7841 - val_loss: 0.7319 - val_acc: 0.7347\n",
      "Epoch 6/12\n",
      "0s - loss: 0.6064 - acc: 0.8201 - val_loss: 0.4901 - val_acc: 0.8163\n",
      "Epoch 7/12\n",
      "0s - loss: 0.5481 - acc: 0.8353 - val_loss: 0.6108 - val_acc: 0.8163\n",
      "Epoch 8/12\n",
      "0s - loss: 0.4902 - acc: 0.8462 - val_loss: 0.5369 - val_acc: 0.8163\n",
      "Epoch 9/12\n",
      "0s - loss: 0.4419 - acc: 0.8811 - val_loss: 0.5942 - val_acc: 0.7959\n",
      "Epoch 10/12\n",
      "0s - loss: 0.4372 - acc: 0.8735 - val_loss: 0.5620 - val_acc: 0.7959\n",
      "Epoch 11/12\n",
      "0s - loss: 0.4207 - acc: 0.8757 - val_loss: 0.5292 - val_acc: 0.8367\n",
      "Epoch 12/12\n",
      "0s - loss: 0.3766 - acc: 0.8953 - val_loss: 0.5242 - val_acc: 0.7959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62826fee80>"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model19.fit(X_n19,y_n19,batch_size=128,nb_epoch=12,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(256, activation='relu',\n",
    "            weights= unary_model19.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.1)(out1)\n",
    "out1 = Dense(10, activation='linear', bias=False,\n",
    "            weights= unary_model19.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model19b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model19b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func19(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model19b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  74.9779499692 %.\n",
      "Accuracy score Unary only:  78.0944515209 %.\n",
      "Zero-one-loss Unary:  5.88235294118 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  75.3768271871 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  75.9671035254 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  78.5249693708 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  78.393077082 %.\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  79.2693855001 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  82.0772453525 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  81.6882476482 %.\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  82.4264252722 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  82.4533128409 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  82.4533128409 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  82.2635595202 %.\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  82.5221826143 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  81.7394695291 %.\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  81.6218224702 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  81.3721735391 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  81.3672507871 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  81.4872988063 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  81.4872988063 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  82.0598355133 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  82.4655150265 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  82.4655150265 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  82.5831620853 %.\n",
      "Zero-one-loss:  23.5294117647 %\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  82.5831620853 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  82.5831620853 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  83.2385821481 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  83.2385821481 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  83.2385821481 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  83.2385821481 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  83.4944456875 %.\n",
      "Zero-one-loss:  23.5294117647 %\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  83.7345417259 %.\n",
      "Zero-one-loss:  23.5294117647 %\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  83.4944456875 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  83.3263784606 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  83.5327768094 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  83.5327768094 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  83.5327768094 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  83.5327768094 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  83.5327768094 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Zero-one-loss:  17.6470588235 %\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  83.9792711967 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  83.1949574712 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 19\n",
    "\n",
    "\n",
    "crf19 = CRF(feat_func19,1+10**2,10, 0, 'B')\n",
    "crf_u19 = CRF(feat_func19,1+10**2,10, 1e-7, 'U')\n",
    "alpha = 0.099\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf19.K-1), np.zeros(crf19.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc19 = 0\n",
    "\n",
    "acc19_t1 = np.zeros(17)\n",
    "acc19_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc19_t1[n] = 1 - hamming(crf19.MAP(X_ts19[n]), y_ts19[n])\n",
    "    acc19_u[n] = 1 - hamming(crf_u19.MAP(X_ts19[n]), y_ts19[n])\n",
    "print('Initial accuracy score Binary: ',100* acc19_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc19_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc19_u[acc19_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr19.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr19.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr19[min_batch[k:k+batch_size]],y_tr19[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr19.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf19.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf19.W[1:] = crf19.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc19_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc19_test[n] = 1 - hamming(crf19.MAP(X_ts19[n]), y_ts19[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc19_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc19 < acc19_test.mean():\n",
    "                best_acc19 = acc19_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc19_test[acc19_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction Data set 20\n",
    "\n",
    "X_tr20, y_tr20 = [], []\n",
    "\n",
    "for k in range(30):\n",
    "    \n",
    "    T = data20['BOF_tr_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data20['BOF_tr_M'][0][k][t,:]\n",
    "        feat[t,30:] = data20['BOF_tr_K'][0][k][t,:]\n",
    "        lab[t] = data20['label_tr'][0][k][t,0]\n",
    "    X_tr20.append(feat)\n",
    "    y_tr20.append(lab)\n",
    "    \n",
    "X_tr20 = np.asarray(X_tr20, dtype='object')\n",
    "y_tr20 = np.asarray(y_tr20, dtype='object')\n",
    "\n",
    "\n",
    "# Data Extraction Testing\n",
    "\n",
    "X_ts20, y_ts20 = [], []\n",
    "\n",
    "for k in range(17):\n",
    "    \n",
    "    T = data20['BOF_te_M'][0][k].shape[0]\n",
    "    feat = np.zeros((T,60))\n",
    "    lab = np.zeros(T, dtype='i4')\n",
    "   \n",
    "    for t in range(T):\n",
    "        feat[t,:30] = data20['BOF_te_M'][0][k][t,:]\n",
    "        feat[t,30:] = data20['BOF_te_K'][0][k][t,:]\n",
    "        lab[t] = data20['label_te'][0][k][t,0]\n",
    "    X_ts20.append(feat)\n",
    "    y_ts20.append(lab)\n",
    "    \n",
    "X_ts20 = np.asarray(X_ts20, dtype='object')\n",
    "y_ts20 = np.asarray(y_ts20, dtype='object')\n",
    "\n",
    "num_node = 0\n",
    "for k in range(30):\n",
    "    for j in range(y_tr20[k].shape[0]):\n",
    "        num_node += 1\n",
    "        \n",
    "max_l = 0 \n",
    "for k in range(30):\n",
    "     max_l = max(max_l, y_tr20[k].max())\n",
    "for k in range(17):\n",
    "    max_l = max(max_l, y_ts20[k].max())\n",
    "print(max_l)\n",
    "\n",
    "\n",
    "X_n20, y_n20 = np.zeros((num_node,60)), np.zeros((num_node,max_l+1), dtype='i4')\n",
    "\n",
    "l = 0\n",
    "for k in range(30):\n",
    "    for j in range(X_tr20[k].shape[0]):\n",
    "        X_n20[l] = X_tr20[k][j]\n",
    "        y_n20[l][y_tr20[k][j]] = 1\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unary Neural Net dataset 20\n",
    "inp = Input((60,), batch_shape=(128,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu')(inp)\n",
    "out1 = Dropout(0.35)(out1)\n",
    "out1 = Dense(10, activation='softmax', bias=False)(out1) \n",
    "\n",
    "unary_model20 = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.009,epsilon=1e-8)\n",
    "\n",
    "unary_model20.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 477 samples, validate on 26 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 1.9421 - acc: 0.3962 - val_loss: 2.1142 - val_acc: 0.4231\n",
      "Epoch 2/10\n",
      "0s - loss: 1.4534 - acc: 0.5514 - val_loss: 1.7871 - val_acc: 0.4615\n",
      "Epoch 3/10\n",
      "0s - loss: 1.1779 - acc: 0.6709 - val_loss: 1.8439 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "0s - loss: 1.0290 - acc: 0.6897 - val_loss: 1.6332 - val_acc: 0.6154\n",
      "Epoch 5/10\n",
      "0s - loss: 0.9016 - acc: 0.7505 - val_loss: 2.0020 - val_acc: 0.5385\n",
      "Epoch 6/10\n",
      "0s - loss: 0.8354 - acc: 0.7841 - val_loss: 2.0479 - val_acc: 0.5769\n",
      "Epoch 7/10\n",
      "0s - loss: 0.7604 - acc: 0.7966 - val_loss: 1.8765 - val_acc: 0.6154\n",
      "Epoch 8/10\n",
      "0s - loss: 0.6991 - acc: 0.7925 - val_loss: 2.1036 - val_acc: 0.6154\n",
      "Epoch 9/10\n",
      "0s - loss: 0.6699 - acc: 0.8260 - val_loss: 1.9409 - val_acc: 0.7308\n",
      "Epoch 10/10\n",
      "0s - loss: 0.6438 - acc: 0.8155 - val_loss: 1.9129 - val_acc: 0.6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62813e19e8>"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unary_model20.fit(X_n20,y_n20,batch_size=128,nb_epoch=10,validation_split=.05, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((60,), batch_shape=(1,60))\n",
    "\n",
    "out1 = Dense(512, activation='relu',\n",
    "            weights= unary_model20.layers[1].get_weights())(inp)\n",
    "out1 = Dropout(0.35)(out1)\n",
    "out1 = Dense(10, activation='linear', bias=False,\n",
    "            weights= unary_model20.layers[-1].get_weights())(out1) \n",
    "\n",
    "unary_model20b = Model(inp,out1)\n",
    "\n",
    "sgd = adam(0.007,epsilon=1e-7)\n",
    "\n",
    "unary_model20b.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def feat_func20(i,j,x,t,N,L):\n",
    "    \n",
    "    binary_chi = np.zeros(L**2)\n",
    "    #unary_chi = np.zeros(N*L)\n",
    "    #unary_chi[i*N:(i+1)*N] = x[t]\n",
    "    unary_chi = unary_model20b.predict(x[t].reshape((1,60)))[0,i]\n",
    "    \n",
    "    if t > 0:\n",
    "    \n",
    "        binary_chi[(L*i+j)] = 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    output = np.zeros(1 + L**2)\n",
    "    output[0] = unary_chi\n",
    "    output[1:] = binary_chi\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy score Binary:  55.7117504951 %.\n",
      "Accuracy score Unary only:  71.6397770731 %.\n",
      "Zero-one-loss Unary:  0.0 %\n",
      "Epoch/Iteration:  1 / 0 . Current Average Test Hamming Accuracy:  58.0265168323 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 2 . Current Average Test Hamming Accuracy:  67.8851617948 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  1 / 4 . Current Average Test Hamming Accuracy:  70.4309094556 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 6 . Current Average Test Hamming Accuracy:  73.1396945489 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  2 / 8 . Current Average Test Hamming Accuracy:  72.963637619 %.\n",
      "Epoch/Iteration:  2 / 10 . Current Average Test Hamming Accuracy:  74.1700667147 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 12 . Current Average Test Hamming Accuracy:  74.7411162367 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 14 . Current Average Test Hamming Accuracy:  75.0070566049 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  3 / 16 . Current Average Test Hamming Accuracy:  76.3589016908 %.\n",
      "Zero-one-loss:  5.88235294118 %\n",
      "Epoch/Iteration:  4 / 18 . Current Average Test Hamming Accuracy:  76.1948798146 %.\n",
      "Epoch/Iteration:  4 / 20 . Current Average Test Hamming Accuracy:  76.5323363074 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  4 / 22 . Current Average Test Hamming Accuracy:  76.48755984 %.\n",
      "Epoch/Iteration:  5 / 24 . Current Average Test Hamming Accuracy:  76.6734969117 %.\n",
      "Zero-one-loss:  0.0 %\n",
      "Epoch/Iteration:  5 / 26 . Current Average Test Hamming Accuracy:  75.8422454922 %.\n",
      "Epoch/Iteration:  5 / 28 . Current Average Test Hamming Accuracy:  75.3652979565 %.\n",
      "Epoch/Iteration:  6 / 30 . Current Average Test Hamming Accuracy:  74.7414120385 %.\n",
      "Epoch/Iteration:  6 / 32 . Current Average Test Hamming Accuracy:  74.4449060326 %.\n",
      "Epoch/Iteration:  6 / 34 . Current Average Test Hamming Accuracy:  73.3712846649 %.\n",
      "Epoch/Iteration:  7 / 36 . Current Average Test Hamming Accuracy:  70.4202634054 %.\n",
      "Epoch/Iteration:  7 / 38 . Current Average Test Hamming Accuracy:  70.6414930384 %.\n",
      "Epoch/Iteration:  7 / 40 . Current Average Test Hamming Accuracy:  69.9386664532 %.\n",
      "Epoch/Iteration:  8 / 42 . Current Average Test Hamming Accuracy:  69.1758868669 %.\n",
      "Epoch/Iteration:  8 / 44 . Current Average Test Hamming Accuracy:  69.1758868669 %.\n",
      "Epoch/Iteration:  8 / 46 . Current Average Test Hamming Accuracy:  69.1758868669 %.\n",
      "Epoch/Iteration:  9 / 48 . Current Average Test Hamming Accuracy:  68.6716851862 %.\n",
      "Epoch/Iteration:  9 / 50 . Current Average Test Hamming Accuracy:  68.6716851862 %.\n",
      "Epoch/Iteration:  9 / 52 . Current Average Test Hamming Accuracy:  68.2359553387 %.\n",
      "Epoch/Iteration:  10 / 54 . Current Average Test Hamming Accuracy:  67.8794490999 %.\n",
      "Epoch/Iteration:  10 / 56 . Current Average Test Hamming Accuracy:  67.8794490999 %.\n",
      "Epoch/Iteration:  10 / 58 . Current Average Test Hamming Accuracy:  67.8794490999 %.\n",
      "Epoch/Iteration:  11 / 60 . Current Average Test Hamming Accuracy:  67.8794490999 %.\n",
      "Epoch/Iteration:  11 / 62 . Current Average Test Hamming Accuracy:  67.4783795812 %.\n",
      "Epoch/Iteration:  11 / 64 . Current Average Test Hamming Accuracy:  67.4783795812 %.\n",
      "Epoch/Iteration:  12 / 66 . Current Average Test Hamming Accuracy:  67.4783795812 %.\n",
      "Epoch/Iteration:  12 / 68 . Current Average Test Hamming Accuracy:  67.1442065999 %.\n",
      "Epoch/Iteration:  12 / 70 . Current Average Test Hamming Accuracy:  67.1442065999 %.\n",
      "Epoch/Iteration:  13 / 72 . Current Average Test Hamming Accuracy:  67.1442065999 %.\n",
      "Epoch/Iteration:  13 / 74 . Current Average Test Hamming Accuracy:  68.6513300448 %.\n",
      "Epoch/Iteration:  13 / 76 . Current Average Test Hamming Accuracy:  68.6513300448 %.\n",
      "Epoch/Iteration:  14 / 78 . Current Average Test Hamming Accuracy:  68.6513300448 %.\n",
      "Epoch/Iteration:  14 / 80 . Current Average Test Hamming Accuracy:  68.6513300448 %.\n",
      "Epoch/Iteration:  14 / 82 . Current Average Test Hamming Accuracy:  68.8103125567 %.\n",
      "Epoch/Iteration:  15 / 84 . Current Average Test Hamming Accuracy:  68.8103125567 %.\n",
      "Epoch/Iteration:  15 / 86 . Current Average Test Hamming Accuracy:  68.1398210934 %.\n",
      "Epoch/Iteration:  15 / 88 . Current Average Test Hamming Accuracy:  67.6628735576 %.\n",
      "Epoch/Iteration:  16 / 90 . Current Average Test Hamming Accuracy:  67.6628735576 %.\n",
      "Epoch/Iteration:  16 / 92 . Current Average Test Hamming Accuracy:  66.6544701963 %.\n",
      "Epoch/Iteration:  16 / 94 . Current Average Test Hamming Accuracy:  66.6544701963 %.\n",
      "Epoch/Iteration:  17 / 96 . Current Average Test Hamming Accuracy:  66.6544701963 %.\n",
      "Epoch/Iteration:  17 / 98 . Current Average Test Hamming Accuracy:  66.6544701963 %.\n",
      "Epoch/Iteration:  17 / 100 . Current Average Test Hamming Accuracy:  65.9414577185 %.\n",
      "Epoch/Iteration:  18 / 102 . Current Average Test Hamming Accuracy:  65.7824752066 %.\n",
      "Epoch/Iteration:  18 / 104 . Current Average Test Hamming Accuracy:  64.9421390722 %.\n",
      "Epoch/Iteration:  18 / 106 . Current Average Test Hamming Accuracy:  64.9421390722 %.\n",
      "Epoch/Iteration:  19 / 108 . Current Average Test Hamming Accuracy:  64.9421390722 %.\n",
      "Epoch/Iteration:  19 / 110 . Current Average Test Hamming Accuracy:  65.7824752066 %.\n",
      "Epoch/Iteration:  19 / 112 . Current Average Test Hamming Accuracy:  65.7824752066 %.\n",
      "Epoch/Iteration:  20 / 114 . Current Average Test Hamming Accuracy:  66.4954876843 %.\n",
      "Epoch/Iteration:  20 / 116 . Current Average Test Hamming Accuracy:  66.6544701963 %.\n",
      "Epoch/Iteration:  20 / 118 . Current Average Test Hamming Accuracy:  66.6544701963 %.\n"
     ]
    }
   ],
   "source": [
    "# Adam stochastic mini-batch gradient descent on the (negative) pseudo-log-liklelihood.\n",
    "# Dataset 20\n",
    "\n",
    "\n",
    "crf20 = CRF(feat_func20,1+10**2,10, 0, 'B')\n",
    "crf_u20 = CRF(feat_func20,1+10**2,10, 1e-7, 'U')\n",
    "alpha = 0.11\n",
    "B1, B2 = 0.9, 0.999\n",
    "eps = 1e-7\n",
    "m, v = np.zeros(crf20.K-1), np.zeros(crf20.K-1)\n",
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "epoch = 1\n",
    "best_acc20 = 0\n",
    "\n",
    "acc20_t1 = np.zeros(17)\n",
    "acc20_u = np.zeros(17)\n",
    "for n in range(17):\n",
    "    acc20_t1[n] = 1 - hamming(crf20.MAP(X_ts20[n]), y_ts20[n])\n",
    "    acc20_u[n] = 1 - hamming(crf_u20.MAP(X_ts20[n]), y_ts20[n])\n",
    "print('Initial accuracy score Binary: ',100* acc20_t1.mean(), '%.')\n",
    "print('Accuracy score Unary only: ',100* acc20_u.mean(), '%.')\n",
    "print('Zero-one-loss Unary: ', 100*acc20_u[acc20_u==1].sum()/17, '%')\n",
    "\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "    min_batch = np.arange(X_tr20.shape[0])\n",
    "    np.random.shuffle(min_batch)\n",
    "    \n",
    "    for k in range(0, X_tr20.shape[0],batch_size):\n",
    "        \n",
    "        X_b, y_b = X_tr20[min_batch[k:k+batch_size]],y_tr20[min_batch[k:k+batch_size]]\n",
    "        t = (X_tr20.shape[0]//batch_size)*(epoch-1) + (k // batch_size) + 1\n",
    "        g = crf20.grad_pll(X_b, y_b)\n",
    "        m = B1 * m + (1-B1) * g\n",
    "        v = B2 * v + np.square(np.sqrt(1-B2) * g)\n",
    "        m_b = m / (1 - B1**t)\n",
    "        v_b = v / (1 - B2**t)\n",
    "        crf20.W[1:] = crf20.W[1:] - (alpha * m_b) / (np.sqrt(v_b) + eps)\n",
    "        \n",
    "        if (k // batch_size) % 2 == 0:\n",
    "            \n",
    "            acc20_test = np.zeros(17)\n",
    "            \n",
    "            for n in range(17):\n",
    "                acc20_test[n] = 1 - hamming(crf20.MAP(X_ts20[n]), y_ts20[n])\n",
    "            print('Epoch/Iteration: ', epoch, '/', t-1, '. Current Average Test Hamming Accuracy: ',\n",
    "                  100* acc20_test.mean(), '%.')\n",
    "            \n",
    "            if best_acc20 < acc20_test.mean():\n",
    "                best_acc20 = acc20_test.mean()\n",
    "                print('Zero-one-loss: ', 100*acc20_test[acc20_test==1].sum()/17, '%')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = [X_n, X_n2, X_n3, X_n4, X_n5, X_n6, X_n7, X_n8, X_n9, X_n10, X_n11,\n",
    "          X_n12, X_n13, X_n14, X_n15, X_n16, X_n17, X_n18, X_n19, X_n20]\n",
    "\n",
    "train_ye = [y_n, y_n2,y_n3,y_n4,y_n5,y_n6,y_n7,y_n8,y_n9,y_n10,y_n11,y_n12,y_n13,\n",
    "           y_n14,y_n15,y_n16,y_n17,y_n18,y_n19,y_n20]\n",
    "\n",
    "train_y = []\n",
    "\n",
    "for Y in train_ye:\n",
    "    \n",
    "    Y_n = np.zeros(Y.shape[0], dtype='i4')\n",
    "    for k in range(Y.shape[0]):\n",
    "        Y_n[k] = Y[k].argmax()\n",
    "        \n",
    "    train_y.append(Y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = [X_ts, X_ts2, X_ts3, X_ts4, X_ts5, X_ts6, X_ts7, X_ts8, X_ts9, X_ts10, X_ts11, X_ts12, X_ts13, \n",
    "          X_ts14, X_ts15, X_ts16, X_ts17, X_ts18, X_ts19, X_ts20]\n",
    "\n",
    "test_y = [y_ts, y_ts2, y_ts3, y_ts4, y_ts5, y_ts6, y_ts7, y_ts8, y_ts9, y_ts10, y_ts11, \n",
    "          y_ts12, y_ts13, y_ts14, y_ts15, y_ts16, y_ts17, y_ts18, y_ts19, y_ts20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamm_svc = np.zeros(20)\n",
    "zo_svc = np.zeros(20)\n",
    "\n",
    "for k in range(20):\n",
    "    clf_s = SVC()\n",
    "    clf_s.fit(train_x[k],train_y[k])\n",
    "    \n",
    "    ham_t = np.zeros(test_y[k].shape[0])\n",
    "    for j in range(test_y[k].shape[0]):\n",
    "        ham_t[j] = accuracy_score(test_y[k][j], clf_s.predict(test_x[k][j]))\n",
    "    \n",
    "    hamm_svc[k] = ham_t.mean()\n",
    "    zo_svc[k] = ham_t[ham_t==1].sum()/ham_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamm_svc_r = np.zeros(20)\n",
    "\n",
    "for k in range(20):\n",
    "    hamm_svc_r[k] = round(hamm_svc[k],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.392,  0.464,  0.346,  0.342,  0.237,  0.289,  0.258,  0.289,\n",
       "        0.45 ,  0.299,  0.441,  0.511,  0.49 ,  0.49 ,  0.346,  0.372,\n",
       "        0.44 ,  0.493,  0.476,  0.478])"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamm_svc_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_h = [0.776, 0.739, 0.552, 0.801, 0.731, 0.649, 0.731, 0.633, 0.813, 0.573,\n",
    "       0.662, 0.805, 0.769, 0.797, 0.753, 0.682, 0.658, 0.740, 0.781, 0.716]\n",
    "\n",
    "u_z = np.zeros(20)\n",
    "u_z[12] = 0.059\n",
    "u_z[-2] = 0.059\n",
    "\n",
    "b_z = np.zeros(20)\n",
    "b_z[1] = 0.059\n",
    "b_z[2] = 0.059\n",
    "b_z[11] = 0.294\n",
    "b_z[13] = 0.118\n",
    "b_z[-2] = 0.176\n",
    "\n",
    "b_h = [0.872, 0.782, 0.623, 0.856, 0.773, 0.680, 0.779, 0.648, 0.879, 0.686, 0.719,\n",
    "       0.847, 0.816, 0.789, 0.828, 0.736, 0.706, 0.769, 0.840, 0.767]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['color: red' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_res(k):\n",
    "    hamm = [round(hamm_svc_r.mean(),3), round(array(u_h).mean(),3), round(array(b_h).mean(),3)]\n",
    "    zo = [round(zo_svc.mean(),3), round(u_z.mean(),3), round(b_z.mean(),3)]\n",
    "    models = ['SVC', 'Unary only', 'Unary and Binary']\n",
    "    met = ['Average Hamming', 'Zero-One']\n",
    "    res_df = pd.DataFrame(hamm)\n",
    "    res_df.columns = ['Average Hamming:']\n",
    "    res_df['Zero-One:'] = zo\n",
    "    res_df.columns.name = 'Model:'\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_7aee585e_4282_11e7_bda1_d05099aa5affrow2_col0 {\n",
       "            \n",
       "                color:  red;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_7aee585e_4282_11e7_bda1_d05099aa5affrow2_col1 {\n",
       "            \n",
       "                color:  red;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_7aee585e_4282_11e7_bda1_d05099aa5aff\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th class=\"index_name level0\" >\n",
       "                  Model:\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col0\" colspan=1>\n",
       "                  Average Hamming:\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col1\" colspan=1>\n",
       "                  Zero-One:\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_7aee585e_4282_11e7_bda1_d05099aa5aff\"\n",
       "                 class=\"row_heading level0 row0\" rowspan=1>\n",
       "                    0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_7aee585e_4282_11e7_bda1_d05099aa5affrow0_col0\"\n",
       "                 class=\"data row0 col0\" >\n",
       "                    0.395\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_7aee585e_4282_11e7_bda1_d05099aa5affrow0_col1\"\n",
       "                 class=\"data row0 col1\" >\n",
       "                    0\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_7aee585e_4282_11e7_bda1_d05099aa5aff\"\n",
       "                 class=\"row_heading level0 row1\" rowspan=1>\n",
       "                    1\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_7aee585e_4282_11e7_bda1_d05099aa5affrow1_col0\"\n",
       "                 class=\"data row1 col0\" >\n",
       "                    0.718\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_7aee585e_4282_11e7_bda1_d05099aa5affrow1_col1\"\n",
       "                 class=\"data row1 col1\" >\n",
       "                    0.006\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_7aee585e_4282_11e7_bda1_d05099aa5aff\"\n",
       "                 class=\"row_heading level0 row2\" rowspan=1>\n",
       "                    2\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_7aee585e_4282_11e7_bda1_d05099aa5affrow2_col0\"\n",
       "                 class=\"data row2 col0\" >\n",
       "                    0.77\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_7aee585e_4282_11e7_bda1_d05099aa5affrow2_col1\"\n",
       "                 class=\"data row2 col1\" >\n",
       "                    0.035\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x7f627dff8240>"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res(19).style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
